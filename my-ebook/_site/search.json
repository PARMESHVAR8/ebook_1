[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "my-ebook",
    "section": "",
    "text": "1 Introduction\nDR.Harsh Pradhan, Phone: +91-9930034241 , Email: harsh.231284@gmail.com, Institute of Management Studies, Banaras Hindu University, Address: 18-GF, Jaipuria Enclave, Kaushambhi, Ghaziabad, India, 201010\nInterest: Goal Orientation Job Performance Consumer Behavior Behavioral Finance Bibiliometric Analysis Options as Derivatives Statistics Indian Knowledge System,\nOrcid ID\nGoogle Scholar\nGitHub\nResearcher ID\nPersonal Website\nYoutube ID\nDoing a PhD with me: README.1st\nAcademic Profile\nTopics to be covered:",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "my-ebook",
    "section": "1.1 Teaching",
    "text": "1.1 Teaching\nScience and statistics is/are one unitary thing; you cannot do one without the other. Towards this end, I teach some (in my opinion) critically important classes that provide a solid statistical foundation for doing research in cognitive science.\nCourses offered:\n\nFree online course, four weeks (MOOC), enrollments open: Introduction to Bayesian Data Analysis\nShort (four-hour) tutorial on Bayesian statistics, taught at EMLAR 2022: here\nIntroduction to (frequentist) statistics\nIntroduction to Bayesian data analysis for cognitive science\nBDA cover",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#lecture-notes",
    "href": "index.html#lecture-notes",
    "title": "my-ebook",
    "section": "1.2 Lecture notes",
    "text": "1.2 Lecture notes\nDownload from here.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#moodle-website",
    "href": "index.html#moodle-website",
    "title": "my-ebook",
    "section": "1.3 Moodle website",
    "text": "1.3 Moodle website\nAll communications with students in Potsdam will be done through this website. # üìò Schedule\n\n\n\nWeek\nLecture\nMain Topic\nSubtopic\nüé• Video\nüìÑ PDF Resource\n\n\n\n\nWeek 2\n1\nDescriptive Statistics\nCentral Tendency\nVideo\nWeek 2.pdf\n\n\n\n2\nDescriptive Statistics\nMeasure of Variability\nVideo\nSame as above\n\n\n\n3\nDescriptive Statistics\nDescribing Data\nVideo\nSame as above\n\n\n\n4\nDescriptive Statistics\nProbability\nVideo\nSame as above\n\n\n\n5\nDescriptive Statistics\nDistribution\nVideo\nSame as above\n\n\nWeek 3\n1\nDescriptive Statistics\nZ Table (Normal Distribution)\nVideo\nWeek 3.pdf\n\n\n\n2\nDescriptive Statistics\nMeasuring Divergence\nVideo\nSame as above\n\n\n\n3\nInferential Statistics\nSample and Population\nVideo\nSame as above\n\n\n\n4\nInferential Statistics\nModel Fit\nVideo\nSame as above\n\n\n\n5\nInferential Statistics\nHypothesis and Error\nVideo\nSame as above\n\n\nWeek 4\n1\nTerms of Statistics\nTerms of Statistics\nVideo\nWeek 4.pdf\n\n\n\n2\nTerms of Statistics\nT-Test\nVideo\nSame as above\n\n\n\n3\nTerms of Statistics\nT-Test in Detail\nVideo\nSame as above\n\n\n\n4\nANOVA\nANOVA\nVideo\nSame as above\n\n\nWeek 5\n1\nANOVA\nExample of ANOVA\nVideo\nWeek 5.pdf\n\n\n\n2\nANOVA\nTypes of ANOVA\nVideo\nSame as above\n\n\n\n3\nCorrelation\nIntroduction to Correlation\nVideo\nSame as above\n\n\n\n4\nCorrelation\nRegression (Part 1)\nVideo\nSame as above\n\n\n\n5\nCorrelation\nRegression (Part 2)\nVideo\nSame as above\n\n\nWeek 6\n1\nCorrelation\nR Script for Regression\nVideo\nWeek 6.pdf\n\n\n\n2\nChi Square\nChi Square\nVideo\nSame as above\n\n\n\n3\nChi Square\nChi Square Test\nVideo\nSame as above\n\n\n\n4\nLogistic Function\nRegression Function\nVideo\nSame as above\n\n\n\n5\nLogistic Function\nDistribution\nVideo\nSame as above\n\n\nWeek 7\n1\nTime Series\nIntro to Time Series\nVideo\nWeek 7.pdf\n\n\n\n2\nTime Series\nConditional Probability\nVideo\nSame as above\n\n\n\n3\nTime Series\nAdditional Concepts\nVideo\nSame as above\n\n\n\n4\nTime Series\nDistribution\nVideo\nSame as above\n\n\n\n5\nTime Series\nPoisson Distribution\nVideo\nSame as above\n\n\n\n6\nIndex Numbers\nPrice & Quantity Index\nVideo\nSame as above\n\n\n\n7\nDecision Environments\nRisk/Uncertainty, Bayes, Trees\nVideo\nSame as above\n\n\n\n8\nTime Series Analysis\nComponents, Trend, Seasonality\nVideo\nSame as above\n\n\n\n9\nTime Series Analysis\nLeast Squares Method\nVideo\nSame as above\n\n\nWeek 8\n1\nEffect Size & Documentation\nPackage/Library\nVideo\nWeek 8.pdf\n\n\n\n2\nEffect Size & Documentation\nRStudio vs RKward\nVideo\nSame as above\n\n\n\n3\nEffect Size & Documentation\nFlexplot\nVideo\nSame as above\n\n\n\n4\nEffect Size & Documentation\nFunctions\nVideo\nSame as above\n\n\n\n5\nEffect Size & Documentation\nR Shiny & R Markdown\nVideo\nSame as above\n\n\n\n6\nEffect Size & Documentation\nApplication with Real Datasets\nVideo\nSame as above\n\n\n\n7\nEffect Size & Interpretation\nImportance in Testing\nVideo\nSame as above\n\n\n\n8\nEffect Size & Interpretation\nInstalling dplyr, ggplot2\nVideo\nSame as above\n\n\n\n9\nEffect Size & Interpretation\nVisual Model Interpretation\nVideo\nSame as above\n\n\n\n10\nEffect Size & Interpretation\nCreating/Using Functions\nVideo\nSame as above\n\n\n\n11\nEffect Size & Interpretation\nReport, Dashboard, Interactivity\nVideo\nSame as above",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction-to-statistics.html",
    "href": "introduction-to-statistics.html",
    "title": "2¬† Introduction to Statistics",
    "section": "",
    "text": "3 Chapter 1: Welcome and Course Overview\nThis course offers an introduction to statistics through the RKWard graphical interface of R. Aimed at learners from diverse backgrounds, the course emphasizes practical application over theory. You don‚Äôt need a strong background in math or computing‚Äîjust an eagerness to learn.\nPre-Requisites:",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction-to-statistics.html#histogram",
    "href": "introduction-to-statistics.html#histogram",
    "title": "2¬† Introduction to Statistics",
    "section": "14.1 1. Histogram",
    "text": "14.1 1. Histogram\n\nDepicts the distribution of a single variable\n\nCan include frequency, relative frequency, and cumulative frequency\n\nBest for understanding where most data points lie",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction-to-statistics.html#pie-chart",
    "href": "introduction-to-statistics.html#pie-chart",
    "title": "2¬† Introduction to Statistics",
    "section": "14.2 2. Pie Chart",
    "text": "14.2 2. Pie Chart\n\nRepresents categorical data as slices of a circle\n\nBest when visualizing proportions",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction-to-statistics.html#scatter-plot",
    "href": "introduction-to-statistics.html#scatter-plot",
    "title": "2¬† Introduction to Statistics",
    "section": "14.3 3. Scatter Plot",
    "text": "14.3 3. Scatter Plot\n\nPlots two variables to examine relationships\n\nX-axis: Independent variable\n\nY-axis: Dependent variable\n\nUseful in exploring associations or potential causality",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction-to-statistics.html#box-plot",
    "href": "introduction-to-statistics.html#box-plot",
    "title": "2¬† Introduction to Statistics",
    "section": "14.4 4. Box Plot",
    "text": "14.4 4. Box Plot\n\nShows data distribution via quartiles\n\nMedian, interquartile range (IQR), and outliers are clearly indicated\n\nUseful for comparing multiple variables",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction-to-statistics.html#density-plot",
    "href": "introduction-to-statistics.html#density-plot",
    "title": "2¬† Introduction to Statistics",
    "section": "14.5 5. Density Plot",
    "text": "14.5 5. Density Plot\n\nSmoothed version of a histogram\n\nBetter suited for continuous data with decimal variation\n\nKey Tips:\n\nJP_01 was frequently used as an example variable\n\nRKWard allows saving and exporting plots easily\n\nGUI menus guide the user through plot creation\n\n\nAlways choose the plot type that best matches your data and goal: frequency, relationship, or comparison.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html",
    "href": "basic-statistics1.html",
    "title": "3¬† week 1",
    "section": "",
    "text": "4 Introduction\nWelcome to the ‚ÄúBasic Statistics Using GUI-R (RK Ward)‚Äù course, led by Dr.¬†Harsh Pradhan at the Institute of Management Studies, Banaras Hindu University. This course takes an integrated approach to statistical analysis, bridging theory with practical skills through the R programming language and its GUI, RKWard.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#objectives-of-the-course",
    "href": "basic-statistics1.html#objectives-of-the-course",
    "title": "3¬† week 1",
    "section": "4.1 Objectives of the Course",
    "text": "4.1 Objectives of the Course\n\nUnderstand fundamental concepts related to statistics.\nGain proficiency in using R and RKWard for statistical analysis.\nLearn to visualize data effectively.\nApply statistical methodologies to real-world datasets.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#r-programming-language",
    "href": "basic-statistics1.html#r-programming-language",
    "title": "3¬† week 1",
    "section": "5.1 R Programming Language",
    "text": "5.1 R Programming Language\nR is a versatile, open-source language specifically designed for statistical analysis and data visualization. It provides an extensive suite of statistical procedures, making it a cornerstone for statisticians and data scientists.\nKey Features of R:\n\nExtensive Libraries: R hosts thousands of packages that support numerous statistical models such as linear regression, time series, and more.\nCustomizable Graphics: The base graphics capabilities, along with packages like ggplot2, allow users to create a variety of complex visualizations with relative ease.\nData Manipulation Tools: Packages like dplyr and tidyr provide robust tools for data cleaning and transformation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#understanding-rkward",
    "href": "basic-statistics1.html#understanding-rkward",
    "title": "3¬† week 1",
    "section": "5.2 Understanding RKWard",
    "text": "5.2 Understanding RKWard\nRKWard serves as a user-friendly interface that simplifies interactions with R, allowing users‚Äîespecially those less familiar with programming‚Äîto utilize its powerful capabilities without a steep learning curve.\nFeatures of RKWard Include:\n\nGraphical User Interface: Navigation through menus rather than command lines enhances accessibility.\nBuilt-in Documentation: Context-sensitive help facilitates learning and troubleshooting.\nIntegration with R: Commands executed via the GUI can be viewed and modified, providing a dual-learning experience.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#types-of-variables",
    "href": "basic-statistics1.html#types-of-variables",
    "title": "3¬† week 1",
    "section": "6.1 Types of Variables",
    "text": "6.1 Types of Variables\nVariables are the building blocks of statistical analysis, representing the characteristics or properties of the data.\n\n6.1.1 Qualitative Variables (Categorical Variables)\n\nNominal Variables: These variables categorize data without an inherent order. For example, types of fruits (apple, orange) are nominal.\nOrdinal Variables: These represent ordered categories. For instance, a customer satisfaction survey may be rated as poor, fair, good, or excellent.\n\n\n\n6.1.2 Quantitative Variables\n\nDiscrete Variables: These variables take on countable values, such as the number of students in a class.\nContinuous Variables: These can take any value within a given range, such as height and weight.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#importance-of-defining-variables",
    "href": "basic-statistics1.html#importance-of-defining-variables",
    "title": "3¬† week 1",
    "section": "6.2 Importance of Defining Variables",
    "text": "6.2 Importance of Defining Variables\nProperly understanding and defining variables is crucial for:\n\nSelecting appropriate statistical tests.\nEnsuring accurate data interpretation.\nStructuring datasets to facilitate analysis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#statistical-data-types",
    "href": "basic-statistics1.html#statistical-data-types",
    "title": "3¬† week 1",
    "section": "7.1 Statistical Data Types",
    "text": "7.1 Statistical Data Types\nData types are foundational for statistical analysis as they define what kind of arithmetic operations can be performed on the data.\n\n\n\n\n\n\n\n\nData Type\nDescription\nExample\n\n\n\n\nNominal\nCategorical data without order\nBlood types (A, B, AB, O)\n\n\nOrdinal\nCategorical data with a defined order\nCustomer satisfaction (poor, fair, good)\n\n\nInterval\nNumerical data with meaningful differences\nTemperature in Celsius\n\n\nRatio\nNumerical data with an absolute zero\nWeight, height",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#spreadsheet-basics",
    "href": "basic-statistics1.html#spreadsheet-basics",
    "title": "3¬† week 1",
    "section": "7.2 Spreadsheet Basics",
    "text": "7.2 Spreadsheet Basics\nSpreadsheets provide a structured format for data entry, where rows represent instances (e.g., individuals, items) and columns represent variables (e.g., age, gender).\nKey Functions of Spreadsheets:\n\nData Organization: Data is easily sorted and filtered.\nFormulas and Functions: Built-in functions allow for quick calculation and data manipulation.\nVisualization Integration: Charts and tables can visually represent data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#data-preparation",
    "href": "basic-statistics1.html#data-preparation",
    "title": "3¬† week 1",
    "section": "8.1 Data Preparation",
    "text": "8.1 Data Preparation\nBefore importing data into RKWard, ensure that your dataset meets standards such as:\n\nProperly labeled columns.\nConsistent data types.\nAbsence of unnecessary formatting or symbols.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#step-by-step-import-process",
    "href": "basic-statistics1.html#step-by-step-import-process",
    "title": "3¬† week 1",
    "section": "8.2 Step-by-Step Import Process",
    "text": "8.2 Step-by-Step Import Process\nSteps to import data into RKWard:\n\nOpen RKWard and access the main interface.\nGo to the ‚ÄúData‚Äù tab and select ‚ÄúImport Data‚Äù.\nChoose the file type such as CSV or Excel.\nBrowse to locate your file.\nSpecify data types for each column during import and ensure the first row contains headers.\nReview the imported data in the workspace to confirm it‚Äôs properly loaded.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#descriptive-statistics",
    "href": "basic-statistics1.html#descriptive-statistics",
    "title": "3¬† week 1",
    "section": "9.1 Descriptive Statistics",
    "text": "9.1 Descriptive Statistics\nDescriptive statistics help summarize and organize data in a meaningful way.\n\n9.1.1 Central Tendency Measures\n\nMean: Average of the dataset.\nMedian: Middle value when data is ordered.\nMode: Most frequent value in the dataset.\n\n\n\n\n\n\n\n\n\nMeasure\nFormula\nDescription\n\n\n\n\nMean\n\\(\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\\)\nAverage value\n\n\nMedian\n(Sorted data, middle item)\nMiddle value in ordered dataset\n\n\nMode\nValue that appears most frequently\nMost common value\n\n\n\n\n\n9.1.2 Dispersion Measures\n\nRange: Difference between the maximum and minimum values.\nVariance: Measurement of the spread of data points.\nStandard Deviation: Square root of variance, providing a measure of the average distance from the mean.\n\n\n\n\n\n\n\n\n\nMeasure\nFormula\nDescription\n\n\n\n\nRange\n\\(Range = Max - Min\\)\nSpread of dataset\n\n\nVariance\n\\(Var(X) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n - 1}\\)\nSpread of data relative to mean\n\n\nStandard Deviation\n\\(SD(X) = \\sqrt{Var(X)}\\)\nAverage distance from mean",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#inferential-statistics",
    "href": "basic-statistics1.html#inferential-statistics",
    "title": "3¬† week 1",
    "section": "9.2 Inferential Statistics",
    "text": "9.2 Inferential Statistics\nInferential statistics allow us to make predictions or inferences about a population based on a sample.\n\nHypothesis Testing: A method to test assumptions regarding population parameters using sample data.\nConfidence Intervals: Define a range of values derived from sample statistics that likely encompass the true population parameter.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#practical-r-commands-and-functions",
    "href": "basic-statistics1.html#practical-r-commands-and-functions",
    "title": "3¬† week 1",
    "section": "9.3 Practical R Commands and Functions",
    "text": "9.3 Practical R Commands and Functions\nUnderstanding and utilizing R functions is crucial for effective data analysis. Some key functions include:\n\nmean(): Calculates the average.\nsd(): Computes standard deviation.\nt.test(): Performs a t-test for hypothesis testing.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#significance-of-data-visualization",
    "href": "basic-statistics1.html#significance-of-data-visualization",
    "title": "3¬† week 1",
    "section": "10.1 Significance of Data Visualization",
    "text": "10.1 Significance of Data Visualization\nVisualization enhances comprehension by allowing researchers to observe patterns, trends, and anomalies effectively.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#types-of-graphs",
    "href": "basic-statistics1.html#types-of-graphs",
    "title": "3¬† week 1",
    "section": "10.2 Types of Graphs",
    "text": "10.2 Types of Graphs\nVariety in graph types caters to different data presentation needs:\n\n\n\n\n\n\n\nGraph Type\nUse Case\n\n\n\n\nBar Graph\nComparing categorical data\n\n\nHistogram\nDisplaying distribution of continuous data\n\n\nBox Plot\nSummarizing data distributions and spotting outliers\n\n\nScatter Plot\nInvestigating relationships between two quantitative variables",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#implementing-visualization-in-rkward",
    "href": "basic-statistics1.html#implementing-visualization-in-rkward",
    "title": "3¬† week 1",
    "section": "10.3 Implementing Visualization in RKWard",
    "text": "10.3 Implementing Visualization in RKWard\nStudents will learn how to create visualizations within RKWard by following these steps:\n\nNavigate to the graph creation menu.\nSelect the desired type of graph.\nCustomize visual elements such as titles, colors, and axes.\nGenerate and export the graph for use in reports.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#case-studies-in-various-fields",
    "href": "basic-statistics1.html#case-studies-in-various-fields",
    "title": "3¬† week 1",
    "section": "11.1 Case Studies in Various Fields",
    "text": "11.1 Case Studies in Various Fields\nStatistics plays a pivotal role in diverse disciplines:\n\n\n\n\n\n\n\nField\nApplication\n\n\n\n\nHealthcare\nAnalyzing medical test results, outcomes of treatments, and patient demographics\n\n\nBusiness\nApplied for market analyses, customer satisfaction studies, and financial forecasting\n\n\nSocial Sciences\nEmployed in surveys to understand populations, opinions, and behavioral patterns",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#utilizing-statistical-methods-for-decision-making",
    "href": "basic-statistics1.html#utilizing-statistical-methods-for-decision-making",
    "title": "3¬† week 1",
    "section": "11.2 Utilizing Statistical Methods for Decision Making",
    "text": "11.2 Utilizing Statistical Methods for Decision Making\n\nUse statistical evidence to guide business strategies.\nMake informed policy decisions based on empirical data.\nReport findings clearly for transparency and comprehension.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics1.html#key-takeaways",
    "href": "basic-statistics1.html#key-takeaways",
    "title": "3¬† week 1",
    "section": "12.1 Key Takeaways",
    "text": "12.1 Key Takeaways\n\nProficiency in defining and using variables and data types.\nCapability to import and manipulate data in RKWard.\nUnderstanding of basic statistical practices and their applications.\nSkill in visualizing data for effective communication of results.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>week 1</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html",
    "href": "basic-statistics2.html",
    "title": "4¬† basic-statistics_2",
    "section": "",
    "text": "5 Introduction",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#purpose-of-the-ebook",
    "href": "basic-statistics2.html#purpose-of-the-ebook",
    "title": "4¬† basic-statistics_2",
    "section": "5.1 Purpose of the eBook",
    "text": "5.1 Purpose of the eBook\nThis eBook aims to provide a comprehensive understanding of basic statistics, focusing on the essential principles necessary for data analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#importance-of-statistics",
    "href": "basic-statistics2.html#importance-of-statistics",
    "title": "4¬† basic-statistics_2",
    "section": "5.2 Importance of Statistics",
    "text": "5.2 Importance of Statistics\nStatistics is critical in interpreting data efficiently and effectively across disciplines.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#overview-of-statistics",
    "href": "basic-statistics2.html#overview-of-statistics",
    "title": "4¬† basic-statistics_2",
    "section": "6.1 Overview of Statistics",
    "text": "6.1 Overview of Statistics\nStatistics is the discipline that deals with the collection, analysis, interpretation, and presentation of data.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#types-of-data",
    "href": "basic-statistics2.html#types-of-data",
    "title": "4¬† basic-statistics_2",
    "section": "6.2 Types of Data",
    "text": "6.2 Types of Data\n\nQualitative Data: Represents categories or labels without numeric value (e.g., gender, religion).\nQuantitative Data:\n\nDiscrete Data: Countable values (e.g., number of students).\nContinuous Data: Measurable values (e.g., height, weight).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#descriptive-vs.-inferential-statistics",
    "href": "basic-statistics2.html#descriptive-vs.-inferential-statistics",
    "title": "4¬† basic-statistics_2",
    "section": "6.3 Descriptive vs.¬†Inferential Statistics",
    "text": "6.3 Descriptive vs.¬†Inferential Statistics\n\nDescriptive Statistics: Summarizes or describes the characteristics of a dataset.\nInferential Statistics: Makes predictions or inferences about a population based on a sample.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#definition-and-importance",
    "href": "basic-statistics2.html#definition-and-importance",
    "title": "4¬† basic-statistics_2",
    "section": "7.1 Definition and Importance",
    "text": "7.1 Definition and Importance\nMeasures of central tendency describe the center point or typical value of a dataset.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#the-mean",
    "href": "basic-statistics2.html#the-mean",
    "title": "4¬† basic-statistics_2",
    "section": "7.2 The Mean",
    "text": "7.2 The Mean\nThe mean is the arithmetic average of a dataset.\n\n7.2.1 Example\nConsider the data: 2, 3, 5, 7, 11\nMean = \\(\\frac{2 + 3 + 5 + 7 + 11}{5} = \\frac{28}{5} = 5.6\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#the-median",
    "href": "basic-statistics2.html#the-median",
    "title": "4¬† basic-statistics_2",
    "section": "7.3 The Median",
    "text": "7.3 The Median\nThe median is the middle value in an ordered dataset.\n\n7.3.1 Example\nConsider the data: 3, 5, 1, 7, 9\nOrdered: 1, 3, 5, 7, 9 ‚Üí Median = 5",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#the-mode",
    "href": "basic-statistics2.html#the-mode",
    "title": "4¬† basic-statistics_2",
    "section": "7.4 The Mode",
    "text": "7.4 The Mode\nThe mode is the value that appears most frequently in a dataset.\n\n7.4.1 Example\nData: 2, 4, 4, 5, 5, 5, 7, 8\nMode = 5",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#comparison-of-measures",
    "href": "basic-statistics2.html#comparison-of-measures",
    "title": "4¬† basic-statistics_2",
    "section": "7.5 Comparison of Measures",
    "text": "7.5 Comparison of Measures\n\n\n\n\n\n\n\n\n\nMeasure\nDescription\nStrengths\nLimitations\n\n\n\n\nMean\nAverage of all data points\nUtilizes all data\nSensitive to outliers\n\n\nMedian\nMiddle value\nRobust to outliers\nIgnores extreme values\n\n\nMode\nMost frequent value\nUseful for categorical data\nMay not exist or be unique",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#definition-and-importance-1",
    "href": "basic-statistics2.html#definition-and-importance-1",
    "title": "4¬† basic-statistics_2",
    "section": "8.1 Definition and Importance",
    "text": "8.1 Definition and Importance\nMeasures of variability indicate the spread or dispersion within a dataset.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#range",
    "href": "basic-statistics2.html#range",
    "title": "4¬† basic-statistics_2",
    "section": "8.2 Range",
    "text": "8.2 Range\nThe range is the difference between the maximum and minimum values.\n\n8.2.1 Example\nData: 4, 8, 2, 10, 6\nRange = 10 - 2 = 8",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#variance",
    "href": "basic-statistics2.html#variance",
    "title": "4¬† basic-statistics_2",
    "section": "8.3 Variance",
    "text": "8.3 Variance\nVariance is the average of the squared deviations from the mean.\n\n8.3.1 Example\nData: 2, 4, 4, 4, 5, 5, 7\nMean = 4.43 (approx.)\nVariance = \\(\\frac{\\sum(x_i - \\bar{x})^2}{n - 1}\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#standard-deviation",
    "href": "basic-statistics2.html#standard-deviation",
    "title": "4¬† basic-statistics_2",
    "section": "8.4 Standard Deviation",
    "text": "8.4 Standard Deviation\nStandard deviation is the square root of the variance.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#interquartile-range-iqr",
    "href": "basic-statistics2.html#interquartile-range-iqr",
    "title": "4¬† basic-statistics_2",
    "section": "8.5 Interquartile Range (IQR)",
    "text": "8.5 Interquartile Range (IQR)\nThe IQR measures the middle 50% of the data between Q1 and Q3.\n\n8.5.1 Example\nData: 1, 2, 3, 4, 5, 6, 7, 8, 9\nQ1 = 3, Q3 = 7\nIQR = 7 - 3 = 4",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#introduction-to-probability",
    "href": "basic-statistics2.html#introduction-to-probability",
    "title": "4¬† basic-statistics_2",
    "section": "9.1 Introduction to Probability",
    "text": "9.1 Introduction to Probability\nProbability measures the likelihood of occurrence of an event.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#types-of-events",
    "href": "basic-statistics2.html#types-of-events",
    "title": "4¬† basic-statistics_2",
    "section": "9.2 Types of Events",
    "text": "9.2 Types of Events\n\nIndependent Events: One event does not affect another.\nDependent Events: One event influences the outcome of another.\nMutually Exclusive Events: Events that cannot happen at the same time.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#basic-probability-rules",
    "href": "basic-statistics2.html#basic-probability-rules",
    "title": "4¬† basic-statistics_2",
    "section": "9.3 Basic Probability Rules",
    "text": "9.3 Basic Probability Rules\n\nAddition Rule: This rule applies when you‚Äôre calculating the probability of event A or event B occurring. \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\nMultiplication Rule: This rule applies when you‚Äôre calculating the probability of event A and event B both occurring (for independent events). \\[\nP(A \\cap B) = P(A) \\times P(B)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#introduction-to-probability-distributions",
    "href": "basic-statistics2.html#introduction-to-probability-distributions",
    "title": "4¬† basic-statistics_2",
    "section": "9.4 Introduction to Probability Distributions",
    "text": "9.4 Introduction to Probability Distributions\n\n9.4.1 Normal Distribution\n\nSymmetric about the mean.\nBell-shaped curve.\nProperties: Mean = Median = Mode.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#transcript-from-lec06",
    "href": "basic-statistics2.html#transcript-from-lec06",
    "title": "4¬† basic-statistics_2",
    "section": "10.1 Transcript from Lec06",
    "text": "10.1 Transcript from Lec06\nKey Discussion Points: - Effects of outliers on the mean. - Properties of the mean.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#transcript-from-lec07",
    "href": "basic-statistics2.html#transcript-from-lec07",
    "title": "4¬† basic-statistics_2",
    "section": "10.2 Transcript from Lec07",
    "text": "10.2 Transcript from Lec07\nKey Discussion Points: - Concepts of range, variance, and standard deviation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#transcript-from-lec08",
    "href": "basic-statistics2.html#transcript-from-lec08",
    "title": "4¬† basic-statistics_2",
    "section": "10.3 Transcript from Lec08",
    "text": "10.3 Transcript from Lec08\nKey Discussion Points: - Explanation of the Z score. - Galton board demonstration.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#transcript-from-lec09",
    "href": "basic-statistics2.html#transcript-from-lec09",
    "title": "4¬† basic-statistics_2",
    "section": "10.4 Transcript from Lec09",
    "text": "10.4 Transcript from Lec09\nKey Discussion Points: - Introduction to probability distributions. - Basic probability concepts and terms.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#frequency-distribution-example",
    "href": "basic-statistics2.html#frequency-distribution-example",
    "title": "4¬† basic-statistics_2",
    "section": "12.1 Frequency Distribution Example",
    "text": "12.1 Frequency Distribution Example\n\n\n\nValue\nFrequency\n\n\n\n\n1\n4\n\n\n2\n6\n\n\n3\n3\n\n\n4\n2\n\n\n5\n1",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#interquartile-range-example",
    "href": "basic-statistics2.html#interquartile-range-example",
    "title": "4¬† basic-statistics_2",
    "section": "12.2 Interquartile Range Example",
    "text": "12.2 Interquartile Range Example\n\n\n\nPosition\nValue\n\n\n\n\n1\n12\n\n\n2\n30\n\n\n3\n45\n\n\n4\n57\n\n\n5\n70\n\n\n\n\\[\n\\text{IQR} = 57 - 30 = 27\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics2.html#box-plot-visualization",
    "href": "basic-statistics2.html#box-plot-visualization",
    "title": "4¬† basic-statistics_2",
    "section": "12.3 Box Plot Visualization",
    "text": "12.3 Box Plot Visualization\nA box plot visualizes:\n\nMinimum\nFirst Quartile (\\(Q1\\))\nMedian\nThird Quartile (\\(Q3\\))\nMaximum",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>basic-statistics_2</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html",
    "href": "basic-statistics3.html",
    "title": "5¬† basic-statistics_3",
    "section": "",
    "text": "6 Introduction",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#importance-of-statistics",
    "href": "basic-statistics3.html#importance-of-statistics",
    "title": "5¬† basic-statistics_3",
    "section": "6.1 Importance of Statistics",
    "text": "6.1 Importance of Statistics\nStatistics is a powerful tool used across various disciplines, from economics and social sciences to natural sciences and engineering. It enables researchers to analyze data, draw conclusions, and make predictions about populations based on sample observations. Understanding statistical principles is essential for anyone involved in empirical research, data science, and decision-making processes.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#overview-of-topics",
    "href": "basic-statistics3.html#overview-of-topics",
    "title": "5¬† basic-statistics_3",
    "section": "6.2 Overview of Topics",
    "text": "6.2 Overview of Topics\nThis eBook will delve deeply into core concepts such as populations and samples, hypotheses and errors, various statistical models, the normal distribution, and essential statistical techniques in R using the GUI-R interface. Each chapter will provide detailed explanations, examples, and practical applications to enhance understanding.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#definition-of-population",
    "href": "basic-statistics3.html#definition-of-population",
    "title": "5¬† basic-statistics_3",
    "section": "7.1 Definition of Population",
    "text": "7.1 Definition of Population\nIn statistics, a population is defined as the entire set of individuals, items, or events of interest. For instance, if a researcher aims to study the average height of adults in the United States, the population would include every adult residing in the country.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#definition-of-sample",
    "href": "basic-statistics3.html#definition-of-sample",
    "title": "5¬† basic-statistics_3",
    "section": "7.2 Definition of Sample",
    "text": "7.2 Definition of Sample\nA sample is a subset of the population selected for analysis. It is crucial that this sample adequately represents the population to ensure that the conclusions drawn are applicable. For example, selecting individuals from various demographic backgrounds when studying a health-related issue ensures a more accurate reflection of the population.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#importance-in-research",
    "href": "basic-statistics3.html#importance-in-research",
    "title": "5¬† basic-statistics_3",
    "section": "7.3 Importance in Research",
    "text": "7.3 Importance in Research\nThe primary reason for studying a sample rather than the entire population is practicality. Conducting a census can be time-consuming and costly. Hence, researchers select samples that allow them to infer insights about the population efficiently.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#relationship-between-population-and-sample",
    "href": "basic-statistics3.html#relationship-between-population-and-sample",
    "title": "5¬† basic-statistics_3",
    "section": "7.4 Relationship Between Population and Sample",
    "text": "7.4 Relationship Between Population and Sample\nThe relationship between population and sample is crucial, as a well-chosen sample can provide valid insights into the population characteristics. Understanding this relationship helps researchers avoid common pitfalls, such as bias in sampling, which can lead to inaccurate conclusions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#understanding-hypotheses",
    "href": "basic-statistics3.html#understanding-hypotheses",
    "title": "5¬† basic-statistics_3",
    "section": "8.1 Understanding Hypotheses",
    "text": "8.1 Understanding Hypotheses\nA hypothesis is an educated guess or a statement about the relationship between two or more variables that can be tested through research. For example, one might hypothesize that ‚Äústudents who study more than three hours a day will score higher on exams.‚Äù",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#crafting-null-and-alternative-hypotheses",
    "href": "basic-statistics3.html#crafting-null-and-alternative-hypotheses",
    "title": "5¬† basic-statistics_3",
    "section": "8.2 Crafting Null and Alternative Hypotheses",
    "text": "8.2 Crafting Null and Alternative Hypotheses\n\nNull Hypothesis (\\(H_0\\)): A statement suggesting that there is no effect or difference.\n\\[H_0: \\mu_1 = \\mu_2\\]\nAlternative Hypothesis (\\(H_a\\)): A statement indicating the presence of an effect or difference.\n\\[H_a: \\mu_1 \\neq \\mu_2\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#types-of-errors",
    "href": "basic-statistics3.html#types-of-errors",
    "title": "5¬† basic-statistics_3",
    "section": "8.3 Types of Errors",
    "text": "8.3 Types of Errors\n\nType I Error (\\(\\alpha\\)): Occurs when a true null hypothesis is incorrectly rejected.\n\nType II Error (\\(\\beta\\)): Occurs when a false null hypothesis is incorrectly accepted.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#significance-level",
    "href": "basic-statistics3.html#significance-level",
    "title": "5¬† basic-statistics_3",
    "section": "8.4 Significance Level",
    "text": "8.4 Significance Level\nThe significance level (often set at 0.05) helps researchers determine the threshold for rejecting the null hypothesis. If the probability of obtaining the observed data under the null hypothesis is less than the significance level, the null hypothesis can be rejected.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#introduction-to-inferential-statistics",
    "href": "basic-statistics3.html#introduction-to-inferential-statistics",
    "title": "5¬† basic-statistics_3",
    "section": "9.1 Introduction to Inferential Statistics",
    "text": "9.1 Introduction to Inferential Statistics\nInferential statistics allow researchers to draw conclusions about populations based on sample data. It involves estimating population parameters, testing hypotheses, and making predictions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#sampling-techniques-in-detail",
    "href": "basic-statistics3.html#sampling-techniques-in-detail",
    "title": "5¬† basic-statistics_3",
    "section": "9.2 Sampling Techniques in Detail",
    "text": "9.2 Sampling Techniques in Detail\n\n9.2.1 Simple Random Sampling\nEach member of the population has an equal chance of being selected.\n\n\n9.2.2 Stratified Sampling\nThe population is divided into subgroups (strata) and samples are drawn proportionally from each stratum.\n\n\n9.2.3 Systematic Sampling\nEvery nth member of the population is selected after a random start.\n\n\n9.2.4 Cluster Sampling\nEntire clusters are randomly selected for analysis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#estimating-population-parameters",
    "href": "basic-statistics3.html#estimating-population-parameters",
    "title": "5¬† basic-statistics_3",
    "section": "9.3 Estimating Population Parameters",
    "text": "9.3 Estimating Population Parameters\nResearchers estimate parameters like the population mean or proportion using sample data and quantify uncertainty through confidence intervals.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#central-limit-theorem",
    "href": "basic-statistics3.html#central-limit-theorem",
    "title": "5¬† basic-statistics_3",
    "section": "9.4 Central Limit Theorem",
    "text": "9.4 Central Limit Theorem\nThe Central Limit Theorem (CLT) states that, for sufficiently large samples (\\(n &gt; 30\\)), the sampling distribution of the sample mean approximates a normal distribution regardless of the population‚Äôs distribution.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#definition-and-importance-of-model-fit",
    "href": "basic-statistics3.html#definition-and-importance-of-model-fit",
    "title": "5¬† basic-statistics_3",
    "section": "10.1 Definition and Importance of Model Fit",
    "text": "10.1 Definition and Importance of Model Fit\nModel fit refers to how well a statistical model represents the data it is based upon. A good model fit enables accurate predictions and reliable conclusions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#statistical-models-explained",
    "href": "basic-statistics3.html#statistical-models-explained",
    "title": "5¬† basic-statistics_3",
    "section": "10.2 Statistical Models Explained",
    "text": "10.2 Statistical Models Explained\n\n10.2.1 Linear Regression\nUsed to predict a dependent variable using one or more independent variables.\n\\[\nY = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\epsilon\n\\]\n\n\n10.2.2 Logistic Regression\nUsed when the outcome variable is binary (e.g., yes/no, pass/fail).\n\n\n10.2.3 Multiple Regression\nAn extension of linear regression that includes more than one predictor.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#evaluating-model-fit",
    "href": "basic-statistics3.html#evaluating-model-fit",
    "title": "5¬† basic-statistics_3",
    "section": "10.3 Evaluating Model Fit",
    "text": "10.3 Evaluating Model Fit\n\n10.3.1 R-squared\n\\[\nR^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n\\]\nIndicates the proportion of variance explained by the model.\n\n\n10.3.2 Adjusted R-squared\nAdjusts \\(R^2\\) based on the number of predictors in the model.\n\n\n10.3.3 AIC and BIC\nModel selection metrics that penalize overly complex models to avoid overfitting.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#characteristics-of-normal-distribution",
    "href": "basic-statistics3.html#characteristics-of-normal-distribution",
    "title": "5¬† basic-statistics_3",
    "section": "11.1 Characteristics of Normal Distribution",
    "text": "11.1 Characteristics of Normal Distribution\n\nSymmetrical bell-shaped curve\n\nMean = Median = Mode\n\n68%-95%-99.7% rule applies",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#practical-application-of-z-tables",
    "href": "basic-statistics3.html#practical-application-of-z-tables",
    "title": "5¬† basic-statistics_3",
    "section": "11.2 Practical Application of Z-tables",
    "text": "11.2 Practical Application of Z-tables\nZ-scores help determine how far a data point is from the mean in terms of standard deviations.\n\\[\nZ = \\frac{(X - \\mu)}{\\sigma}\n\\]\n\n11.2.1 Application Examples\nExample 1\nAverage height = 70 inches, SD = 3, height = 74 inches:\n\\[\nZ = \\frac{74 - 70}{3} = 1.33\n\\]\nThis corresponds to roughly 90.82% in the z-table.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#summary-measures",
    "href": "basic-statistics3.html#summary-measures",
    "title": "5¬† basic-statistics_3",
    "section": "12.1 Summary Measures",
    "text": "12.1 Summary Measures\n\n12.1.1 Mean\n\\[\n\\text{Mean} = \\frac{\\sum X}{N}\n\\]\n\n\n12.1.2 Median\nThe middle value in a sorted dataset.\n\n\n12.1.3 Mode\nThe most frequently occurring value.\n\n\n12.1.4 Variance\n\\[\n\\sigma^2 = \\frac{\\sum (X - \\mu)^2}{N}\n\\]\n\n\n12.1.5 Standard Deviation\n\\[\n\\sigma = \\sqrt{\\sigma^2}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#measures-of-shape",
    "href": "basic-statistics3.html#measures-of-shape",
    "title": "5¬† basic-statistics_3",
    "section": "12.2 Measures of Shape",
    "text": "12.2 Measures of Shape\n\n12.2.1 Skewness\nIndicates asymmetry.\n\n\n12.2.2 Kurtosis\nMeasures peakness. Normal = 3.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics3.html#data-visualization-techniques",
    "href": "basic-statistics3.html#data-visualization-techniques",
    "title": "5¬† basic-statistics_3",
    "section": "12.3 Data Visualization Techniques",
    "text": "12.3 Data Visualization Techniques\n\nHistograms: Show distribution of data\n\nBox Plots: Summarize quartiles and outliers\n\nScatter Plots: Show relationships between two variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>basic-statistics_3</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html",
    "href": "basic-statistics4.html",
    "title": "6¬† basic-statistics_4",
    "section": "",
    "text": "7 Introduction\nThis eBook serves as a comprehensive guide to understanding basic statistics, focusing particularly on concepts pertinent to the use of GUI-R (RK Ward). It combines theoretical knowledge with practical applications, allowing readers to engage with statistical analysis effectively.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#course-name",
    "href": "basic-statistics4.html#course-name",
    "title": "6¬† basic-statistics_4",
    "section": "8.1 Course Name",
    "text": "8.1 Course Name\nBasic Statistics using GUI-R (RKWard)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#instructor-profile",
    "href": "basic-statistics4.html#instructor-profile",
    "title": "6¬† basic-statistics_4",
    "section": "8.2 Instructor Profile",
    "text": "8.2 Instructor Profile\nDr.¬†Harsh Pradhan is an Assistant Professor at the Institute of Management Studies, Banaras Hindu University. He specializes in statistical methods and data analysis techniques. For a complete overview of his work, refer to his BHU Faculty Profile.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#learning-objectives",
    "href": "basic-statistics4.html#learning-objectives",
    "title": "6¬† basic-statistics_4",
    "section": "8.3 Learning Objectives",
    "text": "8.3 Learning Objectives\n\nUnderstand and apply fundamental statistical concepts.\nPerform T-tests and ANOVA using real data.\nCalculate and interpret confidence intervals.\nUtilize GUI-R for statistical analysis effectively.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#descriptive-statistics",
    "href": "basic-statistics4.html#descriptive-statistics",
    "title": "6¬† basic-statistics_4",
    "section": "9.1 Descriptive Statistics",
    "text": "9.1 Descriptive Statistics\nDescriptive statistics summarize and describe the features of a dataset.\n\n9.1.1 Measures of Central Tendency\n\nMean: Average value calculated by summing observations and dividing by the number of observations.\nMedian: The middle value when the data is ordered. If there is an even number of observations, it is the average of the two middle values.\nMode: The most frequently occurring value in a dataset.\n\n\n9.1.1.1 Example Calculation\nGiven the data set: [4, 8, 6, 5, 3]\n\nMean: \\((4 + 8 + 6 + 5 + 3) / 5 = 5.2\\)\nMedian: Ordered data [3, 4, 5, 6, 8], median is 5.\nMode: No mode (all values are unique).\n\n\n\n\n9.1.2 Measures of Dispersion\n\nRange: The difference between the maximum and minimum values in a dataset.\nVariance: The average of the squared differences from the Mean.\nStandard Deviation (SD): The square root of variance, showing how much variation exists from the mean.\n\n\n9.1.2.1 Example Table of Measures\n\n\n\nStatistic\nValue\n\n\n\n\nMean\n5.2\n\n\nMedian\n5\n\n\nMode\nN/A\n\n\nRange\n5\n\n\nVariance\n3.52\n\n\nSD\n1.88",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#inferential-statistics",
    "href": "basic-statistics4.html#inferential-statistics",
    "title": "6¬† basic-statistics_4",
    "section": "9.2 Inferential Statistics",
    "text": "9.2 Inferential Statistics\nInferential statistics involves making predictions or inferences about a population based on a sample of data.\n\n9.2.1 Hypothesis Testing\n\nNull Hypothesis (H‚ÇÄ): A statement asserting there is no effect or difference.\nAlternative Hypothesis (H‚ÇÅ): A statement indicating the presence of an effect or difference.\n\n\n\n9.2.2 Confidence Intervals\nA confidence interval (CI) provides a range of values likely to contain the population parameter (e.g., mean) with a certain level of confidence (usually 95%).\nFormula:\n\\[\nCI = \\bar{x} \\pm Z \\times \\frac{s}{\\sqrt{n}}\n\\]\nWhere: - \\(\\bar{x}\\) = sample mean\n- \\(Z\\) = Z-score for the desired confidence level\n- \\(s\\) = standard deviation of the sample\n- \\(n\\) = sample size\n\n\n9.2.3 Types of Errors\n\nType I Error: Rejecting the null hypothesis when it is true (false positive).\nType II Error: Failing to reject the null hypothesis when it is false (false negative).",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#introduction-to-t-test",
    "href": "basic-statistics4.html#introduction-to-t-test",
    "title": "6¬† basic-statistics_4",
    "section": "10.1 Introduction to T-Test",
    "text": "10.1 Introduction to T-Test\nThe T-test is a hypothesis test used to determine if there is a significant difference between the means of two groups.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#types-of-t-tests",
    "href": "basic-statistics4.html#types-of-t-tests",
    "title": "6¬† basic-statistics_4",
    "section": "10.2 Types of T-Tests",
    "text": "10.2 Types of T-Tests\n\nIndependent T-Test: Compares means of two independent groups.\nPaired T-Test: Compares means of two related groups.\nOne-sample T-Test: Tests the mean from a single group against a known mean.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#performing-t-tests",
    "href": "basic-statistics4.html#performing-t-tests",
    "title": "6¬† basic-statistics_4",
    "section": "10.3 Performing T-Tests",
    "text": "10.3 Performing T-Tests\n\n10.3.1 Step-by-Step Process\n\nState the Hypotheses:\n\nH‚ÇÄ: \\(\\mu_1 = \\mu_2\\)\n\nH‚ÇÅ: \\(\\mu_1 \\neq \\mu_2\\)\n\nCalculate the T-statistic: \\[\nt = \\frac{\\bar{x_1} - \\bar{x_2}}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\]\nDegrees of Freedom: \\[\ndf = n_1 + n_2 - 2\n\\]\nFind the P-value from statistical tables or software.\nMake a Decision: If p &lt; 0.05, reject H‚ÇÄ.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#assumptions-of-the-t-test",
    "href": "basic-statistics4.html#assumptions-of-the-t-test",
    "title": "6¬† basic-statistics_4",
    "section": "10.4 Assumptions of the T-Test",
    "text": "10.4 Assumptions of the T-Test\n\nNormal distribution.\nIndependent groups (for independent T-tests).\nEqual variances.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#example-independent-t-test",
    "href": "basic-statistics4.html#example-independent-t-test",
    "title": "6¬† basic-statistics_4",
    "section": "10.5 Example: Independent T-Test",
    "text": "10.5 Example: Independent T-Test\n\n\n\nGroup\nMean\nSD\nn\n\n\n\n\nGroup A\n78\n10\n30\n\n\nGroup B\n85\n12\n30\n\n\n\nCalculation:\n\\[\nt = \\frac{78 - 85}{\\sqrt{\\frac{10^2}{30} + \\frac{12^2}{30}}} \\approx -2.53\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#t-test-in-gui-r",
    "href": "basic-statistics4.html#t-test-in-gui-r",
    "title": "6¬† basic-statistics_4",
    "section": "10.6 T-Test in GUI-R",
    "text": "10.6 T-Test in GUI-R\n\nOpen GUI-R and import your dataset.\nSelect ‚ÄòT-Test‚Äô from the menu.\nDefine groups.\nRun the test and interpret the output.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#introduction-1",
    "href": "basic-statistics4.html#introduction-1",
    "title": "6¬† basic-statistics_4",
    "section": "11.1 Introduction",
    "text": "11.1 Introduction\nANOVA compares means among 3+ groups to determine if at least one is different.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#one-way-anova",
    "href": "basic-statistics4.html#one-way-anova",
    "title": "6¬† basic-statistics_4",
    "section": "11.2 One-Way ANOVA",
    "text": "11.2 One-Way ANOVA\nInvolves one independent variable.\n\n11.2.1 Steps:\n\nHypotheses:\n\nH‚ÇÄ: All group means equal.\nH‚ÇÅ: At least one group mean is different.\n\nCalculate F-statistic:\n\n\\[\nF = \\frac{MS_{Between}}{MS_{Within}}\n\\]\n\nDegrees of Freedom:\n\n\\(df_{Between} = k - 1\\)\n\\(df_{Within} = N - k\\)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#example-table",
    "href": "basic-statistics4.html#example-table",
    "title": "6¬† basic-statistics_4",
    "section": "11.3 Example Table",
    "text": "11.3 Example Table\n\n\n\nGroup\nMean\nVariance\nn\n\n\n\n\nGroup 1\n5.5\n1.5\n30\n\n\nGroup 2\n7.1\n2.0\n30\n\n\nGroup 3\n6.8\n1.8\n30\n\n\n\n\n11.3.1 Summary Table\n\n\n\nSource\nSS\ndf\nMS\nF\n\n\n\n\nBetween Groups\n42.4\n2\n21.2\n5.24\n\n\nWithin Groups\n122.7\n87\n1.41\n\n\n\nTotal\n165.1\n89",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#anova-in-gui-r",
    "href": "basic-statistics4.html#anova-in-gui-r",
    "title": "6¬† basic-statistics_4",
    "section": "11.4 ANOVA in GUI-R",
    "text": "11.4 ANOVA in GUI-R\n\nImport data.\nChoose ANOVA.\nDefine variables.\nRun and interpret.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#concept",
    "href": "basic-statistics4.html#concept",
    "title": "6¬† basic-statistics_4",
    "section": "12.1 Concept",
    "text": "12.1 Concept\nShows likely range for population parameter.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#formula",
    "href": "basic-statistics4.html#formula",
    "title": "6¬† basic-statistics_4",
    "section": "12.2 Formula",
    "text": "12.2 Formula\n\\[\nCI = \\bar{x} \\pm Z \\cdot \\frac{s}{\\sqrt{n}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#example",
    "href": "basic-statistics4.html#example",
    "title": "6¬† basic-statistics_4",
    "section": "12.3 Example",
    "text": "12.3 Example\nSample Mean = 100, SD = 15, n = 30, Z = 1.96\n\\[\nCI = 100 \\pm 1.96 \\times \\frac{15}{\\sqrt{30}} \\approx [98.04, 101.96]\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#gui-r-overview",
    "href": "basic-statistics4.html#gui-r-overview",
    "title": "6¬† basic-statistics_4",
    "section": "13.1 GUI-R Overview",
    "text": "13.1 GUI-R Overview\nGUI-based interface for R statistical computing.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#workflow",
    "href": "basic-statistics4.html#workflow",
    "title": "6¬† basic-statistics_4",
    "section": "13.2 Workflow",
    "text": "13.2 Workflow\n\nImport Data (CSV/Excel).\nChoose Statistical Test.\nRun & Analyze Results.\nExport or visualize.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics4.html#case-studies",
    "href": "basic-statistics4.html#case-studies",
    "title": "6¬† basic-statistics_4",
    "section": "13.3 Case Studies",
    "text": "13.3 Case Studies\n\nT-Test: Compare test scores from two teaching methods.\nANOVA: Evaluate effect of 3 different drugs on recovery rate.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>basic-statistics_4</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html",
    "href": "basic-statistics5.html",
    "title": "7¬† basic-statistics_5",
    "section": "",
    "text": "7.1 1. Overview of Relationship Testing\nUnderstanding and quantifying the relationships in data is paramount in statistics. Methods like correlation and regression provide researchers with invaluable tools for analyzing interactions between variables.\nCorrelation focuses on measuring the degree of linear association between two continuous variables. Conversely, regression analysis extends this concept by allowing the prediction of one variable based on the known values of another or multiple independent variables. Researchers often utilize these methodologies not only within academic settings but also across industries including healthcare, finance, and social sciences, where such analyses guide decision-making processes.\nIn cases where the variables in question are categorical, statisticians rely on tests such as the Chi-Square test. The Chi-Square test assesses if distributions of categorical variables differ from one another, which is essential when determining relationships in categorical datasets. Thus, relationship testing via these methodologies allows for comprehensive data analysis and interpretation, which in turn aids in developing conclusions and recommendations.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html#lecture-24-introduction-to-correlation",
    "href": "basic-statistics5.html#lecture-24-introduction-to-correlation",
    "title": "7¬† basic-statistics_5",
    "section": "7.2 2. Lecture 24 ‚Äì Introduction to Correlation",
    "text": "7.2 2. Lecture 24 ‚Äì Introduction to Correlation\nIn this section, a detailed exploration of correlation begins.\n\n7.2.1 2.1 Covariance and Its Importance\nCovariance is a foundational statistic representing how two variables change together. If both variables tend to increase together, the covariance is positive. If one increases while the other decreases, the covariance is negative. However, covariance is not standardized, making it challenging to interpret across different datasets. For example, if height and weight are analyzed, a covariance of 30 might indicate a certain relationship between the two variables, but without context, it is difficult to ascertain the strength of that connection.\nThe formal mathematical representation of covariance between variables \\(X\\) and \\(Y\\) is given by:\n\\[\nCov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\n\\]\nWhere \\(n\\) is the number of data points, \\(X_i\\) and \\(Y_i\\) are the individual sample points of X and Y, and \\(\\bar{X}\\) and \\(\\bar{Y}\\) are the means of X and Y, respectively.\n\n\n7.2.2 2.2 Correlation Coefficients Explained\nCorrelation transforms the covariance into a standardized metric, the correlation coefficient, which ranges between ‚Äì1 to +1:\n\nA correlation of +1 indicates a perfect positive linear relationship.\nA correlation of -1 indicates a perfect negative linear relationship.\nA correlation of 0 indicates no linear relationship.\n\nThe most commonly used correlation coefficient is Pearson‚Äôs Correlation (r), suitable for continuous variables that are normally distributed:\n\\[\nr = \\frac{Cov(X,Y)}{SD(X) \\cdot SD(Y)}\n\\]\nWhere \\(SD(X)\\) and \\(SD(Y)\\) are the standard deviations of X and Y.\nOther coefficients, such as Spearman‚Äôs Rank Correlation and Kendall‚Äôs Tau, are used for ordinal data or when assumptions of normality are violated. Spearman‚Äôs correlation assesses monotonic relationships, which allows for discovering relationships that aren‚Äôt necessarily linear.\n\n\n7.2.3 2.3 Practical Examples Using RKWard\nBefore running the following R code examples, we define a sample dataset:\n\n\nCode\nmydata &lt;- data.frame(\n  Height = c(150, 160, 170, 180, 190),\n  Weight = c(50, 60, 70, 80, 90)\n)\n\n\nUtilizing RKWard, the process of correlating variables becomes straightforward. For instance, researchers often analyze anthropometric measurements such as height and weight. By entering the appropriate data into RKWard and generating a correlation analysis, researchers can obtain:\n\nCovariance: \\(2.57\\) (units: \\(m \\cdot kg\\)).\nCorrelation: \\(0.71\\), suggesting a strong positive relationship.\n\nSteps to perform correlation in RKWard include:\n\nInput the dataset.\nUtilize the correlation function, such as:\n::: {.cell}\n\nCode\ncor(mydata$Height, mydata$Weight)\n\n::: {.cell-output .cell-output-stdout}\n[1] 1\n::: :::\nInterpret the computed correlation coefficient.\n\n\n\n7.2.4 2.4 Visualizing Correlation Using Graphs\nVisualizations play an essential role in understanding correlations. Scatter plots allow one to visually assess relationships between variables. In RKWard, users can generate scatter plots using the following code:\n\n\nCode\nplot(mydata$Height, mydata$Weight, main=\"Height vs Weight\", xlab=\"Height (cm)\", ylab=\"Weight (kg)\")\nabline(lm(Weight ~ Height, data=mydata), col=\"blue\")\n\n\n\n\n\n\n\n\n\nThis scatter plot displays individual data points and the fitted regression line, helping to illustrate how height correlates with weight visually. By adding a regression line, one can further investigate if the relationship appears linear and the strength of that association.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html#lecture-25-uses-and-types-of-correlation",
    "href": "basic-statistics5.html#lecture-25-uses-and-types-of-correlation",
    "title": "7¬† basic-statistics_5",
    "section": "7.3 3. Lecture 25 ‚Äì Uses and Types of Correlation",
    "text": "7.3 3. Lecture 25 ‚Äì Uses and Types of Correlation\nIn expanding the utility of correlation analysis, we delve into its uses and potential pitfalls.\n\n7.3.1 3.1 Correlation vs.¬†Causation\nAs previously mentioned, while correlation can indicate a relationship between variables, it does not infer causation. A classic example is the correlation observed between ice cream sales and drowning incidents. Though both variables may increase during summer months, one does not cause the other; rather, a third variable, temperature, influences both.\nResearchers must ensure clarity when interpreting data, often utilizing controlled experiments to establish causal links. Notably, techniques such as Randomized Controlled Trials (RCTs) are crucial in establishing causation by controlling for confounding factors.\n\n\n7.3.2 3.2 Practical Applications of Correlation\nCorrelation is widely utilized across myriad fields:\n\nHealthcare: Researchers may assess relationships between dietary habits and health outcomes. For example, a study of patients‚Äô sugar intake and diabetes prevalence may reveal significant correlations, informing dietary recommendations.\nMarket Research: Businesses frequently utilize correlation to analyze customer behaviors, such as understanding the relationship between advertising spend and sales revenue.\nEducation: Correlational analyses may explore the connection between study habits and student performance across various subjects, informing educational strategies.\n\n\n\n7.3.3 3.3 Correlation in Different Fields\nTo illustrate the diversity of correlation‚Äôs applications, here are some field-specific examples:\n\n\n\n\n\n\n\nField\nExample\n\n\n\n\nPsychology\nAssessing the relationship between stress levels and academic performance.\n\n\nEconomics\nEvaluating the correlation between unemployment rates and inflation.\n\n\nSports Analytics\nAnalyzing the relationship between player statistics and game outcomes.\n\n\nEnvironmental Science\nExamining the correlation between pollution levels and public health metrics.\n\n\n\nIn all these instances, correlations can guide further research and interventions designed to enhance outcomes based on insights gathered.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html#lecture-26-linear-regression-and-model-assumptions",
    "href": "basic-statistics5.html#lecture-26-linear-regression-and-model-assumptions",
    "title": "7¬† basic-statistics_5",
    "section": "7.4 4. Lecture 26 ‚Äì Linear Regression and Model Assumptions",
    "text": "7.4 4. Lecture 26 ‚Äì Linear Regression and Model Assumptions\nThe concept of regression analysis is rooted in its power to model and predict outcomes based on independent variables.\n\n7.4.1 4.1 The Linear Model\nThe primary form of regression is simple linear regression, which describes the relationship between a single independent variable (predictor) and a dependent variable:\n\\[\ny = mx + c\n\\]\nHere, \\(m\\) signifies the slope of the line, indicating the change in \\(y\\) for every one-unit increase in \\(x\\). The constant \\(c\\) represents the y-intercept, where the line intersects the y-axis.\nExample: A researcher finds the regression equation \\(y = 3x + 2\\). This indicates that for every additional hour studied, the test score (\\(y\\)) is expected to increase by 3 points.\n\n\n7.4.2 4.2 Fitting Models in RKWard\nRKWard simplifies the process of conducting regression analysis through intuitive functionalities. The steps include:\n\nInputting Data: Users need to ensure datasets are correctly formatted.\nFitting the Model: Using the lm() function in R:\n::: {.cell}\n\nCode\nmodel &lt;- lm(Weight ~ Height, data=mydata)\n\n:::\nThis fits a linear regression model predicting Weight from Height.\nAnalyzing Model Output: The summary() function provides crucial statistics related to fits, such as coefficients and R¬≤ values:\n::: {.cell}\n\nCode\nsummary(model)\n\n::: {.cell-output .cell-output-stderr}\nWarning in summary.lm(model): essentially perfect fit: summary may be\nunreliable\n:::\n::: {.cell-output .cell-output-stdout}\n\nCall:\nlm(formula = Weight ~ Height, data = mydata)\n\nResiduals:\n         1          2          3          4          5 \n 1.254e-15 -1.133e-16 -1.267e-15 -2.143e-15  2.269e-15 \n\nCoefficients:\n              Estimate Std. Error    t value Pr(&gt;|t|)    \n(Intercept) -1.000e+02  1.120e-14 -8.929e+15   &lt;2e-16 ***\nHeight       1.000e+00  6.565e-17  1.523e+16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.076e-15 on 3 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 2.32e+32 on 1 and 3 DF,  p-value: &lt; 2.2e-16\n::: :::\nInterpreting Coefficients: The coefficient for Height tells you how much Weight is expected to change for each one-unit increase in Height, holding everything else constant.\n\n\n\n7.4.3 4.3 Assessing Model Performance\nTo assess how well the regression model fits the data, several statistics are gathered during the analysis:\n\nCoefficient of Determination (R¬≤): R¬≤ shows the proportion of variance in the dependent variable that is predictable from the independent variable(s). A higher R¬≤ value indicates a better fit.\nF-Ratio: This statistic tests the overall significance of the regression model. A significant F-ratio indicates that at least one predictor variable has a significant relationship with the dependent variable.\nP-Values: Each coefficient in the regression output is accompanied by a p-value. A p-value less than 0.05 typically indicates that the predictor is significantly related to the dependent variable.\n\nThe essential fundamentals of regression analysis also include validation of core assumptions:\n\n\n7.4.4 4.4 Common Pitfalls in Regression Analysis\nCommon pitfalls to avoid in regression analysis include:\n\nOverfitting: Developing a complex model that fits the training data too closely may fail to generalize well on test data. To counter this, simplicity in model choice is often preferred.\nMulticollinearity: High correlations among independent variables can distort regression results. Variance Inflation Factor (VIF) assessments help to diagnose multicollinearity issues.\nHomoscedasticity: The assumption that residuals have constant variance across values of the independent variable must be checked. Various graphical plots can identify deviations from this assumption.\nNormality of Residuals: The normality of residuals can be evaluated using a QQ plot or the Shapiro-Wilk test, ensuring that the data meet the normality requirement before proceeding with interpretations.\n\nVisualizing the fitted model along with residual plots, such as:\n\n\nCode\npar(mfrow=c(2,2))\nplot(model)\n\n\n\n\n\n\n\n\n\nallows one to assess these assumptions logically and adjust the approach as needed.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html#lecture-27-advanced-regression-diagnostic-tests",
    "href": "basic-statistics5.html#lecture-27-advanced-regression-diagnostic-tests",
    "title": "7¬† basic-statistics_5",
    "section": "7.5 5. Lecture 27 ‚Äì Advanced Regression & Diagnostic Tests",
    "text": "7.5 5. Lecture 27 ‚Äì Advanced Regression & Diagnostic Tests\nIn advanced regression analyses, there lies a wealth of diagnostic tests and methodologies to identify the robustness of the model trained.\n\n7.5.1 5.1 Exploring Residuals\nResiduals, the differences between observed and predicted values, are vital to understanding model performance. Analyzing these residuals helps identify patterns or systematic errors in the model‚Äôs predictions.\nThe ideal residual plot should show no discernible pattern, confirming the appropriateness of linear regression. These residuals can be plotted using:\n\n\nCode\nplot(model$residuals)\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 5.2 Common Diagnostic Tests\nTo validate linear regression assumptions, several tests are essential:\n\nDurbin-Watson Test: Tests for autocorrelation within residuals. The null hypothesis states there is no autocorrelation. A value close to 2 is desirable.\nBreusch-Pagan Test: This test assesses the homoscedasticity of residuals.\nNCV Test: This is a graphical or statistical method to evaluate non-constant variance in errors.\n\nEach of these tests provides critical insights into whether a linear regression model can be relied upon or if adjustments are necessary.\n\n\n7.5.3 5.3 Advanced Topics in Regression Analysis\nBeyond the foundational elements discussed, advanced regression topics include:\n\nMultiple Regression: An extension of simple linear regression where multiple independent variables are considered. The regression equation takes the form:\n\\[\n  y = b_0 + b_1x_1 + b_2x_2 + \\cdots + b_nx_n + \\epsilon\n  \\]\nInteraction Terms: Inclusion of interaction terms in regression models can capture the combined effect of two or more predictors. This is essential in deeper analysis when relationships are not purely linear.\nPolynomial Regression: When data exhibit a non-linear relationship, polynomial regression may be used to model these patterns adequately.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html#concepts-from-week-5-6-slides",
    "href": "basic-statistics5.html#concepts-from-week-5-6-slides",
    "title": "7¬† basic-statistics_5",
    "section": "7.6 6. Concepts from Week 5 & 6 Slides",
    "text": "7.6 6. Concepts from Week 5 & 6 Slides\n\n7.6.1 6.1 Week 5: ANOVA and Its Variants\nThe insights from ANOVA significantly complement correlation and regression analyses.\nANOVA Types:\n\nOne-Way ANOVA: Ideal for comparing means across three or more groups. It tests the hypothesis that at least one group mean is significantly different from the others. The F-value computed in ANOVA is compared against a critical value from F-distribution tables.\n\n\n\n\nSource\nSS\ndf\nMS\nF\n\n\n\n\nBetween\n461.64\n3\n153.88\n8.27\n\n\nWithin\n167.42\n9\n18.60\n\n\n\nTotal\n629.06\n12\n\n\n\n\n\n\nRepeated Measures ANOVA: This test analyzes means when repeated measurements occur for the same subjects, controlling for variability between subjects.\n\n\n\n7.6.2 6.2 Week 6: Chi-Square and Non-Parametric Tests\nChi-Square Applications:\n\nGoodness of Fit: Tests if sample data matches the expected distribution.\nTest of Independence: Determines if two categorical variables are related or independent.\n\nFor instance, a Chi-Square test might explore whether gender relates to the choice of academic major, providing insight into educational trends within populations.\nNon-Parametric Equivalents:\nThese tests come into play when data does not meet the normality assumption necessary for traditional parametric tests. Key non-parametric tests include:\n\n\n\n\n\n\n\nTest\nDescription\n\n\n\n\nMann‚ÄìWhitney\nTests differences between two independent groups.\n\n\nKruskal‚ÄìWallis\nAn extension of the Mann-Whitney test for three or more groups.\n\n\nWilcoxon Signed-Rank\nCompares two related samples.\n\n\n\nLogistic Regression: As trends in data become more complex, predicting outcomes between two categories is frequently required. For example, in financial sectors, logistic regression may predict default rates based on categorical input variables:\n\\[\np = \\frac{1}{1 + e^{-(a + bx)}}\n\\]\nwhere \\(p\\) is the probability of the outcome, determined by the independent variables included.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html#summary",
    "href": "basic-statistics5.html#summary",
    "title": "7¬† basic-statistics_5",
    "section": "7.7 7. Summary",
    "text": "7.7 7. Summary\nUltimately, understanding how to quantify and interpret the relationships between variables through correlation, regression, and Chi-Square tests is fundamental for robust statistical analysis.\n\n\n\n\n\n\n\nConcept\nDescription\n\n\n\n\nCorrelation\nMeasures association (e.g., Pearson, Spearman, Kendall)\n\n\nRegression\nPredicts a dependent variable from one or more independent variables\n\n\nChi-Square\nTests associations between categorical variables\n\n\nModel Assumptions\nInclude normality, linearity, homoscedasticity, independence\n\n\nDiagnostic Tools\nResidual plots, QQ plots, Durbin-Watson, NCV test",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics5.html#example-data-for-r-code-chunks",
    "href": "basic-statistics5.html#example-data-for-r-code-chunks",
    "title": "7¬† basic-statistics_5",
    "section": "7.8 Example Data for R Code Chunks",
    "text": "7.8 Example Data for R Code Chunks\nBefore running the following R code examples, we define a sample dataset:\n\n\nCode\nmydata &lt;- data.frame(\n  Height = c(150, 160, 170, 180, 190),\n  Weight = c(50, 60, 70, 80, 90)\n)",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>basic-statistics_5</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html",
    "href": "basic-statistics6.html",
    "title": "8¬† basic-statistics_6",
    "section": "",
    "text": "9 Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#introduction",
    "href": "basic-statistics6.html#introduction",
    "title": "8¬† basic-statistics_6",
    "section": "9.1 1. Introduction",
    "text": "9.1 1. Introduction\nStatistics is a powerful tool used to analyze and interpret data, enabling researchers and decision-makers to draw conclusions and make informed decisions based on empirical evidence. In the field of statistics, certain assumptions must be met for parametric tests to provide reliable results. These assumptions include normality (the data follows a normal distribution), linearity (the relationship between variables is linear), and homoscedasticity (constant variance among the errors). However, many real-world datasets violate these assumptions, and when this occurs, researchers must turn to alternative methods.\nThis eBook serves as a comprehensive guide to exploring three critical aspects of statistical analysis: Chi-Square Tests, Non-Parametric Alternatives, and Non-Linear Regression, including Logistic Regression. By understanding these methodologies, statisticians will be better equipped to handle complex problems that standard methods may overlook, especially when dealing with categorical data or non-linear relationships.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#chi-square-test-of-goodness-of-fit",
    "href": "basic-statistics6.html#chi-square-test-of-goodness-of-fit",
    "title": "8¬† basic-statistics_6",
    "section": "9.2 2. Chi-Square Test of Goodness of Fit",
    "text": "9.2 2. Chi-Square Test of Goodness of Fit\n\n9.2.1 Definition and Purpose\nThe Chi-Square Test of Goodness of Fit is a statistical test used to determine whether there is a significant difference between the observed frequencies in categorical data and the expected frequencies derived from a specific distribution. This test enables researchers to assess how well a sample data conforms to a theoretical distribution, such as a uniform distribution in the case of a die.\n\n\n9.2.2 Key Formula\nThe key formula used in calculating the Chi-Square statistic is:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\nWhere: - \\(O_i\\): Observed frequency for category \\(i\\). - \\(E_i\\): Expected frequency for category \\(i\\) based on a theoretical distribution.\n\n\n9.2.3 Example: Fairness of a Dice\nTo illustrate the application of the Chi-Square Goodness of Fit test, let‚Äôs consider an experiment where a six-sided die is rolled 120 times. The objective is to determine if the die is fair, meaning each face should come up approximately 20 times in the long run.\nThe observed frequency data from the experiment is as follows:\n\n\n\nFace\nObserved\nExpected (20 for each face)\n\n\n\n\n1\n9\n20\n\n\n2\n7\n20\n\n\n3\n6\n20\n\n\n4\n4\n20\n\n\n5\n3\n20\n\n\n6\n7\n20\n\n\nTotal\n36\n120\n\n\n\nCalculating the Chi-Square Statistic:\nNow we will compute the Chi-Square statistic step by step:\n\nCalculate the difference between observed and expected frequencies.\nSquare the differences.\nDivide by expected frequencies and sum the results.\n\n\\[\n\\chi^2 = \\frac{(9 - 20)^2}{20} + \\frac{(7 - 20)^2}{20} + \\ldots + \\frac{(7 - 20)^2}{20}\n\\]\n\\[\n\\chi^2 \\approx \\frac{121}{20} + \\frac{169}{20} + \\frac{196}{20} + \\frac{256}{20} + \\frac{289}{20} + \\frac{169}{20} = 2.67\n\\]\nDegrees of Freedom:\nThe degrees of freedom for the goodness of fit test is calculated as:\n\\[\ndf = n - 1\n\\]\nWhere \\(n\\) is the number of categories (faces of the die). Thus, here, \\(df = 6 - 1 = 5\\).\nComparison with Critical Values:\nUsing Chi-Square distribution tables, we find the critical value at a significance level of 0.05 for 5 degrees of freedom is approximately 11.07.\nConclusion:\nSince our calculated \\(\\chi^2 \\approx 2.67\\) is less than the critical value of 11.07, we fail to reject the null hypothesis \\(H_0\\). Therefore, there is not enough evidence to conclude that the die is unfair.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#chi-square-test-of-independence",
    "href": "basic-statistics6.html#chi-square-test-of-independence",
    "title": "8¬† basic-statistics_6",
    "section": "9.3 3. Chi-Square Test of Independence",
    "text": "9.3 3. Chi-Square Test of Independence\n\n9.3.1 Definition and Purpose\nThe Chi-Square Test of Independence assesses whether two categorical variables are independent of each other. It is particularly useful when conducting surveys or experiments to examine the relationship between variables such as gender and product preference, or age and voting behavior.\n\n\n9.3.2 Example: Gender vs.¬†Laptop Type\nSuppose researchers want to explore whether there is an association between gender (Male, Female) and preference for laptop types (Gaming, Non-Gaming). The following contingency table shows the observational data:\n\n\n\nGender\nGaming\nNon-Gaming\nTotal\n\n\n\n\nMale\n27\n8\n35\n\n\nFemale\n5\n7\n12\n\n\nTotal\n32\n15\n47\n\n\n\n\n\n9.3.3 Expected Frequencies Calculation\nTo determine if the observed frequencies differ significantly from what we would expect if the two variables were independent, we must calculate the expected frequencies. The formula for an expected frequency in the cell at row \\(i\\) and column \\(j\\) is:\n\\[\nE_{ij} = \\frac{(Row \\: Total)(Column \\: Total)}{Grand \\: Total}\n\\]\nFor example, the expected frequency for the Male-Gaming category is calculated as follows:\n\\[\nE_{Male, Gaming} = \\frac{35 \\times 32}{47} \\approx 23.83\n\\]\n\n\n9.3.4 Chi-Square Statistic Calculation\nNow, we can calculate the Chi-Square statistic:\n\nCalculate the differences between observed and expected frequencies.\nSquare the differences.\nDivide by expected frequencies and sum the results.\n\nThe Chi-Square statistic is given by:\n\\[\n\\chi^2 = \\sum \\frac{(O - E)^2}{E}\n\\]\nFor instance:\n\\[\n\\chi^2 = \\frac{(27 - 23.83)^2}{23.83} + \\frac{(8 - 11.17)^2}{11.17} + \\frac{(5 - 4.8)^2}{4.8} + \\frac{(7 - 7.2)^2}{7.2}\n\\]\nCalculating each term:\n\nFor Male-Gaming: \\(\\frac{(27 - 23.83)^2}{23.83} \\approx 0.42\\)\nFor Male-Non-Gaming: \\(\\frac{(8 - 11.17)^2}{11.17} \\approx 1.158\\)\nFor Female-Gaming: \\(\\frac{(5 - 4.8)^2}{4.8} \\approx 0.00867\\)\nFor Female-Non-Gaming: \\(\\frac{(7 - 7.2)^2}{7.2} \\approx 0.00710\\)\n\nSumming these values gives:\n\\[\n\\chi^2 \\approx 0.42 + 1.158 + 0.00867 + 0.00710 \\approx 3.64\n\\]\n\n\n9.3.5 Degrees of Freedom Calculation\nThe degrees of freedom in this case is given by:\n\\[\ndf = (rows - 1) \\times (columns - 1) = (2 - 1)(2 - 1) = 1\n\\]\nComparison with Critical Values:\nUsing the Chi-Square distribution table for 1 degree of freedom at a significance level of 0.05, the critical value is approximately 3.84.\nConclusion:\nSince our calculated \\(\\chi^2 \\approx 3.64\\) is less than the critical value of 3.84, we fail to reject the null hypothesis \\(H_0\\). Hence, there is not enough evidence to suggest that gender and laptop type preference are related.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#non-parametric-tests",
    "href": "basic-statistics6.html#non-parametric-tests",
    "title": "8¬† basic-statistics_6",
    "section": "9.4 4. Non-Parametric Tests",
    "text": "9.4 4. Non-Parametric Tests\n\n9.4.1 Definition and Importance\nNon-parametric tests are statistical methods that do not assume an underlying distribution for the data being analyzed. These tests are beneficial when dealing with ordinal data, non-normally distributed interval data, or small sample sizes. Such tests provide robustness against violations of parametric assumptions, making them versatile tools in various statistical analyses.\n\n\n9.4.2 Common Non-Parametric Tests\nHere is a list of some widely used non-parametric tests along with their parametric equivalents:\n\n\n\nParametric Test\nNon-Parametric Equivalent\n\n\n\n\nOne-sample t-test\nWilcoxon Signed-Rank Test\n\n\nTwo-sample t-test\nMann-Whitney U Test\n\n\nOne-Way ANOVA\nKruskal-Wallis Test\n\n\nTwo-Way ANOVA\nFriedman Test\n\n\nPearson Correlation\nSpearman Rank Correlation\n\n\n\n\n\n9.4.3 Implementation in RKWard\nGiven the advantages of non-parametric tests, they can be implemented easily using R. Here are some examples of how to perform non-parametric tests in R.\n\n9.4.3.1 Wilcoxon Signed-Rank Test\nwilcox.test(my.csv.data$CSE_1, mu=3.5)\n\n\n9.4.3.2 Mann-Whitney U Test\nwilcox.test(my.csv.data$GroupA, my.csv.data$GroupB)\n\n\n\n9.4.4 Example: Mann-Whitney U Test\nConsider a scenario in which we want to test whether two different teaching methods result in different student performance levels. We can use the Mann-Whitney U test (also known as the Wilcoxon rank-sum test) here.\nAssume the following data:\n\nMethod A scores: 65, 70, 78, 80\nMethod B scores: 67, 73, 75, 85\n\nLet‚Äôs conduct the Mann-Whitney U test in R:\nmethod_a_scores &lt;- c(65, 70, 78, 80)\nmethod_b_scores &lt;- c(67, 73, 75, 85)\n\nresult &lt;- wilcox.test(method_a_scores, method_b_scores, alternative = \"two.sided\")\nprint(result)\nThe output will indicate whether there is a statistically significant difference between the two methods.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#non-linear-and-logistic-regression",
    "href": "basic-statistics6.html#non-linear-and-logistic-regression",
    "title": "8¬† basic-statistics_6",
    "section": "9.5 5. Non-Linear and Logistic Regression",
    "text": "9.5 5. Non-Linear and Logistic Regression\n\n9.5.1 Non-Linear Regression\nNon-Linear Regression is an extension of the linear regression analysis technique wherein the relationship between the independent and dependent variable can be modeled by a non-linear equation. Non-linear models can accommodate more complex relationships, thus allowing for better predictions.\nExamples of non-linear equations include polynomial models, exponential growth models, and logarithmic functions:\n\nQuadratic Equation:\n\n\\[\ny = ax^2 + bx + c\n\\]\n\nExponential Growth:\n\n\\[\ny = ae^{bx}\n\\]\n\n\n9.5.2 Evaluating Non-Linear Models\nModel selection and evaluation for non-linear regressions are often guided by the \\(R^2\\) statistic, which indicates the proportion of variance explained by the model. A higher \\(R^2\\) value suggests a better fit of the model.\n\n\n9.5.3 Example: Quadratic Fit\nAssume we have a dataset capturing the relationship between the number of hours studied and exam scores:\n\n\n\nHours Studied\nExam Score\n\n\n\n\n1\n50\n\n\n2\n60\n\n\n3\n80\n\n\n4\n85\n\n\n5\n90\n\n\n\nTo fit a quadratic regression model using R:\nlibrary(stats)\n\nhrs_studied &lt;- c(1, 2, 3, 4, 5)\nexam_scores &lt;- c(50, 60, 80, 85, 90)\n\nmodel &lt;- lm(exam_scores ~ poly(hrs_studied, 2))\nsummary(model)\nInterpreting the summary will reveal coefficients associated with each term of the polynomial and also provide \\(R^2\\) for evaluating the fit of the model.\n\n\n9.5.4 Logistic Regression\nLogistic regression is a specific type of regression analysis used when the outcome variable is binary (0 or 1). Logistic regression models the probability of the occurrence of an event based on one or more predictor variables.\nThe logistic regression equation is expressed as:\n\\[\n\\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n\n\\]\nWhere: - \\(p\\): Probability of the event occurring (e.g., success). - \\(\\beta_0\\): Intercept of the model. - \\(\\beta_1, \\beta_2, \\ldots, \\beta_n\\): Coefficients of independent variables.\n\n\n9.5.5 Example: Logistic Regression\nConsider a study interested in predicting whether students will pass (1) or fail (0) based on hours studied:\n# Sample data\ndata &lt;- data.frame(hours_studied = c(1, 2, 3, 4, 5, 1, 2, 4, 5, 5),\n                   pass_fail = c(0, 0, 1, 1, 1, 0, 0, 1, 1, 1))\n\n# Logistic Regression Model\nlogistic_model &lt;- glm(pass_fail ~ hours_studied, data = data, family = binomial)\nsummary(logistic_model)\n\n\n9.5.6 Odds Ratio Interpretation\nIn logistic regression, the odds ratio expresses the change in odds for each unit change in the predictor variable.\n\\[\n\\text{Odds} = \\frac{p}{1 - p}\n\\]\nAn odds ratio greater than 1 indicates increased odds of the event occurring as the predictor increases, while an odds ratio less than 1 indicates decreased odds.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#poisson-distribution",
    "href": "basic-statistics6.html#poisson-distribution",
    "title": "8¬† basic-statistics_6",
    "section": "9.6 6. Poisson Distribution",
    "text": "9.6 6. Poisson Distribution\n\n9.6.1 Definition and Use Case\nThe Poisson distribution is a discrete probability distribution that models the number of events occurring within a fixed interval of time or space, given the events occur independently of each other. It is particularly useful for modeling rare events, such as the number of emails received in an hour or the number of accidents happening at an intersection in a day.\n\n\n9.6.2 Poisson Probability Mass Function\nThe probability of observing exactly \\(k\\) events in a given interval can be calculated using the Poisson formula:\n\\[\nP(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}\n\\]\nWhere: - \\(\\lambda\\) (lambda): The average rate of occurrence. - \\(k\\): The actual number of occurrences.\n\n\n9.6.3 Example in R\nLet‚Äôs generate random Poisson-distributed values using R:\nlambda &lt;- 2  # Average occurrence\nrandom_values &lt;- rpois(10, lambda)\nprint(random_values)\n\n# Calculate probabilities\nprob_0 &lt;- dpois(0, lambda)\nprob_5 &lt;- dpois(5, lambda)\nThis code snippet outputs random values following a Poisson distribution with an average rate of 2.\n\n\n9.6.4 Applications of Poisson Distribution\nThe Poisson distribution finds applications across various fields, including:\n\nHealthcare: Predicting the number of patients arriving at an emergency room.\nTelecommunications: Modeling incoming calls at a call center.\nTraffic Management: Estimating the average number of vehicles passing through a toll booth in an hour.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#summary",
    "href": "basic-statistics6.html#summary",
    "title": "8¬† basic-statistics_6",
    "section": "9.7 7. Summary",
    "text": "9.7 7. Summary\nThroughout this eBook, we‚Äôve delved into essential statistical methodologies and their applications. Here‚Äôs a summary of the key points addressed:\n\nChi-Square Tests: Excellent for examining categorical data, whether assessing fit against a theoretical distribution or investigating the association between two categorical variables.\nNon-Parametric Tests: Robust alternatives that do not require distributional assumptions, thus offering flexibility in data analysis, especially for ordinal data or small sample sizes.\nNon-Linear Regression: A powerful extension allowing the modeling of complex relationships using polynomial or exponential forms, enhancing predictive accuracy.\nLogistic Regression: Specifically suited for binary outcomes, logistic regression provides insights into the relationship between a binary response variable and one or more predictor variables.\nPoisson Distribution: Essential for modeling count data, particularly for rare events, allowing effective predictions in various practical scenarios.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics6.html#references",
    "href": "basic-statistics6.html#references",
    "title": "8¬† basic-statistics_6",
    "section": "9.8 8. References",
    "text": "9.8 8. References\n\nLecture Transcripts: Lectures 28‚Äì31 by Dr.¬†Harsh Pradhan, Banaras Hindu University.\nWeek 6 Slides from the course ‚ÄúBasic Statistics using GUI-R (RKWard)‚Äù.\nAdditional Statistical Resources: Various textbooks on statistical analysis and R programming.\nSoftware: R and RKWard (GUI-based interface for R).\nR Packages Used:\n\ncar: Companion to applied regression.\nvcd: Visualizing categorical data.\nperformance: Tools for assessing performance of statistical models.\ntidyverse: A collection of R packages designed for data science.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>basic-statistics_6</span>"
    ]
  },
  {
    "objectID": "basic-statistics7.html",
    "href": "basic-statistics7.html",
    "title": "9¬† basic-statistics_7",
    "section": "",
    "text": "10 üìö Table of Contents\n\nIntroduction\nTime Series Analysis\n\nOverview of Time Series Data\nComponents of Time Series\nStatistical Methods for Time Series Analysis\nR Implementation of Time Series Data\nTime Series Forecasting Techniques\nEvaluating Forecast Accuracy\n\nConditional Probability & Bayes‚Äô Theorem\n\nBasic Concepts of Probability\nBayes‚Äô Theorem and Its Applications\nApplications of Bayes‚Äô Theorem in Real Life\n\nExpected Value and Bivariate Variables\n\nExpected Value Basics\nBivariate Distributions\nCalculating Joint Probability Mass Functions\n\nDiscrete Distributions\n\nHypergeometric Distribution\nPoisson Distribution\n\nPractical Applications\n\nApplication of Bayesian Inference\nForecasting in Time Series\n\nAdvanced Statistical Concepts\n\nStationarity and Unit Root Tests\nARIMA Models\n\nSummary\nReferences\n\n\n ## 1. Introduction\nStatistics functions as the backbone for extracting meaningful insights from data. In many modern fields, including finance, healthcare, and environmental science, statistical methods are employed to make informed decisions and predictions based on observed phenomena. Courses such as Basic Statistics using GUI-R (RKWard), taught by Dr.¬†Harsh Pradhan at the Institute of Management Studies, BHU, focus on equipping students with essential statistical knowledge alongside practical skills in R programming.\nThis eBook is structured to provide a comprehensive exploration of advanced statistical concepts, focusing on Time Series Analysis, Conditional Probability, Expected Value, and Discrete Distributions while integrating practical R code snippets for implementation. Each section will delve into theory, practical applications, and advanced topics to ensure a robust understanding.\n\n ## 2. Time Series Analysis\n\n10.0.1 2.1 Overview of Time Series Data\nA time series is a sequence of data points collected or recorded at successive points in time. Time series data is crucial for analyzing trends over specific periods to support forecasting and decision-making.\n\n10.0.1.1 Key Features of Time Series Data\n\nChronological Order: The data is collected sequentially, allowing for time-based analysis.\nRegular Intervals: Observations are taken at uniform time intervals (e.g., daily, weekly, monthly).\nTemporal Context: Each data point has a specific time reference, which is essential for understanding its significance in relation to preceding and succeeding data points.\n\n\n\n\n10.0.2 2.2 Components of Time Series\nUnderstanding the distinct components of time series data helps in effectively analyzing it:\n\n\n\n\n\n\n\nComponent\nDescription\n\n\n\n\nTrend\nThe long-term progression of the series (e.g., increasing sales over the years).\n\n\nSeasonality\nRegular fluctuations occurring at specific intervals (e.g., holiday sales seasons).\n\n\nCyclic\nIrregular fluctuations occurring over longer durations that are not fixed (e.g., business cycles).\n\n\n\n\nCaution: It is crucial to differentiate between trend and seasonality as they carry different implications for analysis and forecasting. A trend may indicate a sustained increase or decrease, while seasonality reflects periodic variations.\n\n\n\n10.0.3 2.3 Statistical Methods for Time Series Analysis\nSeveral statistical methods are employed to analyze time series data effectively:\n\nSmoothing Techniques: Techniques such as moving averages and exponential smoothing help in identifying the underlying pattern by minimizing noise.\n\nSimple Moving Averages (SMA): A method of averaging to smooth out data points by creating a series of averages of different subsets of data. For example, the SMA for a given data series \\(X\\) over \\(n\\) intervals can be calculated as follows:\n\\[\nSMA = \\frac{X_1 + X_2 + X_3 + \\ldots + X_n}{n}\n\\]\nExponential Smoothing: A more sophisticated method that assigns exponentially decreasing weights to older observations.\n\nDecomposition: Breaking down a time series into trend, seasonal, and residual components provides clarity and understanding of the individual influences on the data.\nStationarity Testing: A stationary time series remains constant over time, implying uniform statistical properties.\n\nThe Augmented Dickey-Fuller (ADF) Test is a statistical test used to determine whether a unit root is present in a univariate time series. If the series is non-stationary, differencing might be required to stabilize the mean and variance.\n\n\n\n\n10.0.4 2.4 R Implementation of Time Series Data\nR provides extensive capabilities for handling time series data. The following example demonstrates how to gather stock data using the BatchGetSymbols package:\n# Install and load the required package\ninstall.packages(\"BatchGetSymbols\")\nlibrary(BatchGetSymbols)\n\n# Set the date range for fetching stock prices\nfirst.date &lt;- Sys.Date() - 90  # Data for the past 90 days\nlast.date &lt;- Sys.Date()\nstocks &lt;- c(\"AAPL\", \"GOOG\", \"AMZN\")  # Example stock tickers\n\n# Fetch stock prices\nstock_data &lt;- BatchGetSymbols(tickers = stocks, first.date = first.date, last.date = last.date)\n\n# Save the data to a CSV for future use\nwrite.csv(stock_data$data, \"stock_prices.csv\")\n\n\n10.0.5 2.5 Time Series Forecasting Techniques\nForecasting methods extend beyond basic trend analysis to project future values based on historical data.\n\nNaive Approach: This method suggests that the future value is equal to the latest observed value. It is simple yet can be effective in stable environments.\nARIMA Models: Autoregressive Integrated Moving Average (ARIMA) models are widely used for forecasting in time series analysis. ARIMA models combine autoregression (AR), differencing (I), and moving averages (MA) to model complex data patterns.\n\nIdentifying the Model: The identification of the appropriate ARIMA model is done using ACF (Autocorrelation Function) and PACF (Partial Autocorrelation Function) plots.\n\nExponential Smoothing State Space Model (ETS): This class of forecasting methods accommodates level, trend, and seasonal components, adapting automatically to changes in the data structure.\n\n\n\n10.0.6 2.6 Evaluating Forecast Accuracy\nEvaluating the accuracy of forecasting models is paramount. Common metrics include:\n\nMean Absolute Error (MAE): Measures the average magnitude of errors in a set of forecasts, without considering their direction.\n\\[\nMAE = \\frac{1}{n} \\sum_{i=1}^n |F_i - A_i|\n\\]\nRoot Mean Square Error (RMSE): Measures the square root of the average of squared differences between forecasted and actual values.\n\\[\nRMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (F_i - A_i)^2}\n\\]\nMean Absolute Percentage Error (MAPE): Measures the accuracy as a percentage.\n\\[\nMAPE = \\frac{100}{n} \\sum_{i=1}^n \\left| \\frac{F_i - A_i}{A_i} \\right|\n\\]\n\nThese metrics foster an understanding of model performance and provide essential insights for model adjustments.\n\n ## 3. Conditional Probability & Bayes‚Äô Theorem\n\n\n10.0.7 3.1 Basic Concepts of Probability\nProbability quantifies how likely an event is to occur, yielding values between 0 (impossible event) and 1 (certain event). Key concepts include:\n\nEvent: A specific outcome or combination of outcomes from a random process.\nSample Space: The set of all possible outcomes of a random experiment.\n\nConditional Probability defines the probability of an event \\(A\\) occurring given that event \\(B\\) has already occurred.\nFormula:\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\n\n\n10.0.8 3.2 Bayes‚Äô Theorem and Its Applications\nBayes‚Äô Theorem connects conditional probabilities, allowing the updating of beliefs upon receiving new evidence. The theorem can be expressed as:\n\\[\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\]\n\n\n\nTerm\nMeaning\n\n\n\n\n\\(P(A|B)\\)\nThe posterior probability\n\n\n\\(P(B|A)\\)\nThe likelihood\n\n\n\\(P(A)\\)\nThe prior probability\n\n\n\\(P(B)\\)\nThe marginal likelihood\n\n\n\nThis theorem is instrumental in diverse fields, empowering individuals to make informed predictions about uncertain situations based on prior knowledge and new information.\n\n\n10.0.9 3.3 Applications of Bayes‚Äô Theorem in Real Life\n\nMedical Diagnosis: In healthcare, Bayes‚Äô Theorem is utilized to assess the probability of a disease a patient has based on test results.\n\nBefore a diagnosis, a doctor may have a prior probability of a patient‚Äôs disease, which updates as the doctor considers the test results.\n\nSpam Filtering: Email services employ Bayesian filters to categorize emails as spam or not spam by calculating probabilities based on various features of known spam messages.\n\nAs new types of spam are encountered, the spam filter dynamically updates its rules, improving accuracy.\n\nRisk Assessment in Finance: Investors can assess the probability of a stock‚Äôs performance based on prior market trends and current economic signals, supporting better decision-making.\n\n\n ## 4. Expected Value and Bivariate Variables\n\n\n10.0.10 4.1 Expected Value Basics\nThe Expected Value (EV) of a random variable quantifies what one can expect to obtain on average over many repetitions of a random experiment.\nFor a discrete random variable \\(X\\) with potential values \\(x_i\\) and corresponding probabilities \\(P(x_i)\\):\n\\[\nE(X) = \\sum_{i=1}^n x_i \\cdot P(x_i)\n\\]\n\n10.0.10.1 Properties of Expected Value:\n\nLinearity of Expectation: If \\(Y = aX + b\\), where \\(a\\) and \\(b\\) are constants, the expected value can be expressed as:\n\\[\nE(Y) = aE(X) + b\n\\]\nExpectation of a Constant: The expected value of a constant is simply the constant itself; for example, \\(E(c) = c\\).\n\n\n\n\n10.0.11 4.2 Bivariate Distributions\nExploring two random variables together involves constructing a Joint Probability Distribution and understanding their relationship through the Joint Probability Mass Function (JPMF):\n\\[\nP(X = x, Y = y)\n\\]\n\n10.0.11.1 Calculating Joint Probability Mass Functions\nTo calculate the joint distribution, one can utilize contingency tables that highlight the relationships and frequencies between two variables.\n\n\n\n\\(X \\backslash Y\\)\n0\n1\n2\n3\n\n\n\n\n0\n1/8\n0\n0\n0\n\n\n1\n0\n3/8\n0\n0\n\n\n2\n0\n0\n3/8\n0\n\n\n3\n0\n0\n0\n1/8\n\n\n\nThis table can help compute probabilities associated with specific combinations of events, allowing deeper insights into their interdependence.\n\n ## 5. Discrete Distributions\n\n\n\n10.0.12 5.1 Hypergeometric Distribution\nWhen samples are drawn from a finite population without replacement, the hypergeometric distribution describes the probability of observing a specific number of successes in the sample.\nThe formula for the hypergeometric distribution is expressed as:\n\\[\nP(X = k) = \\frac{\\binom{K}{k} \\cdot \\binom{N-K}{n-k}}{\\binom{N}{n}}\n\\]\nWhere: - \\(N\\) = total size of the population - \\(K\\) = total number of successes in the population - \\(n\\) = number of draws - \\(k\\) = number of observed successes\n\n10.0.12.1 Example Application\nConsider drawing cards from a deck of 52 cards where 12 are face cards:\nSuppose you draw 5 cards without replacement, and want to find the probability of drawing exactly 2 face cards.\n\n\n\n10.0.13 5.2 Poisson Distribution\nThe Poisson distribution is useful for modeling the number of events that occur in a fixed interval of time or space when these events happen independently of one another.\n\n10.0.13.1 Probability Mass Function\nThe probability of observing \\(k\\) events in a fixed interval can be described as:\n\\[\nP(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}\n\\]\nWhere: - \\(\\lambda\\) is the average rate (mean number of events) - \\(k\\) is the actual number of events - \\(e\\) is Euler‚Äôs number (approximately 2.718)\n\n\n10.0.13.2 Practical Example in R\nTo calculate the probability of seeing 3 arrivals in a system during a 10-minute interval when the average arrival rate is 2:\nlambda &lt;- 2\nk &lt;- 3\nprobability &lt;- dpois(k, lambda)\nprint(probability)  # Outputs the probability of 3 events\nThe Poisson distribution is crucial in various fields such as telecommunications, traffic flow analysis, and service operations, as it assists in predicting and managing occurrences effectively.\n\n ## 6. Practical Applications\n\n\n\n10.0.14 6.1 Application of Bayesian Inference\nBayesian inference is pivotal in domains that require integration of prior knowledge with observed data. It is widely applied in:\n\nHealthcare: Assessing new treatment methods‚Äô effectiveness by updating beliefs based on clinical trial data.\nMarketing: Personalizing customer experiences by predicting behavior from previous interactions.\n\n\n\n10.0.15 6.2 Forecasting in Time Series\nForecasting is essential for planning and strategic decision-making in various sectors:\n\nFinance: Investors predict stock prices based on historical trends to determine buy/sell decisions.\nInventory Management: Businesses use historical sales data to manage stock levels, optimizing costs and meeting demand.\nWeather Prediction: Meteorological data is analyzed to forecast weather patterns and help in disaster preparedness.\n\n\n ## 7. Advanced Statistical Concepts\n\n\n10.0.16 7.1 Stationarity and Unit Root Tests\nStationarity is a fundamental concept in time series analysis. A stationary time series exhibits constant mean and variance over time, essential for reliable forecasting. The Augmented Dickey-Fuller (ADF) test is employed to assess stationarity:\n\nNull Hypothesis: The time series has a unit root (is non-stationary).\nAlternative Hypothesis: The time series does not have a unit root (is stationary).\n\nA low p-value (typically &lt; 0.05) indicates rejection of the null hypothesis, suggesting stationarity in the data.\n\n\n10.0.17 7.2 ARIMA Models\nARIMA models provide a robust framework for time series forecasting by incorporating autoregressive and moving average components alongside differencing.\n\nModel Identification: Use ACF and PACF plots to identify appropriate parameters for ARIMA models.\nEstimation and Fitting: Fit the ARIMA model using maximum likelihood estimation for optimal parameters.\nDiagnosis: Evaluate residuals to ensure no patterns remain, validating the model‚Äôs appropriateness.\nForecasting: Use fitted ARIMA models to generate future projections, providing confidence intervals for predictions.\n\n\n ## 8. Summary\nThis eBook provides an in-depth exploration of key concepts in advanced statistics, bridging theoretical understanding with practical applications in time series analysis, probability theory, and discrete distributions. Major topics include:\n\nTime Series Analysis: Grasping trends, seasonality, advanced forecasting methods, and model evaluation techniques.\nBayesian Probability: Gaining insights from past events affecting future predictions.\nExpected Value & Discrete Distributions: Emphasizing the underlying importance of random processes in qualitative decision-making.\nReal-world Applications: Highlighting the roles of these statistical methods in diverse fields ranging from finance to healthcare.\n\nThrough integration of theory and practical R programming examples, this resource aims to equip readers with a comprehensive toolkit for addressing complex statistical challenges in varied contexts.\n\n ## 9. References\n\nHarsh Pradhan, Lecture Transcripts (32‚Äì36), Basic Statistics using GUI-R (RKWard), Institute of Management Studies, BHU.\nWeek 7 Lecture Slides ‚Äì Introduction to Time Series Analysis & Probability Concepts\nBook Source: Chapter 16 - Introduction to Time Series Analysis, SAGE Publications.\nR Documentation: BatchGetSymbols, TSA Package.\n\n\nThis eBook serves as a detailed guide for learners and practitioners in statistics, catering specifically to those seeking to deepen their understanding of statistical theory, methodologies, and applications in R. The inclusion of various statistical measures, R code snippets, and practical examples supports the reader‚Äôs journey toward mastering these advanced statistical concepts.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>basic-statistics_7</span>"
    ]
  }
]