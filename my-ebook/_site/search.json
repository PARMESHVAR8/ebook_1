[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "my-ebook",
    "section": "",
    "text": "0.1 Lecture notes\nIntroduction\nDR.Harsh Pradhan, [Phone: +91-9930034241 , Email: harsh.231284@gmail.com], Institute of Management Studies, Banaras Hindu University, Address: 18-GF, Jaipuria Enclave, Kaushambhi, Ghaziabad, India, 2010\nInterest: Goal Orientation Job Performance Consumer Behavior Behavioral Finance Bibiliometric Analysis Options as Derivatives Statistics Indian Knowledge System,\nOrcid ID\nGoogle Scholar\nYoutube ID\nAcademic Profile\nCourses offered:\nDownload from here.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#moodle-website",
    "href": "index.html#moodle-website",
    "title": "my-ebook",
    "section": "0.2 Moodle website",
    "text": "0.2 Moodle website\nAll communications with students in Potsdam will be done through this website. # üìò Schedule\n\n\n\nWeek\nLecture\nMain Topic\nSubtopic\nüé• Video\nüìÑ PDF Resource\n\n\n\n\nWeek 2\n1\nDescriptive Statistics\nCentral Tendency\nVideo\nWeek 2.pdf\n\n\n\n2\nDescriptive Statistics\nMeasure of Variability\nVideo\nSame as above\n\n\n\n3\nDescriptive Statistics\nDescribing Data\nVideo\nSame as above\n\n\n\n4\nDescriptive Statistics\nProbability\nVideo\nSame as above\n\n\n\n5\nDescriptive Statistics\nDistribution\nVideo\nSame as above\n\n\nWeek 3\n1\nDescriptive Statistics\nZ Table (Normal Distribution)\nVideo\nWeek 3.pdf\n\n\n\n2\nDescriptive Statistics\nMeasuring Divergence\nVideo\nSame as above\n\n\n\n3\nInferential Statistics\nSample and Population\nVideo\nSame as above\n\n\n\n4\nInferential Statistics\nModel Fit\nVideo\nSame as above\n\n\n\n5\nInferential Statistics\nHypothesis and Error\nVideo\nSame as above\n\n\nWeek 4\n1\nTerms of Statistics\nTerms of Statistics\nVideo\nWeek 4.pdf\n\n\n\n2\nTerms of Statistics\nT-Test\nVideo\nSame as above\n\n\n\n3\nTerms of Statistics\nT-Test in Detail\nVideo\nSame as above\n\n\n\n4\nANOVA\nANOVA\nVideo\nSame as above\n\n\nWeek 5\n1\nANOVA\nExample of ANOVA\nVideo\nWeek 5.pdf\n\n\n\n2\nANOVA\nTypes of ANOVA\nVideo\nSame as above\n\n\n\n3\nCorrelation\nIntroduction to Correlation\nVideo\nSame as above\n\n\n\n4\nCorrelation\nRegression (Part 1)\nVideo\nSame as above\n\n\n\n5\nCorrelation\nRegression (Part 2)\nVideo\nSame as above\n\n\nWeek 6\n1\nCorrelation\nR Script for Regression\nVideo\nWeek 6.pdf\n\n\n\n2\nChi Square\nChi Square\nVideo\nSame as above\n\n\n\n3\nChi Square\nChi Square Test\nVideo\nSame as above\n\n\n\n4\nLogistic Function\nRegression Function\nVideo\nSame as above\n\n\n\n5\nLogistic Function\nDistribution\nVideo\nSame as above\n\n\nWeek 7\n1\nTime Series\nIntro to Time Series\nVideo\nWeek 7.pdf\n\n\n\n2\nTime Series\nConditional Probability\nVideo\nSame as above\n\n\n\n3\nTime Series\nAdditional Concepts\nVideo\nSame as above\n\n\n\n4\nTime Series\nDistribution\nVideo\nSame as above\n\n\n\n5\nTime Series\nPoisson Distribution\nVideo\nSame as above\n\n\n\n6\nIndex Numbers\nPrice & Quantity Index\nVideo\nSame as above\n\n\n\n7\nDecision Environments\nRisk/Uncertainty, Bayes, Trees\nVideo\nSame as above\n\n\n\n8\nTime Series Analysis\nComponents, Trend, Seasonality\nVideo\nSame as above\n\n\n\n9\nTime Series Analysis\nLeast Squares Method\nVideo\nSame as above\n\n\nWeek 8\n1\nEffect Size & Documentation\nPackage/Library\nVideo\nWeek 8.pdf\n\n\n\n2\nEffect Size & Documentation\nRStudio vs RKward\nVideo\nSame as above\n\n\n\n3\nEffect Size & Documentation\nFlexplot\nVideo\nSame as above\n\n\n\n4\nEffect Size & Documentation\nFunctions\nVideo\nSame as above\n\n\n\n5\nEffect Size & Documentation\nR Shiny & R Markdown\nVideo\nSame as above\n\n\n\n6\nEffect Size & Documentation\nApplication with Real Datasets\nVideo\nSame as above\n\n\n\n7\nEffect Size & Interpretation\nImportance in Testing\nVideo\nSame as above\n\n\n\n8\nEffect Size & Interpretation\nInstalling dplyr, ggplot2\nVideo\nSame as above\n\n\n\n9\nEffect Size & Interpretation\nVisual Model Interpretation\nVideo\nSame as above\n\n\n\n10\nEffect Size & Interpretation\nCreating/Using Functions\nVideo\nSame as above\n\n\n\n11\nEffect Size & Interpretation\nReport, Dashboard, Interactivity\nVideo\nSame as above",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "2¬† Week 1",
    "section": "",
    "text": "2.1 Module 1: Introduction to Statistics",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#module-1-introduction-to-statistics",
    "href": "week1.html#module-1-introduction-to-statistics",
    "title": "2¬† Week 1",
    "section": "",
    "text": "2.1.1 Pre-Requisites\n\nJust an open and eager mind\nBasic understanding of Mathematics or Statistics\n\n\n\n2.1.2 Agenda\n\nMeaning of Statistics\nNature and Scope\nUses of Statistics\nLimitations\nFallacies and Misuse\nMath vs Statistics\nGUI Tools & Transition to Software-based Stats\n\n\n\n\n2.1.3 Meaning of Statistics\nStatistics is a science which provides tools for analysis and interpretation of raw data collected for decision-making in diverse fields.\nIt includes four core concepts:\n\nPopulation ‚Äì Complete data or total group\nSample ‚Äì Subset of population\nParameter ‚Äì Numerical summary from population\nStatistic ‚Äì Numerical summary from sample\n\n\n\n2.1.4 Nature of Statistics\n\nDeals with numerical facts\nFocused on social phenomena and real-world data\nOrganizes, classifies, and analyzes data\nFacilitates prediction, interpretation, and decision-making\n\n\n\n\n2.1.5 Uses of Statistics\n\nDrawing representative samples\nSummarizing collected data\nTabulation and systematic arrangement\nGroup comparisons\nDetermining behavioral relationships\nEstimating chance vs causation\nApplication in:\n\nPsychology\nEducation\nEmployment surveys\nMarket Research\nIndustrial and Organizational studies\n\n\n\n\n2.1.6 Limitations of Statistics\n\nCannot study qualitative phenomena without quantification\nNot applicable to individuals\nStatistical laws are not exact\nDoes not guarantee causal relationships\nVulnerable to misuse",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#misuse-of-statistics",
    "href": "week1.html#misuse-of-statistics",
    "title": "2¬† Week 1",
    "section": "2.2 Misuse of Statistics",
    "text": "2.2 Misuse of Statistics\n\nUse of extremely small or biased samples\nMisleading graphs or visual misrepresentation\nIllogical or unexpected comparisons\n\nFallacies in Statistics\nFallacies may arise from:\n\nPoor data collection methods\nVague or manipulated term definitions\nImproper unit selection\nFaulty classification or grouping\nInappropriate statistical methods",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#module-2-mathematics-vs-statistics",
    "href": "week1.html#module-2-mathematics-vs-statistics",
    "title": "2¬† Week 1",
    "section": "2.3 Module 2: Mathematics vs Statistics",
    "text": "2.3 Module 2: Mathematics vs Statistics\n\n\n\n\n\n\n\n\nAspect\nMathematics\nStatistics\n\n\n\n\nNature\nAbstract, symbolic reasoning\nApplied, data-based reasoning\n\n\nFocus\nPure logic, proofs\nReal-world data, decision-making\n\n\nTechniques\nAlgebra, Calculus, Geometry\nProbability, Hypothesis testing, Regression\n\n\nOutput\nTheorems, functions, formulas\nInferences, predictions, summaries\n\n\nTools\nEquations, graphs\nCharts, tables, models",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#module-3-software-based-statistical-revolution",
    "href": "week1.html#module-3-software-based-statistical-revolution",
    "title": "2¬† Week 1",
    "section": "2.4 Module 3: Software-Based Statistical Revolution",
    "text": "2.4 Module 3: Software-Based Statistical Revolution\n### From Paper to Code\nWhy shift to software?\n\nFaster analysis of massive data\nError-free calculations\nAnywhere-anytime access\nCloud-based integration\nSupports ML/AI, automation, and deep visualization\n\n\n2.4.1 Popular Statistical Software\n\n\n\n\n\n\n\n\nSoftware\nType\nUse Case\n\n\n\n\nR\nScript\nCore for academic and professional stats\n\n\nRKWard\nGUI\nGUI wrapper for R\n\n\nR Commander\nGUI\nMenu-based GUI for R\n\n\nRattle\nGUI\nData mining toolkit in R\n\n\nExcel\nGUI\nBasic stats with plugins\n\n\nPython (pandas)\nScript\nModern data science + ML\n\n\n\n\n\n2.4.2 GUI vs CLI\n\n\n\n\n\n\n\n\nFeature\nGUI (e.g., RKWard)\nCommand Line (e.g., R Console)\n\n\n\n\nAccessibility\nUser-friendly\nRequires learning syntax\n\n\nSpeed\nSlower for heavy tasks\nHigh performance\n\n\nLearning Curve\nMinimal\nModerate to High\n\n\nCustomization\nLimited\nFully scriptable\n\n\nTeaching Utility\nGood for beginners\nGood for understanding logic\n\n\n\n\n\n2.4.3 Recommended GUI Tools for R\n\nRKWard\nRattle\nR Commander\nR AnalyticFlow\n\n\nüîó https://rkward.kde.org\n\n\n\n2.4.4 Installing RKWard on Ubuntu\nbash sudo apt install kbibtex kate libcurl4-openssl-dev libssl-dev libxml2-dev cmake sudo add-apt-repository ppa:rkward-devel/rkward-stable echo ‚Äúdeb https://ppa.launchpad.net/rkward-devel/rkward-stable/ubuntu jammy main‚Äù | sudo tee /etc/apt/sources.list.d/rkward.list sudo apt update sudo apt-get install rkward Awesome. Here‚Äôs Part 2 of the full markdown, Lines 251‚Äì600, continuing the structured content from your Week 1 lecture.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#module-4-understanding-variables",
    "href": "week1.html#module-4-understanding-variables",
    "title": "2¬† Week 1",
    "section": "2.5 Module 4: Understanding Variables",
    "text": "2.5 Module 4: Understanding Variables\n\n2.5.1 What is a Variable?\nA variable is a characteristic or attribute that can assume different values across individuals or items.\nIn statistics, variables are categorized for analysis and measurement.\n\n\n2.5.2 R Definition:\nIn R, variables are containers for data, created by assignment:\n```r x &lt;- 10 name &lt;- ‚ÄúHarsh‚Äù flag &lt;- TRUE\nClassification of Variables\nA. Qualitative (Categorical)\nType Description Example\nNominal Categories without order Gender (Male, Female) Ordinal Categories with a meaningful order Education Level (UG, PG)\nB. Quantitative (Numerical)\nType Description Example\nDiscrete Countable numbers No.¬†of students Continuous Infinite values in a range Height, Weight\nStatistical Data Types (Scale of Measurement)\nData Type Description Examples\nNominal Categories with no order Blood group (A, B, AB, O) Ordinal Ranked categories Satisfaction (Low, Med, High) Interval Numeric scale with no true zero Temperature in Celsius Ratio Numeric scale with true zero Income, Weight, Age\nData Types in R\nR Type Description Example Code\nNumeric Real numbers x &lt;- 15.3 Integer Whole numbers y &lt;- as.integer(10) Complex Real + imaginary z &lt;- 2+3i Character Text strings c &lt;- ‚Äúhello‚Äù Logical Boolean values b &lt;- TRUE Factor Categorical encoding factor(c(‚Äúyes‚Äù, ‚Äúno‚Äù, ‚Äúyes‚Äù))",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#utilizing-statistical-methods-for-decision-making",
    "href": "week1.html#utilizing-statistical-methods-for-decision-making",
    "title": "2¬† Week 1",
    "section": "5.1 Utilizing Statistical Methods for Decision Making",
    "text": "5.1 Utilizing Statistical Methods for Decision Making\n\nUse statistical evidence to guide business strategies.\nMake informed policy decisions based on empirical data.\nReport findings clearly for transparency and comprehension.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "2¬† Week 1",
    "section": "5.2 Summary",
    "text": "5.2 Summary\nThe ‚ÄúBasic Statistics Using GUI-R (RK Ward)‚Äù course equips learners with the foundational and practical skills needed for statistical analysis using R. Students will understand theoretical concepts, grasp practical applications, and use RKWard effectively to analyze real-world data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#key-takeaways",
    "href": "week1.html#key-takeaways",
    "title": "2¬† Week 1",
    "section": "5.3 Key Takeaways",
    "text": "5.3 Key Takeaways\n\nProficiency in defining and using variables and data types.\nCapability to import and manipulate data in RKWard.\nUnderstanding of basic statistical practices and their applications.\nSkill in visualizing data for effective communication of results.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week1.html#websites",
    "href": "week1.html#websites",
    "title": "2¬† Week 1",
    "section": "5.4 Websites",
    "text": "5.4 Websites\nhttps://rkward.kde.org https://r4stats.com https://cran.r-project.org",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "3¬† Week 2",
    "section": "",
    "text": "3.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#introduction",
    "href": "week2.html#introduction",
    "title": "3¬† Week 2",
    "section": "",
    "text": "3.1.1 Purpose of the eBook\nThis eBook is designed as a complete beginner-to-intermediate guide for understanding the foundational concepts of statistics. It aims to bridge theoretical knowledge and practical application using RKWard (a GUI for R). Readers will be introduced to descriptive and inferential statistics, probability theory, and probability distributions with ample examples and exercises.\n\n\n3.1.2 Who Should Read This?\n\nUndergraduate students\nMBA and management students\nData analysis beginners\nProfessionals dealing with data\n\n\n\n3.1.3 What You‚Äôll Learn\n\nData classification and types\nDescriptive statistics: central tendency and variability\nBasic probability and events\nProbability distributions: Bernoulli, Binomial, and Normal\nUse of RKWard in statistical analysis",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#fundamentals-of-statistics",
    "href": "week2.html#fundamentals-of-statistics",
    "title": "3¬† Week 2",
    "section": "3.2 1. Fundamentals of Statistics",
    "text": "3.2 1. Fundamentals of Statistics\n\n3.2.1 1.1 What is Statistics?\nStatistics is the science of collecting, organizing, analyzing, and interpreting data to make informed decisions. It involves both theoretical (mathematical) and applied approaches to understanding uncertainty and variability in real-world phenomena.\n\n\n3.2.2 1.2 Key Objectives\n\nSummarizing large datasets effectively\nEstimating population parameters\nTesting hypotheses\nMaking predictions and decisions under uncertainty\n\n\n\n3.2.3 1.3 Types of Statistics\n\nDescriptive Statistics: Deals with the presentation and summarization of data.\nInferential Statistics: Draws conclusions about populations based on sample data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#types-of-data",
    "href": "week2.html#types-of-data",
    "title": "3¬† Week 2",
    "section": "3.3 2. Types of Data",
    "text": "3.3 2. Types of Data\n\n3.3.1 2.1 Classification of Data\n\n\n\n\n\n\n\n\nType\nExample\nDescription\n\n\n\n\nQualitative\nGender, Nationality\nNon-numeric labels\n\n\nQuantitative\nHeight, Age\nNumeric values\n\n\nDiscrete\nNo.¬†of Children\nCountable numbers\n\n\nContinuous\nTemperature, Weight\nInfinite values in a range\n\n\n\n\n3.3.1.1 Qualitative (Categorical) Data\n\nNominal: No inherent order (e.g., religion, marital status).\nOrdinal: Natural order (e.g., customer satisfaction: Poor, Average, Good).\n\n\n\n3.3.1.2 Quantitative (Numerical) Data\n\nDiscrete: Integers; e.g., number of books.\nContinuous: Measurable; e.g., weight in kilograms.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#descriptive-statistics",
    "href": "week2.html#descriptive-statistics",
    "title": "3¬† Week 2",
    "section": "3.4 3. Descriptive Statistics",
    "text": "3.4 3. Descriptive Statistics\n\n3.4.1 3.1 Measures of Central Tendency\n\n3.4.1.1 What is Central Tendency?\nCentral tendency refers to the center or middle of a dataset. It‚Äôs the value that best represents the entire distribution.\n\n\n3.4.1.2 Characteristics of a Good Measure\n\nRigidly defined\nEasy to understand\nTakes all data into account\nAmenable to algebraic treatment\nStable under sampling\nMinimally affected by outliers (except mean)\n\n\n\n\n\n3.4.2 3.2 The Mean\n\n3.4.2.1 Definition\nThe arithmetic mean is the sum of all values divided by the number of values.\n\n\n3.4.2.2 Formula\n\\[\n\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n\\]\n\n\n3.4.2.3 Properties of Mean\n\nUses all data values\nAffected by extreme values\nThe sum of deviations from the mean is zero\n\n\n\n3.4.2.4 Example\nData: 10, 15, 20, 25, 30\nMean = \\((10 + 15 + 20 + 25 + 30)/5 = 20\\)\n\n\n\n\n3.4.3 3.3 The Median\n\n3.4.3.1 Definition\nThe median is the value separating the higher half from the lower half of a data sample.\n\n\n3.4.3.2 Calculation\n\nOdd number of items: Middle value\nEven number of items: Average of the two middle values\n\n\n\n3.4.3.3 Properties\n\nNot influenced by extreme values\nBest for skewed data\n\n\n\n3.4.3.4 Example\nData: 4, 6, 9, 12, 15, 21, 33\nMedian = 12 (middle value)\n\n\n\n\n3.4.4 3.4 The Mode\n\n3.4.4.1 Definition\nThe mode is the value that appears most frequently in a dataset.\n\n\n3.4.4.2 Characteristics\n\nCan be used for categorical data\nDataset can be unimodal, bimodal, or multimodal\nMay not exist if all values are unique\n\n\n\n3.4.4.3 Example\nData: 4, 4, 6, 8, 9, 10, 4\nMode = 4\n\n\n\n\n3.4.5 3.5 Comparison Table\n\n\n\n\n\n\n\n\n\nMeasure\nUse Case\nAffected by Outliers\nMathematical Use\n\n\n\n\nMean\nSymmetric distributions\nYes\nHigh\n\n\nMedian\nSkewed distributions\nNo\nModerate\n\n\nMode\nCategorical variables\nNo\nLow",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#measures-of-variability",
    "href": "week2.html#measures-of-variability",
    "title": "3¬† Week 2",
    "section": "3.5 4. Measures of Variability",
    "text": "3.5 4. Measures of Variability\n\n3.5.1 4.1 Why Measure Variability?\nWhile central tendency summarizes data, variability tells us how spread out the data is. It‚Äôs essential in determining consistency and reliability.\n\n\n\n3.5.2 4.2 Range\n\n3.5.2.1 Definition\nThe difference between the maximum and minimum values.\n\\[\n\\text{Range} = x_{\\text{max}} - x_{\\text{min}}\n\\]\n\n\n3.5.2.2 Example\nData: 12, 14, 17, 19, 23\nRange = 23 - 12 = 11\n\n\n3.5.2.3 Limitations\n\nIgnores distribution shape\nExtremely sensitive to outliers\n\n\n\n\n\n3.5.3 4.3 Quartiles and Interquartile Range\n\n3.5.3.1 Quartiles\n\nQ1 (25th percentile): Lower quartile\nQ2 (50th percentile): Median\nQ3 (75th percentile): Upper quartile\n\n\n\n3.5.3.2 Formula for Position\n\\[\nQ_k = \\frac{k(n+1)}{4}\n\\]\n\n\n3.5.3.3 IQR Formula\n\\[\nIQR = Q3 - Q1\n\\]\n\n\n3.5.3.4 Example\nData: 12, 30, 45, 57, 70\nQ1 = 30, Q3 = 57 ‚Üí IQR = 27\n\n\n\n\n3.5.4 4.4 Variance\n\n3.5.4.1 Concept\nVariance is the average of the squared differences from the Mean.\n\n\n3.5.4.2 Formulas\nPopulation Variance:\n\\[\n\\sigma^2 = \\frac{1}{N} \\sum (x_i - \\mu)^2\n\\]\nSample Variance:\n\\[\ns^2 = \\frac{1}{n-1} \\sum (x_i - \\bar{x})^2\n\\]\n\n\n\n\n3.5.5 4.5 Standard Deviation\n\n3.5.5.1 Concept\nStandard deviation is the square root of variance. It provides a measure of spread in the same units as the data.\n\\[\ns = \\sqrt{s^2}\n\\]\n\n\n3.5.5.2 Properties\n\nSame unit as original data\nMeasures how far values deviate from the mean\nWidely used in most statistical computations\n\n\n\n\n\n3.5.6 4.6 Coefficient of Variation (CV)\n\n3.5.6.1 Definition\nThe ratio of the standard deviation to the mean, expressed as a percentage. Used to compare variability between datasets with different units.\n\\[\nCV = \\left( \\frac{s}{\\bar{x}} \\right) \\times 100\\%\n\\]\n\n\n3.5.6.2 Example\nDataset A: Mean = 100, SD = 10 ‚Üí CV = 10%\nDataset B: Mean = 50, SD = 5 ‚Üí CV = 10%\n\n\n\n\n3.5.7 4.7 Moment-Based Measures\n\nFirst Moment (about mean): 0 (since \\(\\sum (x - \\bar{x}) = 0\\))\nSecond Moment: Variance\nThird Moment: Skewness\nFourth Moment: Kurtosis",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#probability-fundamentals",
    "href": "week2.html#probability-fundamentals",
    "title": "3¬† Week 2",
    "section": "3.6 5. Probability Fundamentals",
    "text": "3.6 5. Probability Fundamentals\n\n3.6.1 5.1 Introduction to Probability\nProbability is the mathematical framework for quantifying uncertainty. It helps us estimate how likely an event is to occur.\n\n\n3.6.2 5.2 Key Definitions\n\nExperiment: A process that leads to an outcome.\nOutcome: The result of an experiment.\nSample Space (Œ©): All possible outcomes.\nEvent: A subset of the sample space.\n\n\n\n\n3.6.3 5.3 Types of Events\n\n\n\n\n\n\n\nEvent Type\nDescription\n\n\n\n\nIndependent\nOccurrence of one does not affect the other\n\n\nDependent\nOne affects the outcome of another\n\n\nMutually Exclusive\nCannot occur together\n\n\nExhaustive\nIncludes all possible outcomes\n\n\n\n\n\n\n3.6.4 5.4 Classical Probability\nUsed when all outcomes are equally likely.\nFormula: \\[\nP(A) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total outcomes in } \\Omega}\n\\]\nExample: Rolling a fair die\nP(rolling a 3) = 1/6\n\n\n\n3.6.5 5.5 Probability Rules\n\n3.6.5.1 Rule 1: Non-Negativity\n\\[\n0 \\leq P(A) \\leq 1\n\\]\n\n\n3.6.5.2 Rule 2: Total Probability\n\\[\nP(\\Omega) = 1\n\\]\n\n\n3.6.5.3 Rule 3: Complement Rule\n\\[\nP(A^c) = 1 - P(A)\n\\]\n\n\n3.6.5.4 Rule 4: Addition Rule\nIf A and B are mutually exclusive:\n\\[\nP(A \\cup B) = P(A) + P(B)\n\\]\nOtherwise:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\n\n\n3.6.5.5 Rule 5: Multiplication Rule\n\nFor independent events:\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]\n\n\n\n\n\n3.6.6 5.6 Conditional Probability\nFormula:\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#discrete-probability-distributions",
    "href": "week2.html#discrete-probability-distributions",
    "title": "3¬† Week 2",
    "section": "3.7 6. Discrete Probability Distributions",
    "text": "3.7 6. Discrete Probability Distributions\n\n3.7.1 6.1 Bernoulli Distribution\n\nOne trial, two outcomes (success/failure).\nSuccess = 1, Failure = 0\n\n\\[\nP(X = x) = p^x (1 - p)^{1 - x}, \\quad x \\in \\{0,1\\}\n\\]\n\nMean = \\(p\\)\nVariance = \\(p(1 - p)\\)\n\n\n3.7.1.1 Example:\nFlip a fair coin ‚Üí p = 0.5\nMean = 0.5, Variance = 0.25\n\n\n\n\n3.7.2 6.2 Binomial Distribution\n\nSeries of \\(n\\) independent Bernoulli trials\nNumber of successes \\(x\\) out of \\(n\\) trials\n\nFormula:\n\\[\nP(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x}\n\\]\n\nMean: \\(\\mu = np\\)\nVariance: \\(\\sigma^2 = np(1 - p)\\)\n\n\n3.7.2.1 Example:\nFlip a coin 5 times (p = 0.5)\nP(X = 3) = \\(\\binom{5}{3} (0.5)^3 (0.5)^2 = 10 \\cdot 0.125 \\cdot 0.25 = 0.3125\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#continuous-distributions",
    "href": "week2.html#continuous-distributions",
    "title": "3¬† Week 2",
    "section": "3.8 7. Continuous Distributions",
    "text": "3.8 7. Continuous Distributions\n\n3.8.1 7.1 Normal Distribution\nThe most important continuous distribution in statistics.\nProperties:\n\nBell-shaped and symmetric\nDefined by mean (Œº) and variance (œÉ¬≤)\nTotal area under the curve = 1\n\nProbability Density Function (PDF):\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right)\n\\]\n\n3.8.1.1 Empirical Rule:\n\n68% of values lie within ¬±1œÉ\n95% within ¬±2œÉ\n99.7% within ¬±3œÉ\n\n\n\n\n\n3.8.2 7.2 Standard Normal Distribution\nA normal distribution with:\n\nMean = 0\nStandard deviation = 1\n\nZ-score Formula:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\n\n3.8.2.1 Example:\nIf \\(\\mu = 100\\), \\(\\sigma = 15\\), and \\(X = 130\\)\nThen \\(Z = \\frac{130 - 100}{15} = 2\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#visualizing-data",
    "href": "week2.html#visualizing-data",
    "title": "3¬† Week 2",
    "section": "3.9 8. Visualizing Data",
    "text": "3.9 8. Visualizing Data\n\n3.9.1 8.1 Frequency Distribution\n\n\n\nClass Interval\nFrequency\n\n\n\n\n0‚Äì10\n3\n\n\n11‚Äì20\n7\n\n\n21‚Äì30\n9\n\n\n31‚Äì40\n6\n\n\n\n\n\n\n3.9.2 8.2 Histogram\nA bar chart representing the frequency distribution of numerical data.\nUse Case: Visualize shape (e.g., normal, skewed)\n\n\n\n3.9.3 8.3 Boxplot (Box-and-Whisker Plot)\nShows:\n\nMinimum\nQ1\nMedian\nQ3\nMaximum\nOutliers (as dots)\n\nHelps identify skewness and outliers quickly.\n\n\n\n3.9.4 8.4 Scatter Plot\nUsed to study the relationship between two quantitative variables.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#practical-applications",
    "href": "week2.html#practical-applications",
    "title": "3¬† Week 2",
    "section": "3.10 9. Practical Applications",
    "text": "3.10 9. Practical Applications\n\n3.10.1 9.1 Business Use Cases\n\nRetail: Analyze sales patterns\nHealthcare: Patient outcome probabilities\nFinance: Stock volatility (using SD, CV)\n\n\n\n\n3.10.2 9.2 Education and Research\n\nStudent test scores: Use mean, SD, and percentile ranking\nExperiment analysis: Use Z-scores and Normal Distribution",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#using-rkward",
    "href": "week2.html#using-rkward",
    "title": "3¬† Week 2",
    "section": "3.11 10. Using RKWard",
    "text": "3.11 10. Using RKWard\n\n3.11.1 10.1 What is RKWard?\nA graphical frontend for the R programming language designed for statistical analysis and data visualization.\n\n\n\n3.11.2 10.2 Installation Guide\n\nDownload R from CRAN\nInstall RKWard from rkward.kde.org\nStart RKWard and begin with menu-driven tasks\n\n\n\n\n3.11.3 10.3 Sample RKWard Activities\n\n3.11.3.1 Calculate Mean and SD\n\nLoad dataset\nClick Statistics ‚Üí Descriptive Statistics\nChoose variables and click OK\n\n\n\n3.11.3.2 Visualize Histogram\n\nClick Graphics ‚Üí Histogram\nSelect variable and customize bins\n\n\n\n\n\n3.11.4 10.4 Using R Code in RKWard\n```r data &lt;- c(12, 15, 17, 18, 21) mean(data) sd(data) hist(data)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week2.html#summary",
    "href": "week2.html#summary",
    "title": "3¬† Week 2",
    "section": "3.12 Summary",
    "text": "3.12 Summary\nThis eBook provided a deep dive into basic statistics including:\nData types and classification Central tendency and variability Probability theory and rules Discrete and continuous distributions Visual interpretation and real-world applications GUI-based statistical analysis using RKWard",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "4¬† Week 3",
    "section": "",
    "text": "4.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#introduction",
    "href": "week3.html#introduction",
    "title": "4¬† Week 3",
    "section": "",
    "text": "4.1.1 Importance of Statistics\nStatistics is a powerful tool used across disciplines ‚Äî from economics and psychology to biology, data science, and machine learning. It enables:\n\nInterpretation of data\nGeneralization from samples to populations\nHypothesis testing and decision-making\nPrediction and modeling\n\nUnderstanding statistics is essential for anyone involved in empirical research, policy making, data-driven decision-making, or scientific inquiry.\n\n\n\n4.1.2 Overview of Topics\nThis book covers:\n\nPopulation vs Sample\nHypotheses and Errors\nDescriptive vs Inferential Statistics\nData Types (R + Theoretical)\nSampling Techniques\nNormal Distribution\nLinear and Logistic Regression\nGUI-based R interfaces: RKWard, Rcmdr, Rattle\nFallacies and misuse in statistics\nGraphical Methods\nR programming constructs for statistics",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#understanding-populations-and-samples",
    "href": "week3.html#understanding-populations-and-samples",
    "title": "4¬† Week 3",
    "section": "4.2 Understanding Populations and Samples",
    "text": "4.2 Understanding Populations and Samples\n\n4.2.1 Population\nThe complete set of all units of interest. Examples:\n\nAll students in India\nAll electric cars in the U.S.\n\n\n\n4.2.2 Sample\nA subset of the population, selected for analysis. Goal: represent the population accurately.\n\n\n4.2.3 Why Use Samples?\n\nMore practical and cost-efficient\nEnables faster analysis\nAllows estimation and inference\n\n\n\n4.2.4 Relation Between Population & Sample\nPopulation ‚Üí Sample ‚Üí Statistic ‚Üí Inference ‚Üí Population Parameter",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#hypotheses-and-errors",
    "href": "week3.html#hypotheses-and-errors",
    "title": "4¬† Week 3",
    "section": "4.3 Hypotheses and Errors",
    "text": "4.3 Hypotheses and Errors\n\n4.3.1 Hypothesis Defined\nA hypothesis is a testable assumption about a population.\n\n4.3.1.1 Null Hypothesis (\\(H_0\\))\n\nNo difference or effect\n\nExample: \\(H_0\\): ‚ÄúŒº = 100‚Äù\n\n\n\n4.3.1.2 Alternative Hypothesis (\\(H_A\\))\n\nA difference or effect exists\n\nExample: \\(H_A\\): ‚ÄúŒº ‚â† 100‚Äù\n\n\n\n\n4.3.2 Types of Errors\n\n\n\nError Type\nDescription\n\n\n\n\nType I Error\nRejecting \\(H_0\\) when it‚Äôs true (false positive)\n\n\nType II Error\nFailing to reject \\(H_0\\) when it‚Äôs false (false neg)\n\n\n\n\n\n4.3.3 Significance Level (Œ±)\nThe probability of making a Type I error ‚Äî commonly set to 0.05 (5%)",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#inferential-statistics",
    "href": "week3.html#inferential-statistics",
    "title": "4¬† Week 3",
    "section": "4.4 Inferential Statistics",
    "text": "4.4 Inferential Statistics\n\n4.4.1 Purpose\n\nEstimate unknown population parameters\nTest hypotheses\nPredict outcomes\n\n\n\n4.4.2 Common Techniques\n\nt-test\nz-test\nANOVA\nChi-square\nRegression\n\n\n\n\n4.4.3 Sampling Techniques\n\n4.4.3.1 1. Simple Random Sampling\nEvery unit has equal probability.\n\n\n4.4.3.2 2. Systematic Sampling\nPick every kth element.\n\n\n4.4.3.3 3. Stratified Sampling\nSubdivide population into strata (e.g.¬†age groups), then sample from each.\n\n\n4.4.3.4 4. Cluster Sampling\nRandomly choose entire groups (e.g.¬†schools, cities).\n\n\n\n\n4.4.4 Central Limit Theorem (CLT)\nIf \\(n &gt; 30\\), the distribution of sample means approximates a normal distribution even if the original population is not normal.\nFormula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#descriptive-statistics",
    "href": "week3.html#descriptive-statistics",
    "title": "4¬† Week 3",
    "section": "4.5 Descriptive Statistics",
    "text": "4.5 Descriptive Statistics\n\n4.5.1 Measures of Central Tendency\n\n4.5.1.1 Mean\n\\[\n\\bar{x} = \\frac{\\sum x_i}{n}\n\\]\n\n\n4.5.1.2 Median\nMiddle value in an ordered dataset.\n\n\n4.5.1.3 Mode\nMost frequent value.\n\n\n\n\n4.5.2 Measures of Dispersion\n\n4.5.2.1 Range\n\\[\nRange = Max - Min\n\\]\n\n\n4.5.2.2 Variance\n\\[\ns^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n - 1}\n\\]\n\n\n4.5.2.3 Standard Deviation\n\\[\ns = \\sqrt{s^2}\n\\]\n\n\n\n\n4.5.3 Measures of Shape\n\nSkewness: Degree of asymmetry\nKurtosis: Peakedness of distribution",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#graphical-methods",
    "href": "week3.html#graphical-methods",
    "title": "4¬† Week 3",
    "section": "4.6 Graphical Methods",
    "text": "4.6 Graphical Methods\n\n4.6.1 Histogram\nr hist(data$height, col=‚Äúblue‚Äù, main=‚ÄúHeight Distribution‚Äù) Boxplot\nboxplot(data\\(score ~ data\\)group) Scatter Plot\nplot(data\\(x, data\\)y, col=‚Äúred‚Äù) Ogive (Cumulative Frequency Plot)\nBuilt using cumulative frequency of class intervals.\n\n\n4.6.2 R Data Types and Structures\nBasic Data Types\nx &lt;- 12.5 # numeric y &lt;- as.integer(5) # integer z &lt;- 4 + 3i # complex name &lt;- ‚ÄúRavi‚Äù # character flag &lt;- TRUE # logical Vectors\nv &lt;- c(1, 2, 3) Matrices\nm &lt;- matrix(1:9, nrow=3, byrow=TRUE) Data Frame\ndf &lt;- data.frame(Name=c(‚ÄúA‚Äù, ‚ÄúB‚Äù), Score=c(89, 94)) Lists\nlst &lt;- list(id=101, name=‚ÄúJohn‚Äù, marks=c(78, 82)) Factors\ngender &lt;- factor(c(‚ÄúMale‚Äù, ‚ÄúFemale‚Äù, ‚ÄúMale‚Äù)) Statistical Fallacies\nWhat are Fallacies?\nFallacies occur when conclusions are drawn based on flawed statistical reasoning.\nCommon Fallacies\nImproper Sampling Misleading Graphs Ambiguous Term Definitions Ignoring Confounding Variables Assuming Correlation Implies Causation Misuse of Statistics\nExamples of Misuse\nUsing biased samples Cherry-picking data Using 3D pie charts to exaggerate results Misrepresenting scale in graphs\n\n\n4.6.3 Comparing R vs Excel vs GUI-R (RKWard)\n\n\n\nFeature\nR (Script)\nExcel\nRKWard GUI\n\n\n\n\nUsability\nMedium\nEasy\nEasy\n\n\nFlexibility\nHigh\nLow-Medium\nMedium\n\n\nStatistical Power\nVery High\nLow\nHigh\n\n\nGraphics\nggplot2\nBasic\nggplot2 supported\n\n\nReproducibility\nHigh\nLow\nHigh\n\n\n\n\n\n4.6.4 Installing RKWard (Ubuntu)\n\\[\nsudo apt install kbibtex kate libcurl4-openssl-dev libssl-dev libxml2-dev cmake\nsudo add-apt-repository ppa:rkward-devel/rkward-stable\necho \"deb https://ppa.launchpad.net/rkward-devel/rkward-stable/ubuntu jammy main\" | sudo tee /etc/apt/sources.list.d/rkward.list\nsudo apt update\nsudo apt-get install rkward\n\\]\n\n\n4.6.5 Teaching Tools in RKWard\n\\[\ninstall.packages(c(\"R2HTML\", \"car\", \"e1071\", \"Hmisc\", \"plyr\", \"ggplot2\", \"prob\", \"ez\", \"multcomp\", \"remotes\"), dependencies=TRUE)\nremotes::install_github(\"cran/prob\")\nremotes::install_github(\"rkward-community/rk.Teaching\")\n\\]\n\n\n4.6.6 GUI-Based Statistical Tools\nRKWard ‚Äì KDE interface for R Rcmdr ‚Äì Classic R Commander GUI Rattle ‚Äì Data mining GUI in R R AnalyticFlow ‚Äì Flow-based programming for statistics",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#linear-regression-in-r",
    "href": "week3.html#linear-regression-in-r",
    "title": "4¬† Week 3",
    "section": "4.7 Linear Regression in R",
    "text": "4.7 Linear Regression in R\n\n4.7.1 What is Linear Regression?\nLinear regression models the relationship between a dependent variable (Y) and one or more independent variables (X).\n\n4.7.1.1 Simple Linear Regression Equation:\n\\[\nY = \\beta_0 + \\beta_1 X + \\epsilon\n\\]\nWhere:\n\n\\(Y\\) is the dependent variable\n\n\\(X\\) is the independent variable\n\n\\(\\beta_0\\) is the intercept\n\n\\(\\beta_1\\) is the slope\n\n\\(\\epsilon\\) is the error term\n\n\n\n\n4.7.2 Code Example\nr ## Load data data(mtcars)",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#fit-model",
    "href": "week3.html#fit-model",
    "title": "4¬† Week 3",
    "section": "4.8 Fit model",
    "text": "4.8 Fit model\nmodel &lt;- lm(mpg ~ wt, data=mtcars)",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "4¬† Week 3",
    "section": "4.9 Summary",
    "text": "4.9 Summary\nsummary(model)\n\n4.9.1 Adjusted R-squared\nPenalizes the number of predictors to avoid overfitting.\nAIC & BIC\nAIC: Akaike Information Criterion BIC: Bayesian Information Criterion Lower values of AIC/BIC ‚Üí better model fit (with penalty for complexity).\n\n\n4.9.2 Normal Distribution\nKey Properties\nSymmetrical, bell-shaped curve Mean = Median = Mode Total area under curve = 1 Empirical Rule: 68% within ¬±1 SD 95% within ¬±2 SD 99.7% within ¬±3 SD\nExample: Given: Mean = 70, SD = 5, X = 75\nz &lt;- (75 - 70) / 5 # Result: 1.0 Z-Table Usage\nFind the area under the curve to the left of the z-score Useful for probability and percentile ranking\n\n\n4.9.3 Data Import Techniques\nCSV Import in R\ndf &lt;- read.csv(‚Äúdata.csv‚Äù, header=TRUE) head(df) Excel Import (using readxl)\ninstall.packages(‚Äúreadxl‚Äù) library(readxl)\ndf &lt;- read_excel(‚Äúdata.xlsx‚Äù)\n\n\n4.9.4 Working with the RKWard Interface\nSections: Console ‚Äì Run R code Script Editor ‚Äì Write reusable code Workspace ‚Äì View loaded variables Teaching Tab ‚Äì Education-focused modules\n\n\n4.9.5 Spreadsheet Concepts\nStructure\nComponent |Description Rows |Individual observations Columns |Variables Cells |Data points Header Row| Variable names\n\n\n4.9.6 Advantages\nEasy data entry Visual inspection Good for small datasets\n\n\n4.9.7 Limitations\nLimited statistical functionality Hard to reproduce Error-prone for large datasets\n\n\n4.9.8 Advanced Plots and Techniques\nDensity Plot\n\n\nCode\nplot(density(mtcars$mpg), main=\"Density Plot\", col=\"blue\")\n\n\n\n\n\n\n\n\n\nPair Plot\n\n\nCode\npairs(mtcars[, 1:4])\n\n\n\n\n\n\n\n\n\nCorrelation Matrix\n\n\nCode\ncor(mtcars)\n\n\n            mpg        cyl       disp         hp        drat         wt\nmpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594\ncyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958\ndisp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799\nhp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479\ndrat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406\nwt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000\nqsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159\nvs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157\nam    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953\ngear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870\ncarb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059\n            qsec         vs          am       gear        carb\nmpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507\ncyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829\ndisp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686\nhp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247\ndrat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980\nwt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594\nqsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923\nvs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714\nam   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435\ngear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284\ncarb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000\n\n\nHeatmap\n\n\nCode\nheatmap(cor(mtcars), main=\"Correlation Heatmap\")\n\n\n\n\n\n\n\n\n\n\n\n4.9.9 Common R Packages for Statistics\nPackage |Purpose ggplot2 |Data visualization dplyr |Data manipulation tidyr |Data tidying Hmisc |Misc stats functions car |Regression diagnostics e1071 |Skewness/kurtosis, ML tools psych |Psychological statistics shiny |Interactive apps caret |Classification and regression\n\n\n4.9.10 Introduction to Command Line",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week3.html#windows-terminal",
    "href": "week3.html#windows-terminal",
    "title": "4¬† Week 3",
    "section": "4.10 Windows Terminal",
    "text": "4.10 Windows Terminal\n\\[\ncd ..\nmkdir my_project\ndir\n\\] ### Linux Terminal \\[\ncd ~\nmkdir stats_project\nls -l\n\\]\n\n4.10.1 Git + R Project Example\n\\[\ngit init\ngit clone https://github.com/username/project.git\n\\]\n\n\n4.10.2 Fallacies and Bias: Real-World Cautions\nExamples of Statistical Abuse\nCherry-picking data Data dredging (p-hacking) Using relative risk without absolute context Non-random sampling Ethics in Data Analysis\nBe transparent Document sources Disclose methodology Avoid overstating conclusions\n\n\n4.10.3 Future Applications of Statistics\nReal-World Domains\nHealthcare: Drug effectiveness, diagnostics Economics: Forecasting, policy evaluation Sociology: Survey analysis Sports: Performance analytics AI/ML: Predictive modeling, optimization Next Steps\nLearn tidyverse ecosystem Explore machine learning in R Build Shiny dashboards Get familiar with reproducible research using Quarto\n\n\n4.10.4 Practice Challenges\n\nLoad and summarize data\n\nLoad mtcars or your own dataset Use summary(), mean(), sd() 2. Create 3 different plots\nHistogram Boxplot by group Scatter plot with trend line 3. Build a regression model\nIdentify predictor and outcome Use lm() and summary() 4. Explore a GUI like RKWard or Rcmdr\n\n\n4.10.5 Key Takeaways\nStatistics supports informed decision-making. R and its GUI frontends offer flexibility + power. Understand theory ‚Üí then automate with code. Avoid fallacies by following robust methods. Visuals are crucial: plot early, plot often.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "5¬† Week 4",
    "section": "",
    "text": "5.1 Introduction\nThis eBook is a comprehensive companion to the course Basic Statistics using GUI-R (RKWard). It includes foundational theory, practical examples, and step-by-step explanations, with integrated GUI-R usage.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#course-overview",
    "href": "week4.html#course-overview",
    "title": "5¬† Week 4",
    "section": "5.2 Course Overview",
    "text": "5.2 Course Overview\n\n5.2.1 Course Name\nBasic Statistics using GUI-R (RKWard)\n\n\n5.2.2 Instructor Profile\nDr.¬†Harsh Pradhan is Assistant Professor at the Institute of Management Studies, Banaras Hindu University.\nüìé Faculty Profile\n\n\n5.2.3 Learning Objectives\n\nUnderstand core concepts in statistics\nApply t-tests and ANOVA using real data\nCompute confidence intervals and test statistics\nUse GUI-R (RKWard) for statistical analysis",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-1-fundamental-concepts",
    "href": "week4.html#chapter-1-fundamental-concepts",
    "title": "5¬† Week 4",
    "section": "5.3 Chapter 1: Fundamental Concepts",
    "text": "5.3 Chapter 1: Fundamental Concepts\n\n5.3.1 Descriptive Statistics\n\n5.3.1.1 Central Tendency\n\nMean\n\nMedian\n\nMode\n\n\n\n5.3.1.2 Dispersion\n\nRange\n\nVariance\n\nStandard Deviation\n\n\n\n5.3.1.3 Example:\n\n\nCode\ndata &lt;- c(4, 8, 6, 5, 3)\nmean(data)\n\n\n[1] 5.2\n\n\nCode\nmedian(data)\n\n\n[1] 5\n\n\nCode\nsd(data)\n\n\n[1] 1.923538\n\n\n\n\n\n5.3.2 Standard Error\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nSmall SE = sample mean is a good estimate of the population mean.\n\n\n5.3.3 Central Limit Theorem\nFor \\(n &gt; 30\\), sampling distribution of the mean approximates normal:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\frac{\\sigma}{\\sqrt{n}})\n\\]\n\n\n5.3.4 Confidence Intervals\n\\[\nCI = \\bar{x} \\pm Z \\cdot \\frac{s}{\\sqrt{n}}\n\\]\nInterpret 95% CI as: 95 of 100 such intervals would contain the true mean.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-2-estimation",
    "href": "week4.html#chapter-2-estimation",
    "title": "5¬† Week 4",
    "section": "5.4 Chapter 2: Estimation",
    "text": "5.4 Chapter 2: Estimation\n\n5.4.1 Types of Estimates\n\n\n\nType\nDescription\nExample\n\n\n\n\nPoint Estimate\nSingle value\nSample mean\n\n\nInterval Estimate\nRange + confidence\nConfidence Int\n\n\n\n\n\n5.4.2 Parameter vs Statistic\n\n\n\nTerm\nDescription\n\n\n\n\nParameter\nValue from population (e.g., \\(\\mu\\))\n\n\nStatistic\nValue from sample (e.g., \\(\\bar{x}\\))",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-3-hypothesis-testing",
    "href": "week4.html#chapter-3-hypothesis-testing",
    "title": "5¬† Week 4",
    "section": "5.5 Chapter 3: Hypothesis Testing",
    "text": "5.5 Chapter 3: Hypothesis Testing\n\nNull Hypothesis (\\(H_0\\)): No effect\n\nAlternative Hypothesis (\\(H_1\\)): Some effect\n\nType I Error: Reject \\(H_0\\) when true\n\nType II Error: Fail to reject \\(H_0\\) when false",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-4-students-t-test",
    "href": "week4.html#chapter-4-students-t-test",
    "title": "5¬† Week 4",
    "section": "5.6 Chapter 4: Student‚Äôs T-Test",
    "text": "5.6 Chapter 4: Student‚Äôs T-Test\n\n5.6.1 Types\n\n\n\nTest Type\nDescription\n\n\n\n\nOne-Sample\nCompare sample to fixed value\n\n\nIndependent\nCompare two unrelated groups\n\n\nPaired\nCompare two related groups\n\n\n\n\n\n5.6.2 One-Sample T-Test Example\n\n\nCode\ndata &lt;- c(22, 24, 27, 26, 28, 23, 25, 29, 21, 26, 24, 27)\nt.test(data, mu = 25)\n\n\n\n    One Sample t-test\n\ndata:  data\nt = 0.2363, df = 11, p-value = 0.8175\nalternative hypothesis: true mean is not equal to 25\n95 percent confidence interval:\n 23.61427 26.71906\nsample estimates:\nmean of x \n 25.16667 \n\n\n\n\n5.6.3 Test Statistic\n\\[\nt = \\frac{\\bar{x} - \\mu}{SE}\n\\]\n\n\n5.6.4 Degrees of Freedom\n\\[\ndf = n - 1\n\\]\n\n\n5.6.5 Decision Rule\nCompare calculated \\(t\\) to table value. If \\(|t| &gt; t_{critical}\\), reject \\(H_0\\).\n\n\n5.6.6 T-Test in GUI-R\n\nImport data\n\nChoose T-Test\n\nDefine groups\n\nRun & interpret output",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-5-anova",
    "href": "week4.html#chapter-5-anova",
    "title": "5¬† Week 4",
    "section": "5.7 Chapter 5: ANOVA",
    "text": "5.7 Chapter 5: ANOVA\n\n5.7.1 Purpose\nUsed when comparing means across 3+ groups.\n\n5.7.1.1 One-Way ANOVA Formula\n\\[\nF = \\frac{MS_{between}}{MS_{within}}\n\\]\nWhere:\n\n\\(MS_{between} = \\frac{SS_{between}}{df_{between}}\\)\n\n\\(MS_{within} = \\frac{SS_{within}}{df_{within}}\\)\n\n\n\n5.7.1.2 Assumptions\n\nNormality\n\nHomogeneity of variance\n\nIndependence\n\n\n\n5.7.1.3 Example Table\n\n\n\nGroup\nMean\nVar\nn\n\n\n\n\nA\n5.5\n1.5\n30\n\n\nB\n7.1\n2.0\n30\n\n\nC\n6.8\n1.8\n30\n\n\n\n\n\n\n5.7.2 Post-Hoc Tests\nRun if ANOVA is significant to locate pairwise differences.\n\n\n5.7.3 ANOVA in GUI-R\n\nLoad data\n\nChoose ‚ÄúOne-Way ANOVA‚Äù\n\nDefine groups\n\nInterpret output",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-6-gui-r-workflow",
    "href": "week4.html#chapter-6-gui-r-workflow",
    "title": "5¬† Week 4",
    "section": "5.8 Chapter 6: GUI-R Workflow",
    "text": "5.8 Chapter 6: GUI-R Workflow\n\nImport Data (CSV, Excel)\n\nChoose Test (T-Test, ANOVA, etc.)\n\nRun the analysis\n\nInterpret the output\n\nExport the results or visualizations",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-7-advanced-concepts",
    "href": "week4.html#chapter-7-advanced-concepts",
    "title": "5¬† Week 4",
    "section": "5.9 Chapter 7: Advanced Concepts",
    "text": "5.9 Chapter 7: Advanced Concepts\n\n5.9.1 Variance Partitioning\n\\[\n\\text{Total Variance} = \\text{Explained Variance} + \\text{Unexplained Variance}\n\\]\n\n\n\nExplained Terms\nUnexplained Terms\n\n\n\n\nSystematic\nRandom\n\n\nPredictive\nError\n\n\nDeterministic\nNoise\n\n\n\n\n\n5.9.2 Degrees of Freedom\nFor equation \\(x + y + z = 3\\), if 2 values are known, third is fixed.\nHence, \\(df = n - k\\) where \\(n\\) = total variables, \\(k\\) = constraints.\n\n\n5.9.3 Chi-Square and F Distribution\n\nChi-Square: Categorical variable comparison\n\nF-Distribution: Used in ANOVA, variance testing\n\n\n\n5.9.4 Univariate, Bivariate, Multivariate\n\n\n\nType\nVariables\nExample\n\n\n\n\nUnivariate\n1\nHeight\n\n\nBivariate\n2\nHeight vs Weight\n\n\nMultivariate\n&gt;2\nStudy w/ Age, Gender, Income\n\n\n\n\n\n5.9.5 Parametric Test Assumptions\n\nInterval/Ratio DV\n\nRandom Sampling\n\nNormality\n\nEqual Variances\n\nIf assumptions violated ‚Üí use non-parametric test.\n\n\n5.9.6 Effect Size\n\\[\n\\text{Effect Size} = \\frac{|\\mu_1 - \\mu_2|}{\\sigma}\n\\]\nUsed for comparison across studies.\n\n\n5.9.7 Power of a Test\n\\[\n\\text{Power} = 1 - \\beta\n\\]\nHigher power ‚Üí lower chance of Type II error\nPower increases with sample size, effect size",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#conclusion",
    "href": "week4.html#conclusion",
    "title": "5¬† Week 4",
    "section": "5.10 Conclusion",
    "text": "5.10 Conclusion\nStatistics is the language of data. GUI-R makes statistical tools accessible for everyone. This book empowers you to analyze data effectively using t-tests, ANOVA, and confidence intervals in a GUI environment.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#references",
    "href": "week4.html#references",
    "title": "5¬† Week 4",
    "section": "5.11 References",
    "text": "5.11 References\n\nPradhan, H. (2023). Basic Statistics using GUI-R (RKWard)\n\nField, A. (2013). Discovering Statistics Using R.\n\nhttps://methods.sagepub.com",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-8-advanced-t-test-applications",
    "href": "week4.html#chapter-8-advanced-t-test-applications",
    "title": "5¬† Week 4",
    "section": "5.12 Chapter 8: Advanced T-Test Applications",
    "text": "5.12 Chapter 8: Advanced T-Test Applications\n\n5.12.1 Paired Sample T-Test\nUsed when the same group is measured twice (e.g., before and after).\n\n5.12.1.1 Example:\n\n\nCode\nbefore &lt;- c(80, 82, 79, 84, 88)\nafter &lt;- c(78, 81, 76, 83, 86)\nt.test(before, after, paired = TRUE)\n\n\n\n    Paired t-test\n\ndata:  before and after\nt = 4.8107, df = 4, p-value = 0.008581\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.7611494 2.8388506\nsample estimates:\nmean difference \n            1.8 \n\n\n\n\n\n5.12.2 Independent Samples T-Test\nCompare means of two unrelated groups.\n\n\nCode\ngroup1 &lt;- c(85, 90, 88, 92, 87)\ngroup2 &lt;- c(80, 83, 85, 84, 82)\nt.test(group1, group2)\n\n\n\n    Welch Two Sample t-test\n\ndata:  group1 and group2\nt = 3.7755, df = 7.226, p-value = 0.006537\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 2.114814 9.085186\nsample estimates:\nmean of x mean of y \n     88.4      82.8 \n\n\n\n\n5.12.3 One-Sample T-Test with GUI-R\n\nImport dataset\nUse ‚ÄòDescriptive Statistics‚Äô to check mean\nNavigate to ‚ÄòT-Test‚Äô ‚Üí ‚ÄòOne Sample‚Äô\nInput hypothesized mean and run",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-9-more-on-confidence-intervals",
    "href": "week4.html#chapter-9-more-on-confidence-intervals",
    "title": "5¬† Week 4",
    "section": "5.13 Chapter 9: More on Confidence Intervals",
    "text": "5.13 Chapter 9: More on Confidence Intervals\n\n5.13.1 Visualizing Confidence Intervals in R\n\n\nCode\nx &lt;- c(88, 90, 85, 87, 89)\nmean_x &lt;- mean(x)\nse &lt;- sd(x) / sqrt(length(x))\nci_lower &lt;- mean_x - 1.96 * se\nci_upper &lt;- mean_x + 1.96 * se\nc(ci_lower, ci_upper)\n\n\n[1] 86.11394 89.48606\n\n\nPlot using ggplot2:\n\n\nCode\nlibrary(ggplot2)\ndf &lt;- data.frame(x = x)\nggplot(df, aes(y = x, x = 1)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.1)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-10-robust-anova-models",
    "href": "week4.html#chapter-10-robust-anova-models",
    "title": "5¬† Week 4",
    "section": "5.14 Chapter 10: Robust ANOVA Models",
    "text": "5.14 Chapter 10: Robust ANOVA Models\n\n5.14.1 Two-Way ANOVA\nExamines the effect of two categorical independent variables on a continuous dependent variable.\n\n\nCode\n# Sample dataset for demonstration\ndataset &lt;- data.frame(\n  score = c(85, 90, 88, 92, 87, 80, 83, 85, 84, 82),\n  gender = rep(c(\"Male\", \"Female\"), each = 5),\n  teaching_method = rep(c(\"A\", \"B\"), times = 5)\n)\naov_result &lt;- aov(score ~ gender * teaching_method, data = dataset)\nsummary(aov_result)\n\n\n                       Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ngender                  1  78.40   78.40  23.718 0.00279 **\nteaching_method         1   6.02    6.02   1.820 0.22598   \ngender:teaching_method  1  18.15   18.15   5.491 0.05759 . \nResiduals               6  19.83    3.31                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n5.14.2 Repeated Measures ANOVA\nUse when the same subjects are used for each treatment.\n\n\nCode\n# Sample repeated measures data in long format\ndata_long &lt;- data.frame(\n  id = rep(1:5, each = 3),\n  condition = rep(c(\"A\", \"B\", \"C\"), times = 5),\n  score = c(85, 88, 90, 80, 82, 85, 78, 80, 83, 90, 92, 95, 88, 90, 91)\n)\nlibrary(ez)\nezANOVA(data = data_long, dv = .(score), wid = .(id), within = .(condition))\n\n\nWarning: Converting \"id\" to factor for ANOVA.\n\n\nWarning: Converting \"condition\" to factor for ANOVA.\n\n\n$ANOVA\n     Effect DFn DFd        F            p p&lt;.05       ges\n2 condition   2   8 88.22222 3.539139e-06     * 0.1479687\n\n$`Mauchly's Test for Sphericity`\n     Effect         W         p p&lt;.05\n2 condition 0.5555556 0.4140867      \n\n$`Sphericity Corrections`\n     Effect       GGe        p[GG] p[GG]&lt;.05       HFe        p[HF] p[HF]&lt;.05\n2 condition 0.6923077 9.135419e-05         * 0.9411765 6.568851e-06         *",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-11-effect-size-measures",
    "href": "week4.html#chapter-11-effect-size-measures",
    "title": "5¬† Week 4",
    "section": "5.15 Chapter 11: Effect Size Measures",
    "text": "5.15 Chapter 11: Effect Size Measures\n\n5.15.1 Cohen‚Äôs d\n\\[\nd = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p}\n\\]\nWhere \\(s_p\\) is the pooled standard deviation.\n\n5.15.1.1 R Example\n\n\nCode\nlibrary(effsize)\ncohen.d(group1, group2)\n\n\n\nCohen's d\n\nd estimate: 2.387848 (large)\n95 percent confidence interval:\n    lower     upper \n0.4791634 4.2965327 \n\n\n\n\n\n5.15.2 Eta-Squared (\\(\\eta^2\\))\nUsed for ANOVA:\n\\[\n\\eta^2 = \\frac{SS_{between}}{SS_{total}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-12-statistical-assumptions-checking",
    "href": "week4.html#chapter-12-statistical-assumptions-checking",
    "title": "5¬† Week 4",
    "section": "5.16 Chapter 12: Statistical Assumptions Checking",
    "text": "5.16 Chapter 12: Statistical Assumptions Checking\n\n5.16.1 Normality\nUse Shapiro-Wilk test:\n\n\nCode\n# Sample data frame for normality test\ndata &lt;- data.frame(variable = c(88, 90, 85, 87, 89, 91, 92, 88, 90, 87))\nshapiro.test(data$variable)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  data$variable\nW = 0.97743, p-value = 0.95\n\n\nVisualize:\n\n\nCode\nqqnorm(data$variable)\nqqline(data$variable)\n\n\n\n\n\n\n\n\n\n\n\n5.16.2 Homogeneity of Variance\nUse Levene‚Äôs Test:\n\n\nCode\n# Sample data frame for Levene's Test\ndata &lt;- data.frame(\n  variable = c(88, 90, 85, 87, 89, 91, 92, 88, 90, 87),\n  group = rep(c(\"A\", \"B\"), each = 5)\n)\nlibrary(car)\n\n\nLoading required package: carData\n\n\nCode\nleveneTest(variable ~ group, data = data)\n\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  0.0769 0.7885\n       8",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#chapter-13-non-parametric-alternatives",
    "href": "week4.html#chapter-13-non-parametric-alternatives",
    "title": "5¬† Week 4",
    "section": "5.17 Chapter 13: Non-Parametric Alternatives",
    "text": "5.17 Chapter 13: Non-Parametric Alternatives\n\n5.17.1 Wilcoxon Signed Rank Test\n\n\nCode\nwilcox.test(before, after, paired = TRUE)\n\n\nWarning in wilcox.test.default(before, after, paired = TRUE): cannot compute\nexact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  before and after\nV = 15, p-value = 0.05676\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n5.17.2 Mann-Whitney U Test\n\n\nCode\nwilcox.test(group1, group2)\n\n\nWarning in wilcox.test.default(group1, group2): cannot compute exact p-value\nwith ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  group1 and group2\nW = 24.5, p-value = 0.01597\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n5.17.3 Kruskal-Wallis Test\nNon-parametric alternative to ANOVA.\n\n\nCode\n# Sample data frame for Kruskal-Wallis Test\ndata &lt;- data.frame(\n  score = c(85, 88, 90, 80, 82, 85, 78, 80, 83, 90, 92, 95, 88, 90, 91),\n  group = rep(c(\"A\", \"B\", \"C\"), times = 5)\n)\nkruskal.test(score ~ group, data = data)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  score by group\nKruskal-Wallis chi-squared = 2.2329, df = 2, p-value = 0.3274",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#visualizing-statistical-results",
    "href": "week4.html#visualizing-statistical-results",
    "title": "5¬† Week 4",
    "section": "5.18 Visualizing Statistical Results",
    "text": "5.18 Visualizing Statistical Results",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#boxplots",
    "href": "week4.html#boxplots",
    "title": "5¬† Week 4",
    "section": "5.19 Boxplots",
    "text": "5.19 Boxplots\n\n\nCode\nggplot(data, aes(x = group, y = score)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n5.19.1 Histograms\n\n\nCode\nggplot(data, aes(x = score)) +\n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\n\n\n\n5.19.2 Density Plot\n\n\nCode\nggplot(data, aes(x = score)) +\n  geom_density()",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week4.html#rkward-gui-r-tips",
    "href": "week4.html#rkward-gui-r-tips",
    "title": "5¬† Week 4",
    "section": "5.20 RKWard (GUI-R) Tips",
    "text": "5.20 RKWard (GUI-R) Tips\n\nUse menu-based analysis for beginners\nSave and export plots easily\nIntegrate with R scripts for reproducibility\n\n\n5.20.1 üìòSummary: Basic Statistics using GUI-R (RKWard)\nThis eBook, authored by Dr.¬†Harsh Pradhan (Assistant Professor at the Institute of Management Studies, Banaras Hindu University), serves as a comprehensive guide to understanding and applying basic statistical concepts, particularly in the GUI-based software RKWard (GUI-R).\nKey Highlights: 1. Descriptive Statistics Covers measures of central tendency (mean, median, mode) and variability (range, variance, standard deviation). Introduces standard error and its role in estimating population parameters. 2. Inferential Statistics Introduces the Central Limit Theorem and how it forms the foundation for many statistical techniques. Confidence intervals are explained both theoretically and with practical calculations. 3. T-Tests (Student‚Äôs t) Explains one-sample, independent-sample, and paired-sample t-tests. Includes step-by-step computation and GUI-R implementation. Includes interpretation of p-values, degrees of freedom, and test statistics. 4. Analysis of Variance (ANOVA) Covers one-way, two-way, and repeated measures ANOVA. Focuses on the F-statistic, assumptions, and post-hoc analyses. Discusses partitioning of variance into systematic and unsystematic components. 5. Effect Size and Statistical Power Introduces Cohen‚Äôs d, eta-squared, and power analysis. Emphasizes that statistical significance does not always imply practical importance. 6. Assumption Testing Tests for normality (Shapiro-Wilk, QQ plot). Tests for homogeneity of variance (Levene‚Äôs test). Highlights when to use non-parametric alternatives. 7. Non-Parametric Tests Introduces Wilcoxon signed-rank, Mann-Whitney U, and Kruskal-Wallis tests as robust alternatives to parametric methods. 8. Data Visualization in R Demonstrates use of boxplots, histograms, and density plots using ggplot2. Provides example R code for reproducibility. 9. GUI-R (RKWard) Usage Offers practical steps for using GUI-R for all statistical techniques covered. Designed to bridge the gap for learners unfamiliar with command-line R.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "6¬† Week 5",
    "section": "",
    "text": "6.1 1. Introduction\nWelcome to Week 5 of Basic Statistics using GUI-R (RKWard), where we cover relationship testing, correlation, regression, ANOVA, and related diagnostics in depth, using both theory and R-based implementation.\nThis book is designed to:",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#introduction",
    "href": "week5.html#introduction",
    "title": "6¬† Week 5",
    "section": "",
    "text": "Clarify statistical concepts visually\nUse real data simulations\nEmpower you with reproducible R/RKWard workflows\nPrepare you to run statistical diagnostics and build interpretations",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#lecture-24-deep-dive-correlation",
    "href": "week5.html#lecture-24-deep-dive-correlation",
    "title": "6¬† Week 5",
    "section": "6.2 2. Lecture 24 ‚Äì Deep Dive: Correlation",
    "text": "6.2 2. Lecture 24 ‚Äì Deep Dive: Correlation\n\n6.2.1 2.1 What is Correlation?\nCorrelation is a statistical measure that expresses the extent to which two variables are linearly related.\n\n6.2.1.1 üí° Theory\n\nIf variable X increases as Y increases ‚Üí Positive correlation\nIf variable X increases as Y decreases ‚Üí Negative correlation\nIf there‚Äôs no linear trend ‚Üí Zero correlation\n\n\nPearson‚Äôs r ranges from -1 to +1.\n\n\n\n\n\n6.2.2 2.2 Types of Correlation and Use Cases\n\n\n\n\n\n\n\n\nData Type\nCorrelation Type\nUse Case Example\n\n\n\n\nNominal\nPhi\nGender vs.¬†Yes/No Preferences\n\n\nDichotomous\nPoint-Biserial\nPass/Fail vs.¬†Exam Score\n\n\nOrdinal/Rank\nSpearman/Kendall\nRank in class vs.¬†Test anxiety\n\n\nRatio/Interval\nPearson\nHeight vs.¬†Weight\n\n\nMultivariate\nPartial Correl.\nControl confounders\n\n\n\n\n\n\n6.2.3 2.3 Pearson, Spearman, Kendall Comparison\n{r} ## Simulate linear data set.seed(123) x &lt;- rnorm(100) y &lt;- 2 * x + rnorm(100)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#add-non-linear-data",
    "href": "week5.html#add-non-linear-data",
    "title": "6¬† Week 5",
    "section": "6.3 Add non-linear data",
    "text": "6.3 Add non-linear data\nz &lt;- x^2 + rnorm(100)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#pearson-linear",
    "href": "week5.html#pearson-linear",
    "title": "6¬† Week 5",
    "section": "6.4 Pearson (linear)",
    "text": "6.4 Pearson (linear)\ncor(x, y, method = ‚Äúpearson‚Äù)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#spearman-rank-monotonic",
    "href": "week5.html#spearman-rank-monotonic",
    "title": "6¬† Week 5",
    "section": "6.5 Spearman (rank, monotonic)",
    "text": "6.5 Spearman (rank, monotonic)\ncor(x, z, method = ‚Äúspearman‚Äù)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#kendall-ordinal",
    "href": "week5.html#kendall-ordinal",
    "title": "6¬† Week 5",
    "section": "6.6 Kendall (ordinal)",
    "text": "6.6 Kendall (ordinal)\ncor(x, z, method = ‚Äúkendall‚Äù) 2.4 Visualizing Correlations ## Visualization library(ggplot2) data &lt;- data.frame(x, y, z)\nggplot(data, aes(x = x, y = y)) + geom_point() + geom_smooth(method = ‚Äúlm‚Äù, se = FALSE, color = ‚Äúblue‚Äù) + labs(title = ‚ÄúScatter Plot with Linear Fit‚Äù, x = ‚ÄúX‚Äù, y = ‚ÄúY‚Äù)\nggplot(data, aes(x = x, y = z)) + geom_point(color = ‚Äúdarkred‚Äù) + labs(title = ‚ÄúNon-Linear Relationship‚Äù, x = ‚ÄúX‚Äù, y = ‚ÄúZ‚Äù) 2.5 Correlation Matrix in RKWard Steps:\nLoad data into RKWard.\nNavigate to Statistics ‚Üí Summaries ‚Üí Correlation Matrix.\nChoose the appropriate variables.\nChoose correlation type (Pearson, Spearman).\nRun and interpret the matrix output.\n2.6 Partial Correlation in R When you want to compute the correlation between two variables while controlling for a third:",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#install.packagesggm",
    "href": "week5.html#install.packagesggm",
    "title": "6¬† Week 5",
    "section": "6.7 install.packages(‚Äúggm‚Äù)",
    "text": "6.7 install.packages(‚Äúggm‚Äù)\nlibrary(ggm) X1 &lt;- rnorm(100) X2 &lt;- X1 + rnorm(100, sd = 0.5) X3 &lt;- rnorm(100) pcor(c(‚ÄúX1‚Äù, ‚ÄúX2‚Äù, ‚ÄúX3‚Äù), cov(cbind(X1, X2, X3))) Interpretation: This tells you the pure correlation between X1 and X2, controlling for X3.\n2.7 R Code to Automate All",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#simulate-data",
    "href": "week5.html#simulate-data",
    "title": "6¬† Week 5",
    "section": "6.8 Simulate data",
    "text": "6.8 Simulate data\nset.seed(100) data &lt;- data.frame( A = rnorm(100), B = rnorm(100), C = rnorm(100) )",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#generate-all-pairwise-correlations",
    "href": "week5.html#generate-all-pairwise-correlations",
    "title": "6¬† Week 5",
    "section": "6.9 Generate all pairwise correlations",
    "text": "6.9 Generate all pairwise correlations\ncor(data)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#visualize-matrix-with-corrplot",
    "href": "week5.html#visualize-matrix-with-corrplot",
    "title": "6¬† Week 5",
    "section": "6.10 Visualize matrix with corrplot",
    "text": "6.10 Visualize matrix with corrplot\nlibrary(corrplot) corrplot(cor(data), method = ‚Äúcolor‚Äù, tl.col = ‚Äúblack‚Äù, addCoef.col = ‚Äúblack‚Äù) 2.8 Spearman vs Pearson ‚Äì When to Use? Use Pearson when data is normally distributed, continuous, and linear.\nUse Spearman when data is ordinal, ranked, or non-linear but monotonic.\nKendall‚Äôs Tau is more robust for small sample sizes.\nüëÄ Next Up: Part 2/4 will include:\n\nOne-Way ANOVA full theory + math\n\nRepeated Measures ANOVA (detailed)\n\nVisualization of F-distributions\n\nMANOVA + N-Way examples\n\n10+ R code exercises",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#lecture-25-one-way-anova-detailed",
    "href": "week5.html#lecture-25-one-way-anova-detailed",
    "title": "6¬† Week 5",
    "section": "6.11 3. Lecture 25 ‚Äì One-Way ANOVA (Detailed)",
    "text": "6.11 3. Lecture 25 ‚Äì One-Way ANOVA (Detailed)\n\n6.11.1 3.1 Concept Overview\nAnalysis of Variance (ANOVA) is used when comparing the means of three or more groups.\n\n6.11.1.1 üí° Formula Breakdown\n\nSSM (Sum of Squares Model): Variation between groups\nSSR (Sum of Squares Residual): Variation within groups\nSST (Total): Total variation\n\nF-Ratio:\n\\[\nF = \\frac{MS_{between}}{MS_{within}} = \\frac{SSM / df_M}{SSR / df_R}\n\\]\n\n\n\n6.11.2 3.2 ANOVA Table Example\n\n\n\nSource\nSS\ndf\nMS\nF\n\n\n\n\nBetween\n461.64\n3\n153.88\n8.27\n\n\nWithin\n167.42\n9\n18.60\n\n\n\nTotal\n629.08\n12\n\n\n\n\n\n\n\n\n6.11.3 3.3 R Code ‚Äì One-Way ANOVA\ngroup1 &lt;- c(28, 36, 38, 31) group2 &lt;- c(32, 33, 40) group3 &lt;- c(47, 43, 52) group4 &lt;- c(40, 47, 45)\nscore &lt;- c(group1, group2, group3, group4) group &lt;- factor(rep(c(‚ÄúHunter‚Äù, ‚ÄúFarming‚Äù, ‚ÄúNatural‚Äù, ‚ÄúIndustrial‚Äù), times=c(4,3,3,3)))\ndata &lt;- data.frame(score, group) anova_model &lt;- aov(score ~ group, data=data) summary(anova_model) 3.4 Post-Hoc Analysis (Tukey HSD)\nTukeyHSD(anova_model) 3.5 Visualize Group Differences\nboxplot(score ~ group, data = data, col = c(‚Äúlightblue‚Äù, ‚Äúpink‚Äù, ‚Äúlightgreen‚Äù, ‚Äúyellow‚Äù)) 4. Lecture 26 ‚Äì Repeated Measures ANOVA 4.1 Theory Repeated measures involve the same subjects measured under multiple conditions.\nAspect Repeated Measures Between-Subjects Subjects Same across treatments Different per group Variability Control Higher (less noise) Lower Efficiency More efficient Requires more samples\n4.2 R Code ‚Äì Repeated Measures\nlibrary(ez) subject &lt;- factor(rep(1:10, each=3)) treatment &lt;- factor(rep(c(‚ÄúPre‚Äù, ‚ÄúMid‚Äù, ‚ÄúPost‚Äù), times=10)) score &lt;- c(rnorm(10, 65), rnorm(10, 70), rnorm(10, 75)) rm_df &lt;- data.frame(subject, treatment, score)\nezANOVA(data=rm_df, dv=score, wid=subject, within=treatment) 4.3 Visual Check\nlibrary(ggplot2) ggplot(rm_df, aes(x=treatment, y=score, group=subject, color=subject)) + geom_line() + geom_point() + theme_minimal() + labs(title=‚ÄúRepeated Measures ANOVA Plot‚Äù) 5. Lecture 27 ‚Äì MANOVA and N-Way ANOVA 5.1 What is MANOVA? Multivariate Analysis of Variance (MANOVA) extends ANOVA to multiple dependent variables.\nExample Use Case:\nInvestigating how teaching methods affect:\nExam scores\nClass participation\nHomework submission\n5.2 R Code ‚Äì MANOVA\ny1 &lt;- rnorm(30, 60, 5) y2 &lt;- rnorm(30, 70, 6) y3 &lt;- rnorm(30, 80, 4) method &lt;- factor(rep(c(‚ÄúA‚Äù, ‚ÄúB‚Äù, ‚ÄúC‚Äù), each=10))\nmanova_model &lt;- manova(cbind(y1, y2, y3) ~ method) summary(manova_model) 5.3 N-Way ANOVA (Interaction Effects)\ndf &lt;- expand.grid( Teaching = c(‚ÄúTraditional‚Äù, ‚ÄúInteractive‚Äù), Gender = c(‚ÄúMale‚Äù, ‚ÄúFemale‚Äù), Rep = 1:20 ) df$Score &lt;- rnorm(80, mean = 70, sd = 5)\nmodel_nway &lt;- aov(Score ~ Teaching * Gender, data = df) summary(model_nway) 5.4 Interaction Plot {r} interaction.plot(df\\(Teaching, df\\)Gender, df$Score, col=c(‚Äúred‚Äù, ‚Äúblue‚Äù)) 5.5 Assumptions of ANOVA Assumption Check Method Tool Normality QQ Plot, Shapiro Test shapiro.test() Homogeneity Levene‚Äôs/Bartlett‚Äôs Test car::leveneTest() Independence Design-level assurance Design phase\n5.6 Assumption Check in R {r} # Normality check shapiro.test(residuals(anova_model))",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#homogeneity-check",
    "href": "week5.html#homogeneity-check",
    "title": "6¬† Week 5",
    "section": "6.12 Homogeneity check",
    "text": "6.12 Homogeneity check\nlibrary(car) leveneTest(score ~ group, data = data) 5.7 Visualizing F-Distribution\ncurve(df(x, df1=3, df2=9), from=0, to=10, col=‚Äúblue‚Äù, lwd=2, ylab=‚ÄúDensity‚Äù, main=‚ÄúF-distribution df(3,9)‚Äù) abline(v=8.27, col=‚Äúred‚Äù, lwd=2, lty=2) legend(‚Äútopright‚Äù, legend=c(‚ÄúF = 8.27‚Äù), col=‚Äúred‚Äù, lty=2) 5.8 Simulation: When F is not significant\nset.seed(2024) group_A &lt;- rnorm(10, mean=50) group_B &lt;- rnorm(10, mean=51) group_C &lt;- rnorm(10, mean=50.5)\nscore &lt;- c(group_A, group_B, group_C) group &lt;- factor(rep(c(‚ÄúA‚Äù, ‚ÄúB‚Äù, ‚ÄúC‚Äù), each=10))\ndf &lt;- data.frame(score, group) aov_model &lt;- aov(score ~ group, data=df) summary(aov_model) ‚û°Ô∏è End of Part 2/4. Part 3 includes Regression (Simple, Multiple, Non-linear), VIF, Residuals, and Advanced Modeling",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#lecture-28-simple-linear-regression",
    "href": "week5.html#lecture-28-simple-linear-regression",
    "title": "6¬† Week 5",
    "section": "6.13 6. Lecture 28 ‚Äì Simple Linear Regression",
    "text": "6.13 6. Lecture 28 ‚Äì Simple Linear Regression\n\n6.13.1 6.1 Theory Refresher\nLinear regression predicts a dependent variable (Y) using an independent variable (X).\nModel Equation:\n\\[\nY = \\beta_0 + \\beta_1 X + \\epsilon\n\\]\nWhere:\n\n\\(\\beta_0\\) = Intercept\n\n\\(\\beta_1\\) = Slope\n\n\\(\\epsilon\\) = Error term\n\n\n\n\n6.13.2 6.2 Example in R\nstudy_time &lt;- c(2, 3, 4, 5, 6) grades &lt;- c(50, 60, 65, 70, 75)\nmodel &lt;- lm(grades ~ study_time) summary(model) 6.3 Regression Line Visualization\nplot(study_time, grades, main=‚ÄúSimple Regression‚Äù, xlab=‚ÄúStudy Time‚Äù, ylab=‚ÄúGrades‚Äù) abline(model, col=‚Äúblue‚Äù, lwd=2) 6.4 Interpret Coefficients\ncoef(model) Intercept: Grade when study time = 0\nSlope: Grade increases per hour of study\n6.5 Residual Plots\npar(mfrow=c(2,2)) plot(model) Top-left: Residuals vs Fitted\nBottom-left: Scale-Location\nTop-right: QQ Plot\nBottom-right: Residuals vs Leverage\n6.6 Confidence Intervals\nconfint(model) 7. Lecture 29 ‚Äì Multiple Regression 7.1 Add More Predictors\ndf &lt;- data.frame( Exam = c(50, 55, 60, 65, 70), Hours = c(2, 3, 4, 5, 6), Sleep = c(7, 6.5, 6, 5.5, 5) ) multi_model &lt;- lm(Exam ~ Hours + Sleep, data = df) summary(multi_model) 7.2 Check VIF (Multicollinearity)\nlibrary(car) vif(multi_model) VIF &gt; 5 ‚Üí multicollinearity warning VIF &gt; 10 ‚Üí serious problem\n7.3 Partial Residual Plots\navPlots(multi_model) 7.4 Plot 3D Regression Plane\n\n\n6.13.3 install.packages(‚Äúscatterplot3d‚Äù)\nlibrary(scatterplot3d) scatterplot3d(df\\(Hours, df\\)Sleep, df$Exam, highlight.3d=TRUE, type=‚Äúh‚Äù, angle=55, color=‚Äúdarkgreen‚Äù, pch=16) 8. Lecture 30 ‚Äì Polynomial and Non-Linear Regression 8.1 Simulating Non-linear Relationship\nx &lt;- seq(0, 10, 0.1) y &lt;- 5 + 2 * x^2 + rnorm(length(x), 0, 5) plot(x, y, main=‚ÄúNon-linear Pattern‚Äù, pch=19) 8.2 Polynomial Regression\npoly_model &lt;- lm(y ~ poly(x, 2)) summary(poly_model)\nlines(x, predict(poly_model), col=‚Äúblue‚Äù, lwd=2) 8.3 Compare with Linear Fit\nlinear_model &lt;- lm(y ~ x) lines(x, predict(linear_model), col=‚Äúred‚Äù, lwd=2, lty=2) legend(‚Äútopleft‚Äù, legend=c(‚ÄúPoly‚Äù, ‚ÄúLinear‚Äù), col=c(‚Äúblue‚Äù, ‚Äúred‚Äù), lty=c(1,2)) 8.4 Residual Analysis\npar(mfrow=c(1,2)) plot(poly_model\\(fitted.values, poly_model\\)residuals, main=‚ÄúPolynomial Residuals‚Äù) plot(linear_model\\(fitted.values, linear_model\\)residuals, main=‚ÄúLinear Residuals‚Äù) 8.5 Curve Fitting with nls()\nx &lt;- seq(0, 10, length.out=100) y &lt;- 2 * exp(0.3 * x) + rnorm(100, sd=3)\nnls_model &lt;- nls(y ~ a * exp(b * x), start=list(a=2, b=0.3)) summary(nls_model)\nlines(x, predict(nls_model), col=‚Äúpurple‚Äù, lwd=2) 9. Lecture 31 ‚Äì Model Evaluation Metrics 9.1 R¬≤ and Adjusted R¬≤\nsummary(multi_model)\\(r.squared\nsummary(multi_model)\\)adj.r.squared 9.2 MSE and RMSE\npred &lt;- predict(multi_model) actual &lt;- df$Exam residuals &lt;- actual - pred mse &lt;- mean(residuals^2) rmse &lt;- sqrt(mse)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week5.html#lecture-32-logistic-regression",
    "href": "week5.html#lecture-32-logistic-regression",
    "title": "6¬† Week 5",
    "section": "6.14 10. Lecture 32 ‚Äì Logistic Regression",
    "text": "6.14 10. Lecture 32 ‚Äì Logistic Regression\n\n6.14.1 10.1 When to Use\nLogistic regression is used when the dependent variable is categorical (typically binary: 0/1, Yes/No, Pass/Fail).\n\n\n6.14.2 10.2 Logistic Function\n\\[\nP(Y=1) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X)}}\n\\]\n\n\n\n6.14.3 10.3 R Example: Predicting Admission\ndf &lt;- data.frame( Admit = c(1,1,0,1,0,0,1,1,0,0), Score = c(80,85,60,90,55,40,88,83,59,52) )\nlogit_model &lt;- glm(Admit ~ Score, data=df, family=‚Äúbinomial‚Äù) summary(logit_model) 10.4 Probability Prediction\ndf$Prob &lt;- predict(logit_model, type=‚Äúresponse‚Äù) df 10.5 ROC Curve\nlibrary(pROC) roc_obj &lt;- roc(df\\(Admit, df\\)Prob) plot(roc_obj, col=‚Äúdarkgreen‚Äù) auc(roc_obj) 10.6 Classification Table\ndf\\(Pred &lt;- ifelse(df\\)Prob &gt; 0.5, 1, 0) table(Predicted = df\\(Pred, Actual = df\\)Admit) 11. Lecture 33 ‚Äì Chi-Square Test 11.1 Categorical Independence Used when evaluating if two categorical variables are independent.\n11.2 Example: Gender vs Department Choice\ngender &lt;- c(‚ÄúMale‚Äù, ‚ÄúMale‚Äù, ‚ÄúFemale‚Äù, ‚ÄúFemale‚Äù) dept &lt;- c(‚ÄúScience‚Äù, ‚ÄúArts‚Äù, ‚ÄúScience‚Äù, ‚ÄúArts‚Äù) counts &lt;- c(30, 20, 25, 25)\nchi_df &lt;- data.frame(Gender=rep(gender, counts), Dept=rep(dept, counts)) tbl &lt;- table(chi_df\\(Gender, chi_df\\)Dept) chisq.test(tbl) 12. Lecture 34 ‚Äì Non-Parametric Tests 12.1 When to Use Data is not normally distributed\nOrdinal data or small sample sizes\n12.2 Mann‚ÄìWhitney U\ngroup1 &lt;- c(45, 50, 60, 55) group2 &lt;- c(70, 75, 80, 85) wilcox.test(group1, group2) 12.3 Kruskal‚ÄìWallis (Non-parametric ANOVA)\ng1 &lt;- c(10, 20, 30) g2 &lt;- c(40, 50, 60) g3 &lt;- c(70, 80, 90) kw_df &lt;- data.frame( score = c(g1, g2, g3), group = factor(rep(c(‚ÄúA‚Äù, ‚ÄúB‚Äù, ‚ÄúC‚Äù), each=3)) ) kruskal.test(score ~ group, data=kw_df) 12.4 Wilcoxon Signed-Rank\nbefore &lt;- c(60, 70, 65, 80) after &lt;- c(62, 75, 68, 82) wilcox.test(before, after, paired=TRUE) 13. Case Study ‚Äì Social Media & Mental Health 13.1 Dataset Simulation\nset.seed(100) n &lt;- 100 hours &lt;- rnorm(n, 3, 1.5) stress &lt;- 10 + 1.2 * hours + rnorm(n)\ndf &lt;- data.frame(hours, stress) model &lt;- lm(stress ~ hours, data=df) summary(model) 13.2 Visual\nplot(hours, stress, main=‚ÄúSocial Media Use vs Stress‚Äù, pch=19) abline(model, col=‚Äúred‚Äù, lwd=2) 13.3 Interpretation Positive slope ‚Üí More hours = more stress\nR¬≤ tells how well hours predict stress\n\n50 Multiple Choice Questions (MCQs) Q1. Pearson‚Äôs r is best used when: Data is ordinal\n\nData is continuous and normally distributed\nData has outliers\nYou want to rank variables\nQ2. Which test compares more than 2 independent means? t-test\nANOVA\nChi-Square\nCorrelation\nQ3. A VIF of 12 means: No multicollinearity\nSevere multicollinearity\nPerfect fit\nHomoscedasticity\n\nExercises Exercise 1: One-Way ANOVA on Fake Marketing Data Generate three ad strategies and test which gives highest customer conversions.\n\nExercise 2: Correlate temperature and ice cream sales Include scatterplot, Pearson‚Äôs r, regression line.\nExercise 3: Logistic regression predicting credit approval Predict using income and debt ratio.\nExercise 4: Chi-Square on survey data Test independence of satisfaction vs.¬†purchase intention.\nExercise 5: Repeated Measures ANOVA Simulate 10 people tested across 3 time points.\n\nGlossary Term Definition ANOVA Test for differences in means across groups Regression Predict numerical output from inputs Correlation Measure of linear association between two variables R¬≤ Proportion of variance explained by model AIC Akaike Information Criterion ‚Äì model quality metric VIF Variance Inflation Factor ‚Äì checks multicollinearity Logistic Regression Used for binary outcome prediction Chi-Square Test for independence between two categorical variables\nAppendix 17.1 RKWard Menus Correlation ‚Üí Statistics ‚Üí Summaries ‚Üí Correlation Matrix\n\nANOVA ‚Üí Analysis ‚Üí ANOVA ‚Üí One-Way or Repeated\nPlots ‚Üí Graphics ‚Üí Histogram / Boxplot / Scatterplot\nRegression ‚Üí Analysis ‚Üí Linear Models\n17.2 Troubleshooting Issue Solution ‚Äúobject not found‚Äù Check variable names (case-sensitive) Plot doesn‚Äôt show Use print(plot_name) or run outside R chunk Model output blank Use summary(model) instead of just model Package not found Install using install.packages(‚Äúname‚Äù)",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7¬† Week 7",
    "section": "",
    "text": "7.1 1. Introduction\nThis eBook focuses on key statistical topics covered in Week 7 of the course Basic Statistics using GUI-R (RKWard). From time series forecasting to Bayesian probability and discrete distributions, each concept is explored with R-based demonstrations, code implementations, and visual outputs.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week7.html#time-series-analysis",
    "href": "week7.html#time-series-analysis",
    "title": "7¬† Week 7",
    "section": "7.2 2. Time Series Analysis",
    "text": "7.2 2. Time Series Analysis\n\n7.2.1 2.1 Overview of Time Series Data",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week7.html#load-and-visualize-example-data",
    "href": "week7.html#load-and-visualize-example-data",
    "title": "7¬† Week 7",
    "section": "7.3 Load and visualize example data",
    "text": "7.3 Load and visualize example data\ninstall.packages(‚ÄúTSA‚Äù) library(TSA) data(tempdub) plot(tempdub, main=‚ÄúMonthly Temperature in Dubuque‚Äù) Trend: Long-term increase or decrease\nSeasonality: Predictable recurring patterns\nCyclic: Irregular, long-term fluctuations\n2.2 Data Import and Price Fetching\ninstall.packages(‚ÄúBatchGetSymbols‚Äù) library(BatchGetSymbols)\nfirst.date &lt;- Sys.Date() - 90 last.date &lt;- Sys.Date() stocks &lt;- c(‚ÄúTCS.NS‚Äù) tcs_prices &lt;- BatchGetSymbols(tickers = stocks, first.date, last.date) write.csv(tcs_prices$data, ‚Äútcs.csv‚Äù) 2.3 Handling Seasonality\nrt &lt;- diff(log(tempdub), 12) # Seasonal difference for monthly data plot(rt, main = ‚ÄúSeasonally Differenced Series‚Äù)\nlibrary(tseries) adf.test(rt) # Test for stationarity Monthly Dummies\nmonth &lt;- season(tempdub) m1 &lt;- lm(tempdub ~ month - 1) summary(m1) resid &lt;- residuals(m1) adf.test(resid) 2.4 Trend Extraction & Detrending\nsim &lt;- rnorm(100, mean = 0, sd = 10) x &lt;- 5 + time(sim)*3 + ts(sim) x &lt;- ts(x) plot(x)\nmodel2 &lt;- lm(x ~ time(x)) resid2 &lt;- resid(model2) adf.test(resid2) 2.5 Smoothing Techniques Simple Moving Average (SMA)\nlibrary(forecast) ts_data &lt;- ts(c(10, 15, 20, 25, 30, 35, 40)) sma &lt;- ma(ts_data, order = 3) plot(sma, type = ‚Äòl‚Äô, col = ‚Äòblue‚Äô) Exponential Moving Average (EMA)\nlibrary(TTR) data &lt;- c(23, 45, 67, 34, 56, 78, 90) ts_data &lt;- ts(data) ema &lt;- EMA(ts_data, n = 3) plot(ema, type = ‚Äòl‚Äô, col = ‚Äòdarkgreen‚Äô) 2.6 Forecasting Models Naive Forecasting: Future = last value\nARIMA:\nlibrary(forecast) fit &lt;- auto.arima(AirPassengers) forecast(fit, h = 12) plot(forecast(fit, h = 12)) ETS Models:\nets_model &lt;- ets(AirPassengers) plot(forecast(ets_model)) 2.7 Accuracy Metrics\nactual &lt;- c(100, 110, 120) pred &lt;- c(98, 112, 119)\nMAE &lt;- mean(abs(actual - pred)) RMSE &lt;- sqrt(mean((actual - pred)^2)) MAPE &lt;- mean(abs((actual - pred)/actual)) * 100\nprint(c(MAE = MAE, RMSE = RMSE, MAPE = MAPE)) 3. Conditional Probability & Bayes‚Äô Theorem 3.1 Conditional Probability If \\(P(B) &gt; 0\\), then:",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week7.html#simulate-joint-probability",
    "href": "week7.html#simulate-joint-probability",
    "title": "7¬† Week 7",
    "section": "7.4 Simulate joint probability",
    "text": "7.4 Simulate joint probability\njoint &lt;- matrix(c(0.1, 0.2, 0.2, 0.5), nrow = 2) P_A_given_B &lt;- joint[1,2] / (joint[1,2] + joint[2,2]) print(P_A_given_B) 3.2 Bayes‚Äô Theorem",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week7.html#prior-probabilities",
    "href": "week7.html#prior-probabilities",
    "title": "7¬† Week 7",
    "section": "7.5 Prior probabilities",
    "text": "7.5 Prior probabilities\nP_user &lt;- 0.05 P_pos_given_user &lt;- 0.9 P_neg_given_nonuser &lt;- 0.8 P_nonuser &lt;- 1 - P_user P_pos_given_nonuser &lt;- 1 - P_neg_given_nonuser",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week7.html#bayes-formula",
    "href": "week7.html#bayes-formula",
    "title": "7¬† Week 7",
    "section": "7.6 Bayes‚Äô formula",
    "text": "7.6 Bayes‚Äô formula\nP_user_given_pos &lt;- (P_pos_given_user * P_user) / ((P_pos_given_user * P_user) + (P_pos_given_nonuser * P_nonuser))\nprint(P_user_given_pos) 3.3 Real-Life Applications Medical Testing\nSpam Filtering\nCredit Risk Modeling",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week7.html#expected-value-and-bivariate-variables",
    "href": "week7.html#expected-value-and-bivariate-variables",
    "title": "7¬† Week 7",
    "section": "7.7 4. Expected Value and Bivariate Variables",
    "text": "7.7 4. Expected Value and Bivariate Variables\n\n7.7.1 4.1 Expected Value Basics\nFor discrete variable \\(X\\):\n\\[\nE(X) = \\sum x_i \\cdot P(x_i)\n\\]\n```r x &lt;- c(1, 2, 3, 4) p &lt;- c(0.1, 0.3, 0.4, 0.2) expected_value &lt;- sum(x * p) print(expected_value) 4.2 Linearity of Expectation If \\(Y = aX + b\\):\na &lt;- 3 b &lt;- 5 E_X &lt;- expected_value E_Y &lt;- a * E_X + b print(E_Y) 4.3 Bivariate Distributions Example: Coin Toss (from PPT) Let:\n\\(X\\) = number of heads\n\\(Y\\) = |heads - tails|\nThen, for 3 coin tosses:\njoint_pmf &lt;- matrix(c( 0, 0, 0, 1/8, 0, 3/8, 0, 0, 0, 3/8, 0, 0, 0, 0, 0, 1/8 ), nrow = 4, byrow = TRUE)\ncolnames(joint_pmf) &lt;- c(‚ÄúY=0‚Äù, ‚ÄúY=1‚Äù, ‚ÄúY=2‚Äù, ‚ÄúY=3‚Äù) rownames(joint_pmf) &lt;- c(‚ÄúX=0‚Äù, ‚ÄúX=1‚Äù, ‚ÄúX=2‚Äù, ‚ÄúX=3‚Äù) print(joint_pmf) 4.4 Marginal Probabilities",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week7.html#advanced-statistical-concepts",
    "href": "week7.html#advanced-statistical-concepts",
    "title": "7¬† Week 7",
    "section": "10.1 7. Advanced Statistical Concepts",
    "text": "10.1 7. Advanced Statistical Concepts\n\n10.1.1 7.1 Stationarity and Unit Root Testing\nA stationary time series has constant mean and variance over time. Its essential for: - Forecasting - Valid modeling - Avoiding spurious regression\n\n10.1.1.1 Unit Root: Augmented Dickey-Fuller (ADF) Test\nlibrary(tseries) set.seed(42) x &lt;- cumsum(rnorm(100)) # non-stationary random walk plot.ts(x, main = ‚ÄúSimulated Random Walk‚Äù)\nadf.test(x) # Likely non-stationary (p &gt; 0.05) 7.2 Detrending Time Series\nt &lt;- time(x) trend_model &lt;- lm(x ~ t) resid_trend &lt;- resid(trend_model) plot(resid_trend, main = ‚ÄúDetrended Series‚Äù) adf.test(resid_trend) # Residuals should now be stationary 7.3 ARIMA Modeling Autoregressive Integrated Moving Average AR(p): Autoregression\nI(d): Differencing\nMA(q): Moving average\nlibrary(forecast) auto.arima(AirPassengers) Full Workflow\ntsdata &lt;- AirPassengers plot(tsdata)",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "Visual Model Summary",
    "section": "",
    "text": "8.1 1. Introduction\nThis module explores the powerful integration of visual analytics and statistical reasoning. While traditional models often rely on tabular outputs, the flexplot package and similar tools highlight the importance of graphical modeling, especially in response to the replication crisis. The week also emphasizes how GUIs like RKWard and RStudio serve different user bases for statistical analysis.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#effect-size-and-cohens-d",
    "href": "week8.html#effect-size-and-cohens-d",
    "title": "Visual Model Summary",
    "section": "8.2 2. Effect Size and Cohen‚Äôs d",
    "text": "8.2 2. Effect Size and Cohen‚Äôs d\nEffect size quantifies the magnitude of the difference, independent of sample size. One of the most common effect size measures is Cohen‚Äôs d, which compares two means.\n\n8.2.1 ‚úÖ Interpretation of d:\n\n\n\nd\nMeaning\n\n\n\n\n0.2\nSmall effect\n\n\n0.5\nMedium effect\n\n\n0.8\nLarge effect\n\n\n\n\n\n8.2.2 üìå R Code Example (Cohen‚Äôs d)",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#load-required-package",
    "href": "week8.html#load-required-package",
    "title": "Visual Model Summary",
    "section": "8.3 Load required package",
    "text": "8.3 Load required package\ninstall.packages(‚Äúlsr‚Äù) library(lsr)",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#load-your-data-csv-format",
    "href": "week8.html#load-your-data-csv-format",
    "title": "Visual Model Summary",
    "section": "8.4 Load your data (CSV format)",
    "text": "8.4 Load your data (CSV format)\nmy.csv.data &lt;- read.csv(‚Äúyourdata.csv‚Äù)",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#independent-groups-cohens-d",
    "href": "week8.html#independent-groups-cohens-d",
    "title": "Visual Model Summary",
    "section": "8.5 Independent groups Cohen‚Äôs d",
    "text": "8.5 Independent groups Cohen‚Äôs d\nlsr::cohensD(my.csv.data[[‚ÄúCSE_1‚Äù]], my.csv.data[[‚ÄúCSE_2‚Äù]])",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#one-sample-mean-vs-population-mean",
    "href": "week8.html#one-sample-mean-vs-population-mean",
    "title": "Visual Model Summary",
    "section": "8.6 One-sample mean vs population mean",
    "text": "8.6 One-sample mean vs population mean\nlsr::cohensD(my.csv.data[[‚ÄúCSE_1‚Äù]], mu = 3.9) üß† Practical Use: Effect size helps you understand practical significance, especially in behavioral research where p-values alone are insufficient.\nNote: Effect sizes should always accompany inferential statistics to avoid overreliance on significance testing.\n\nUnderstanding flexplot: Graphical Statistical Modeling The flexplot package allows for intuitive, formula-driven visual modeling. It uses GLM-style formulas like y ~ x1 + x2, bringing clarity between statistical models and their graphical representations.\n\nüîç Key Features: Visualize univariate, bivariate, and multivariate models\nSupports linear, logistic, and mixed models\nMatches graphical output directly with statistical models\nRequires only one line of code for most use cases\n‚úÖ Installation and Setup:\ninstall.packages(‚Äúflexplot‚Äù) library(flexplot) library(cowplot) # For arranging multiple plots üí° More Coming in Part 2: Univariate & Bivariate flexplot() demos\nGLM integration\nPaneling, Ghost Lines, Beeswarm Visuals\nOverlap handling and jitter control",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#using-flexplot-examples-and-best-practices",
    "href": "week8.html#using-flexplot-examples-and-best-practices",
    "title": "Visual Model Summary",
    "section": "8.7 4. Using flexplot: Examples and Best Practices",
    "text": "8.7 4. Using flexplot: Examples and Best Practices\n\n8.7.1 4.1 Univariate Visualization\nflexplot(CSE_1 ~ 1, data = my.csv.data) Plots raw data (jittered) with mean overlay\nUseful for outlier detection and distribution shape\n4.2 Bivariate Continuous vs Categorical",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#visualizing-continuous-dv-vs-categorical-iv",
    "href": "week8.html#visualizing-continuous-dv-vs-categorical-iv",
    "title": "Visual Model Summary",
    "section": "8.8 Visualizing continuous DV vs categorical IV",
    "text": "8.8 Visualizing continuous DV vs categorical IV\nflexplot(CSE_1 ~ Gender, data = my.csv.data) Automatically creates beeswarm or violin plots\nOverlay: mean ¬± error bars\nJitter is used to prevent overlap of points\n4.3 Continuous DV vs Continuous IV\nflexplot(CSE_1 ~ Age, data = my.csv.data) Shows scatterplot + best-fit line\nAdds error ribbons\nOutliers stand out visually\n4.4 Multiple Predictors (Additive Models)\nflexplot(CSE_1 ~ Age + Gender, data = my.csv.data) Panels by Gender\nLinear fits across Age\nHelps uncover interaction\n4.5 Logistic Regression Visualization",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#convert-passfail-variable-to-factor",
    "href": "week8.html#convert-passfail-variable-to-factor",
    "title": "Visual Model Summary",
    "section": "8.9 Convert pass/fail variable to factor",
    "text": "8.9 Convert pass/fail variable to factor\nmy.csv.data\\(Pass &lt;- as.factor(my.csv.data\\)Pass)",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#logistic-visualization",
    "href": "week8.html#logistic-visualization",
    "title": "Visual Model Summary",
    "section": "8.10 Logistic visualization",
    "text": "8.10 Logistic visualization\nflexplot(Pass ~ Hours, data = my.csv.data, family = ‚Äúbinomial‚Äù) 5. RKWard vs RStudio: Interface & Functionality Feature RKWard RStudio Target Users Beginners, GUI-centric Coders, devs, advanced users Data Handling Spreadsheet-like Tidyverse-friendly Plots Auto-generated via dialogs ggplot2 required manually Statistical Models GUI for t-tests, ANOVA Syntax for all models\nüîé Conclusion: RKWard is ideal for non-programmers, while RStudio is better for reproducible analysis via code and markdown.\n\nCognitive Fit and Visual Communication Flexplot builds upon Cognitive Fit Theory ‚Äî visual representations should match the task and viewer‚Äôs expectation.\n\nKey Graph Types in flexplot Type Best For Beeswarm Small-to-medium samples Violin Density + mean overlay Ghost Lines Slope visualization across panels Panels 2‚Äì3 categorical moderators\n\nAdvanced Flexplot Controls 7.1 Ghost Lines for Slope Tracking\n\nflexplot(mpg ~ wt + cyl, data = mtcars) Panels by cyl\nGray reference slope: overall trend\nColored slope: panel-specific\n7.2 Model Overlays\nflexplot(CSE_1 ~ CSE_2 + Gender, data = my.csv.data) Adds regression lines\nIncludes model summaries in plot captions\n7.3 Added Plot (Influence Visualization)\nmodel &lt;- lm(CSE_1 ~ CSE_2 + Age, data = my.csv.data) added.plot(model) Visualizes the unique contribution of predictors\nResidual scatter by regressor\n\nAssociation, AVPs, and Repeated Measures 8.1 Visualizing Correlation\n\nflexplot(mpg ~ hp, data = mtcars) Adds correlation line\nIncludes Pearson‚Äôs r\n8.2 Repeated Measures (Paneling)\nflexplot(score ~ time + condition, data = repeated_df) Each condition as panel\nTime as predictor\nFits separate lines\n8.3 Binned Paneling (Continuous Moderators)\nflexplot(CSE_1 ~ Age + Income, data = my.csv.data) Age: X-axis\nIncome: Panel bins (equal-width)\nVisualizes moderation effects\n8.4 Jitter, Transparency, Point Customization\nflexplot(CSE_1 ~ Age + Gender, data = my.csv.data, jitter = 0.3, alpha = 0.5, point.size = 2) 9. Interactive Plots and R Markdown Integration\ninstall.packages(‚Äúplotly‚Äù) library(plotly) p &lt;- flexplot(mpg ~ wt + cyl, data = mtcars) ggplotly(p) # Adds interactivity Quarto Embedding markdown\nflexplot(CSE_1 ~ Gender, data = my.csv.data)",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#whats-next-in-part-3",
    "href": "week8.html#whats-next-in-part-3",
    "title": "Visual Model Summary",
    "section": "8.11 üß† What‚Äôs Next in Part 3?",
    "text": "8.11 üß† What‚Äôs Next in Part 3?\n\nüìà Full-scale simulation for effect size\nüß™ Reproducible workflows\nüß∞ Custom function design\nüìò Summary + export instructions\n\nThis final section includes:\nüìä Simulation for effect size\nüß™ Custom model visuals\nüì¶ Reproducible workflows\nüìã Summary + rendering/export notes",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#simulation-effect-size-and-visual-inference",
    "href": "week8.html#simulation-effect-size-and-visual-inference",
    "title": "Visual Model Summary",
    "section": "8.12 10. Simulation: Effect Size and Visual Inference",
    "text": "8.12 10. Simulation: Effect Size and Visual Inference\n\n8.12.1 10.1 Simulate Cohen‚Äôs d with Flexplot\nset.seed(123) group1 &lt;- rnorm(50, mean = 5, sd = 1) group2 &lt;- rnorm(50, mean = 6.2, sd = 1)\ngroup &lt;- factor(rep(c(‚ÄúA‚Äù, ‚ÄúB‚Äù), each = 50)) score &lt;- c(group1, group2)\nsim_df &lt;- data.frame(group, score)\nlibrary(lsr) cohensD(score ~ group, data = sim_df) # Should return d ‚âà 1.2\nflexplot(score ~ group, data = sim_df) 10.2 Power and Confidence Visualization\nlibrary(pwr) pwr.t.test(d = 0.8, power = 0.8, sig.level = 0.05, type = ‚Äútwo.sample‚Äù) 10.3 Monte Carlo Effect Size Estimation\nsim_d &lt;- replicate(1000, { g1 &lt;- rnorm(30, 5, 1) g2 &lt;- rnorm(30, 6, 1) cohensD(g1, g2) })\nhist(sim_d, breaks = 50, col = ‚Äúlightblue‚Äù, main = ‚ÄúSimulated Cohen‚Äôs d Distribution‚Äù) abline(v = mean(sim_d), col = ‚Äúred‚Äù) 11. Visual Inference in Teaching üéì Overlay Raw + Model Together\nflexplot(mpg ~ wt + cyl, data = mtcars) Cyl = Panel\nGray slope = overall\nColor slope = per panel\nR¬≤ and p-values appear below\n\nWorkflow: Reproducible Visual Analytics in R 12.1 Data Import\n\ndf &lt;- read.csv(‚ÄúCSE_scores.csv‚Äù) str(df) 12.2 Visualization Plan Start with flexplot()\nPanel by categorical moderators\nAdd continuous predictors\nUse added.plot() to show incremental effect\nReport both visualization + model summary\n12.3 R Markdown Report markdown\nlibrary(flexplot) flexplot(score ~ gender + age, data = df)",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week8.html#model-summary-with-visual-numeric-layers",
    "href": "week8.html#model-summary-with-visual-numeric-layers",
    "title": "Visual Model Summary",
    "section": "8.13 13. Model Summary with Visual + Numeric Layers",
    "text": "8.13 13. Model Summary with Visual + Numeric Layers\nmodel &lt;- lm(CSE_1 ~ CSE_2 + Age + Gender, data = my.csv.data) summary(model)\nadded.plot(model) # Visual version of unique effect 14. Combining flexplot with ggplot2\np1 &lt;- flexplot(CSE_1 ~ CSE_2 + Gender, data = my.csv.data) p2 &lt;- ggplot(my.csv.data, aes(CSE_2, CSE_1)) + geom_point() + geom_smooth(method = ‚Äúlm‚Äù)\ncowplot::plot_grid(p1, p2, labels = c(‚ÄúFlexplot‚Äù, ‚ÄúGGplot‚Äù)) 15. Summary Concept Tool Used Effect Size cohensD() from lsr Graphical Modeling flexplot() Simulation Monte Carlo Association Plot Slope Panels Influence Plot added.plot() Interactive Graphs ggplotly()",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Week 8</span>"
    ]
  }
]