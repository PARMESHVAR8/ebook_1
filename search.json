[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "my-ebook",
    "section": "",
    "text": "0.1 Lecture notes\nIntroduction\nDR.Harsh Pradhan, [Phone: +91-9930034241 , Email: harsh.231284@gmail.com], Institute of Management Studies, Banaras Hindu University, Address: 18-GF, Jaipuria Enclave, Kaushambhi, Ghaziabad, India, 2010\nInterest: Goal Orientation Job Performance Consumer Behavior Behavioral Finance Bibiliometric Analysis Options as Derivatives Statistics Indian Knowledge System,\nOrcid ID\nGoogle Scholar\nYoutube ID\nAcademic Profile\nCourses offered:\nDownload from here.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#moodle-website",
    "href": "index.html#moodle-website",
    "title": "my-ebook",
    "section": "0.2 Moodle website",
    "text": "0.2 Moodle website\nAll communications with students in Potsdam will be done through this website. # 📘 Schedule\n\n\n\nWeek\nLecture\nMain Topic\nSubtopic\n🎥 Video\n📄 PDF Resource\n\n\n\n\nWeek 2\n1\nDescriptive Statistics\nCentral Tendency\nVideo\nWeek 2.pdf\n\n\n\n2\nDescriptive Statistics\nMeasure of Variability\nVideo\nSame as above\n\n\n\n3\nDescriptive Statistics\nDescribing Data\nVideo\nSame as above\n\n\n\n4\nDescriptive Statistics\nProbability\nVideo\nSame as above\n\n\n\n5\nDescriptive Statistics\nDistribution\nVideo\nSame as above\n\n\nWeek 3\n1\nDescriptive Statistics\nZ Table (Normal Distribution)\nVideo\nWeek 3.pdf\n\n\n\n2\nDescriptive Statistics\nMeasuring Divergence\nVideo\nSame as above\n\n\n\n3\nInferential Statistics\nSample and Population\nVideo\nSame as above\n\n\n\n4\nInferential Statistics\nModel Fit\nVideo\nSame as above\n\n\n\n5\nInferential Statistics\nHypothesis and Error\nVideo\nSame as above\n\n\nWeek 4\n1\nTerms of Statistics\nTerms of Statistics\nVideo\nWeek 4.pdf\n\n\n\n2\nTerms of Statistics\nT-Test\nVideo\nSame as above\n\n\n\n3\nTerms of Statistics\nT-Test in Detail\nVideo\nSame as above\n\n\n\n4\nANOVA\nANOVA\nVideo\nSame as above\n\n\nWeek 5\n1\nANOVA\nExample of ANOVA\nVideo\nWeek 5.pdf\n\n\n\n2\nANOVA\nTypes of ANOVA\nVideo\nSame as above\n\n\n\n3\nCorrelation\nIntroduction to Correlation\nVideo\nSame as above\n\n\n\n4\nCorrelation\nRegression (Part 1)\nVideo\nSame as above\n\n\n\n5\nCorrelation\nRegression (Part 2)\nVideo\nSame as above\n\n\nWeek 6\n1\nCorrelation\nR Script for Regression\nVideo\nWeek 6.pdf\n\n\n\n2\nChi Square\nChi Square\nVideo\nSame as above\n\n\n\n3\nChi Square\nChi Square Test\nVideo\nSame as above\n\n\n\n4\nLogistic Function\nRegression Function\nVideo\nSame as above\n\n\n\n5\nLogistic Function\nDistribution\nVideo\nSame as above\n\n\nWeek 7\n1\nTime Series\nIntro to Time Series\nVideo\nWeek 7.pdf\n\n\n\n2\nTime Series\nConditional Probability\nVideo\nSame as above\n\n\n\n3\nTime Series\nAdditional Concepts\nVideo\nSame as above\n\n\n\n4\nTime Series\nDistribution\nVideo\nSame as above\n\n\n\n5\nTime Series\nPoisson Distribution\nVideo\nSame as above\n\n\n\n6\nIndex Numbers\nPrice & Quantity Index\nVideo\nSame as above\n\n\n\n7\nDecision Environments\nRisk/Uncertainty, Bayes, Trees\nVideo\nSame as above\n\n\n\n8\nTime Series Analysis\nComponents, Trend, Seasonality\nVideo\nSame as above\n\n\n\n9\nTime Series Analysis\nLeast Squares Method\nVideo\nSame as above\n\n\nWeek 8\n1\nEffect Size & Documentation\nPackage/Library\nVideo\nWeek 8.pdf\n\n\n\n2\nEffect Size & Documentation\nRStudio vs RKward\nVideo\nSame as above\n\n\n\n3\nEffect Size & Documentation\nFlexplot\nVideo\nSame as above\n\n\n\n4\nEffect Size & Documentation\nFunctions\nVideo\nSame as above\n\n\n\n5\nEffect Size & Documentation\nR Shiny & R Markdown\nVideo\nSame as above\n\n\n\n6\nEffect Size & Documentation\nApplication with Real Datasets\nVideo\nSame as above\n\n\n\n7\nEffect Size & Interpretation\nImportance in Testing\nVideo\nSame as above\n\n\n\n8\nEffect Size & Interpretation\nInstalling dplyr, ggplot2\nVideo\nSame as above\n\n\n\n9\nEffect Size & Interpretation\nVisual Model Interpretation\nVideo\nSame as above\n\n\n\n10\nEffect Size & Interpretation\nCreating/Using Functions\nVideo\nSame as above\n\n\n\n11\nEffect Size & Interpretation\nReport, Dashboard, Interactivity\nVideo\nSame as above",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "2  week 6",
    "section": "",
    "text": "Table of Contents\nIntroduction_\nChi-Square Test of Goodness of Fit\nChi-Square Test of Independence\nNon-Parametric Tests\nNon-Linear and Logistic Regression\nPoisson & Negative Binomial Distribution\nRobust and Bayesian Regression\nModel Fit Diagnostics\nExercises, Simulations, & Datasets\nSummary\nReferences\n\nIntroduction\n\nThis Week 6 eBook focuses on advanced statistical procedures for analyzing categorical and non-normal data using RKWard, a GUI-based frontend to R.\nWe address: - When traditional parametric methods fail - Tools for ordinal, non-linear, or count data - How to interpret diagnostic plots, residuals, and goodness-of-fit metrics\n\nChi-Square Test of Goodness of Fit\n\nTheory Refresher\nUse this test to see if observed frequency data matches a theoretical distribution (e.g., uniform, binomial, Poisson).\n📊 Example 1: Dice Fairness\nobs &lt;- c(9, 7, 6, 4, 5, 5) expected &lt;- rep(sum(obs)/6, 6) chisq.test(obs, p = rep(1/6, 6)) 📊 Example 2: Simulated Biased Die (Monte Carlo)\nset.seed(42) sim_data &lt;- sample(1:6, size = 600, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.2, 0.2, 0.2)) table_sim &lt;- table(sim_data) chisq.test(table_sim, p = rep(1/6, 6)) 📊 Example 3: Poisson-GOF for Counts\nlibrary(MASS) data_counts &lt;- rpois(100, lambda = 3) obs_table &lt;- table(data_counts) exp_probs &lt;- dpois(as.numeric(names(obs_table)), lambda = 3) chisq.test(obs_table, p = exp_probs/sum(exp_probs)) 🎨 Visualizing Frequencies\nbarplot(rbind(obs, expected), beside = TRUE, col = c(“skyblue”, “orange”), legend.text = c(“Observed”, “Expected”), main = “Dice Roll Distribution”) 3. Chi-Square Test of Independence 🔍 Purpose Test whether two categorical variables are independent.\n📊 Example 1: Gender vs Preference\ndf &lt;- data.frame( Gender = c(“Male”, “Male”, “Female”, “Female”), Laptop = c(“Gaming”, “Non-Gaming”, “Gaming”, “Non-Gaming”), Freq = c(27, 8, 5, 7) ) table_df &lt;- xtabs(Freq ~ Gender + Laptop, data = df) chisq.test(table_df) 📊 Example 2: Titanic Survival\nlibrary(datasets) data(Titanic) chisq.test(Titanic) 📊 Example 3: Simulated Survey\nset.seed(123) survey &lt;- data.frame( Smoke = sample(c(“Yes”, “No”), 100, replace = TRUE), Exer = sample(c(“None”, “Some”, “Regular”), 100, replace = TRUE) ) tb &lt;- table(survey\\(Smoke, survey\\)Exer) chisq.test(tb) 📉 Association Strength\nlibrary(vcd) assocstats(tb) 4. Non-Parametric Tests 🎯 Why Use Them? Parametric assumptions (normality, equal variance) are not always met. Non-parametric tests allow analysis without these constraints.\n📋 Common Tests Parametric Non-Parametric Equivalent One-sample t-test Wilcoxon Signed-Rank Test Two-sample t-test Mann-Whitney U Test One-Way ANOVA Kruskal-Wallis Test Two-Way ANOVA Friedman Test Pearson Correlation Spearman Rank Correlation\n📊 Example 1: Wilcoxon Test (Single Sample)\ndata &lt;- c(3.1, 3.6, 3.8, 4.0, 3.5) wilcox.test(data, mu = 3.5) 📊 Example 2: Mann-Whitney (Between Groups)\ngroup_a &lt;- c(10, 12, 14, 16) group_b &lt;- c(8, 9, 10, 11) wilcox.test(group_a, group_b) 📊 Example 3: Kruskal-Wallis on Iris\nkruskal.test(Sepal.Length ~ Species, data = iris) 📊 Example 4: Spearman Rank Correlation\ncor.test(iris\\(Sepal.Length, iris\\)Petal.Length, method = “spearman”) 🚧 Next: Part 2 — covering:\nNon-Linear Regression\nLogistic Regression\nPoisson & Negative Binomial\nRobust & Bayesian Regression\nModel Fit Diagnostics\nSimulations, Interactive Plots\n\nNon-Linear and Logistic Regression\n\n5.1 Non-Linear Regression\nUsed when data shows curvature, not a straight-line relationship.\n📊 Example 1: Quadratic Fit\n```r x &lt;- 1:10 y &lt;- 5 + 2 * x^2 + rnorm(10, 0, 10) model_quad &lt;- lm(y ~ poly(x, 2, raw = TRUE)) summary(model_quad) plot(x, y) lines(x, predict(model_quad), col = “red”) 📊 Example 2: Exponential Growth\nx &lt;- 1:20 y &lt;- 2 * exp(0.3 * x) + rnorm(20, 0, 10) df &lt;- data.frame(x, y) model_exp &lt;- nls(y ~ a * exp(b * x), data = df, start = list(a = 1, b = 0.1)) summary(model_exp) 5.2 Logistic Regression 📊 Example: Student Pass/Fail\nstudents &lt;- data.frame( Hours = c(1,2,3,4,5,6,7,8,9,10), Pass = c(0,0,0,1,1,1,1,1,1,1) )\nlog_model &lt;- glm(Pass ~ Hours, data = students, family = binomial()) summary(log_model) 🔁 Predict Probabilities\nstudents\\(prob &lt;- predict(log_model, type = \"response\")\nplot(students\\)Hours, students$prob, type = “b”, col = “blue”) 🎯 ROC Curve\nlibrary(pROC) roc_obj &lt;- roc(students\\(Pass, students\\)prob) plot(roc_obj) auc(roc_obj) 6. Poisson & Negative Binomial Distribution ## 6.1 Poisson: Modeling Rare Events\n\nset.seed(123)\nlambda &lt;- 3\ndata_pois &lt;- rpois(100, lambda = lambda)\nobserved &lt;- table(data_pois)\nexpected &lt;- dpois(as.numeric(names(observed)), lambda = lambda)\nchisq.test(observed, p = expected / sum(expected))\n\nWarning in chisq.test(observed, p = expected/sum(expected)): Chi-squared\napproximation may be incorrect\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  observed\nX-squared = 3.0235, df = 8, p-value = 0.9329\n\n\n🔍 Test Fit\nobserved &lt;- table(data_pois) expected &lt;- dpois(as.numeric(names(observed)), lambda = lambda) chisq.test(observed, p = expected / sum(expected)) 6.2 Negative Binomial: Handling Overdispersion\nlibrary(MASS) nb_data &lt;- rnbinom(100, size = 5, mu = 4) hist(nb_data, col = “darkred”, main = “Negative Binomial”) 🔬 Compare Fit\nmean(data_pois); var(data_pois) # Poisson: mean ≈ variance mean(nb_data); var(nb_data) # NB: var &gt; mean 7. Robust and Bayesian Regression 7.1 Robust Regression\nlibrary(MASS) x &lt;- 1:10 y &lt;- 2*x + rnorm(10) y[10] &lt;- 100 # Outlier\nmodel_rlm &lt;- rlm(y ~ x) summary(model_rlm) plot(x, y) abline(model_rlm, col = “red”) 7.2 Bayesian Regression (brms)\nlibrary(brms) data &lt;- data.frame(x = rnorm(100), y = rnorm(100)) model_brm &lt;- brm(y ~ x, data = data, family = gaussian(), chains = 2, iter = 1000) summary(model_brm) plot(model_brm) 8. Model Fit Diagnostics 🔎 AIC & BIC\nAIC(model_quad, log_model) BIC(model_quad, log_model) 📈 Residual Plots\npar(mfrow=c(2,2)) plot(log_model) 🧪 Durbin-Watson Test\nlibrary(car) durbinWatsonTest(log_model) 9. Exercises, Simulations, & Datasets 🧠 Challenge 1: Titanic Chi-Square\nchisq.test(Titanic) 🧠 Challenge 2: Spearman on mtcars\ncor.test(mtcars\\(mpg, mtcars\\)hp, method = “spearman”) 🧠 Challenge 3: Logistic + Polynomial\nmtcars\\(am &lt;- as.factor(mtcars\\)am) log_mod &lt;- glm(am ~ poly(mpg, 2), data = mtcars, family = binomial()) summary(log_mod) 🧠 Challenge 4: Negative Binomial Fit\nlibrary(MASS) data &lt;- rnegbin(100, theta = 2) fit_nb &lt;- glm.nb(data ~ 1) summary(fit_nb) 10. Summary This module brought together:\n💡 Chi-Square Tests for independence and fit\n🧱 Non-parametric alternatives to parametric tests\n🔁 Logistic Regression for classification\n📊 Poisson and NB distributions for count data\n🧠 Robust and Bayesian inference for resistant modeling\n🧪 Diagnostics to ensure model quality\nReferences\nDr. Harsh Pradhan, BHU Lecture Notes R Core Team (2024). The R Project for Statistical Computing. MASS, brms, car, vcd, performance, tidyverse packages Text: Field, A. (2013). Discovering Statistics Using R\n🚀 Next Steps\nComing in Part 3:\nMultinomial and ordinal logistic regression\nZero-inflated Poisson (ZIP) and hurdle models\nBootstrapping and permutation tests\nRMarkdown interactivity: sliders, code widgets\nCustom diagnostic dashboards\nExpanded regression use cases: finance, healthcare, social science\nBrute-force simulations, grid search tuning, multiple datasets\nData cleaning + wrangling using dplyr, janitor, and tidymodels\n\nAdvanced Logistic Models\n\n12.1 Multinomial Logistic Regression\nUsed when the outcome variable has more than two categories (e.g., “Low”, “Medium”, “High”).\nlibrary(nnet) data(iris) iris\\(Size &lt;- cut(iris\\)Sepal.Length, breaks=3, labels=c(“Short”, “Medium”, “Long”)) model_multi &lt;- multinom(Size ~ Sepal.Width + Petal.Length, data=iris) summary(model_multi) 12.2 Ordinal Logistic Regression For ordered categories.\nlibrary(MASS) housing &lt;- data.frame( Sat = factor(sample(1:3, 100, replace = TRUE), labels = c(“Low”, “Med”, “High”)), Infl = sample(1:5, 100, replace = TRUE), Type = sample(c(“Tower”, “Apartment”, “House”), 100, replace = TRUE) ) model_ord &lt;- polr(Sat ~ Infl + Type, data = housing, Hess=TRUE) summary(model_ord) 13. Zero-Inflated and Hurdle Models 13.1 Zero-Inflated Poisson (ZIP) Used when count data has excess zeros.\nlibrary(pscl) data(“bioChemists”, package = “pscl”) zip_model &lt;- zeroinfl(art ~ fem + mar + kid5 + phd + ment, data = bioChemists, dist = “poisson”) summary(zip_model) 13.2 Hurdle Model\nhurdle_model &lt;- hurdle(art ~ fem + mar + kid5 + phd + ment, data = bioChemists) summary(hurdle_model) 14. Bootstrapping & Permutation Testing 14.1 Bootstrapping a Mean\nlibrary(boot) data &lt;- rnorm(50, mean = 10, sd = 3)\nmean_fn &lt;- function(data, indices) { d &lt;- data[indices] return(mean(d)) }\nboot_out &lt;- boot(data = data, statistic = mean_fn, R = 1000) boot.ci(boot_out, type = “bca”) 14.2 Permutation Test Example\nset.seed(100) group1 &lt;- rnorm(20, mean = 50) group2 &lt;- rnorm(20, mean = 55)\nobs_diff &lt;- mean(group1) - mean(group2)\ncombined &lt;- c(group1, group2) perm_diffs &lt;- replicate(5000, { shuffled &lt;- sample(combined) mean(shuffled[1:20]) - mean(shuffled[21:40]) })\np_value &lt;- mean(abs(perm_diffs) &gt;= abs(obs_diff)) hist(perm_diffs, main = “Permutation Test”, col = “lightblue”) abline(v = obs_diff, col = “red”) 15. Interactive Widgets with Quarto Sliders\n\nbarplot(dpois(0:10, 3), names.arg = 0:10, main = \"Poisson Distribution with λ = 3\", col = \"steelblue\")\n\n\n\n\n\n\n\n\n\n3 (Remove or comment out any previous code chunk that used input$lambda or Shiny-specific code for barplot)\n\nData Wrangling Pipelines Cleaning & Summarizing\n\nlibrary(dplyr) library(janitor)\ncleaned &lt;- iris %&gt;% clean_names() %&gt;% group_by(species) %&gt;% summarise(across(everything(), mean, .names = “avg_{.col}”)) 17. Visual Diagnostics 17.1 Residual Diagnostics\nlibrary(performance) model &lt;- lm(mpg ~ wt + hp, data = mtcars) performance::check_model(model) 17.2 Leverage & Influence\ninfluence.measures(model) plot(hatvalues(model), main = “Leverage Values”) 18. Grid Search and Cross Validation Using caret package\nlibrary(caret) data(iris)\ntrain_control &lt;- trainControl(method = “cv”, number = 5) grid &lt;- expand.grid(.k = seq(3, 15, by = 2))\nmodel_knn &lt;- train(Species ~ ., data = iris, method = “knn”, trControl = train_control, tuneGrid = grid) plot(model_knn) 19. Case Study: Healthcare Outcomes Predicting hospital readmission using logistic regression.\nset.seed(42) df &lt;- data.frame( age = sample(20:90, 200, replace = TRUE), diabetes = sample(c(0,1), 200, replace = TRUE), readmit = sample(c(0,1), 200, replace = TRUE) )\nlogit &lt;- glm(readmit ~ age + diabetes, data = df, family = binomial()) summary(logit) Plot Prediction\ndf\\(pred &lt;- predict(logit, type = \"response\")\nplot(df\\)age, df\\(pred, col = df\\)diabetes + 1, pch = 19, xlab = “Age”, ylab = “Predicted Probability”) 20. Massive Simulation: Chi-Square Distribution\nset.seed(123) sim_data &lt;- replicate(10000, { obs &lt;- rpois(6, lambda = 10) exp &lt;- rep(mean(obs), 6) sum((obs - exp)^2 / exp) })\nhist(sim_data, breaks = 50, col = “gray”, main = “Chi-Square Simulated Distribution”) abline(v = qchisq(0.95, df = 5), col = “red”) 21. Resources for Practice Datasets:\nmtcars, iris, Titanic, bioChemists, airquality, faithful\nVisual tools:\nplotly, ggplot2, performance, brms\nCore Packages:\ncaret, pscl, nnet, MASS, boot, dplyr, tidymodels, vcd\nFinal Thoughts\nTesting relationships (Chi-Square)\nModeling categories (Logistic, Ordinal, Multinomial)\nWorking with counts (Poisson, ZIP, NB)\nHandling noise and outliers (Robust Regression)\nGoing Bayesian (brms + Stan)\nValidating rigorously (cross-validation, bootstrap, ROC, AIC/BIC)\nThis eBook can be extended to predictive modeling, real-world dashboards, and reproducible research.\n\nProject Template: Real-World Case Study Framework\n\nObjective\nDevelop an end-to-end statistical analysis pipeline using tools covered in this course.\n📁 Dataset: Custom or Open Data Portal\nOptions: - UCI Machine Learning Repository - Kaggle Datasets - Indian Government Data Portals (data.gov.in)\nSteps:\n🔍 Step 1: Problem Definition\nDefine a question like: &gt; “Is there an association between education level and voting preference?”\n🧹 Step 2: Data Cleaning\nlibrary(tidyverse) data &lt;- read.csv(“your_dataset.csv”) data_clean &lt;- data %&gt;% janitor::clean_names() %&gt;% drop_na() 📊 Step 3: EDA (Exploratory Data Analysis)\nggplot(data_clean, aes(x = variable1, fill = factor(variable2))) + geom_bar(position = “dodge”) + theme_minimal() 📈 Step 4: Modeling Choose one or more:\nChi-square (for independence)\nLogistic Regression (for binary outcomes)\nPoisson/NB (for count outcomes)\nNon-parametric (when assumptions fail)\n🧪 Step 5: Validation\nlibrary(performance) check_model(your_model) 📋 Step 6: Reporting Use:\nTables\nModel summaries\nAIC/BIC\nResiduals\nR² (if applicable)\nsummary(your_model) 24. Visual Appendix: Model Diagnostic Gallery library(performance) library(see)\nExample with linear model\nmodel &lt;- lm(mpg ~ hp + wt, data = mtcars)\nModel diagnostics\ncheck_model(model) 25. Bonus: Live Simulation Tool with Shiny\nEdit library(shiny)\nui &lt;- fluidPage( titlePanel(“Poisson Simulator”), sidebarLayout( sidebarPanel( sliderInput(“lambda”, “Lambda (Rate)”, 1, 10, value = 3) ), mainPanel( plotOutput(“poisPlot”) ) ) )\nserver &lt;- function(input, output) { # (Poisson barplot code removed for PDF compatibility) }\nshinyApp(ui = ui, server = server) 26. Advanced Topics for Further Exploration Topic Package Description Bayesian Multilevel brms, rstan Hierarchical regression models Structural Equation lavaan Latent variable modeling Time Series Forecasting forecast, tsibble ARIMA, exponential smoothing Mixed-Effects Models lme4, nlme Random intercept/slope models Missing Data Handling mice, missForest Imputation strategies High-Dimensional Data glmnet Lasso and Ridge regression",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>week 6</span>"
    ]
  }
]